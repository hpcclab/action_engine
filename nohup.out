INFO 03-21 15:29:22 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot.py:29: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot.py:41: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
Model Name:  Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8
Runnig on Parallel - Loading tokenizer...
Loading model across multiple GPUs...
INFO 03-21 15:29:32 [config.py:583] This model supports multiple tasks: {'classify', 'reward', 'generate', 'embed', 'score'}. Defaulting to 'generate'.
INFO 03-21 15:29:33 [gptq_marlin.py:143] The model is convertible to gptq_marlin during runtime. Using gptq_marlin kernel.
INFO 03-21 15:29:33 [config.py:1515] Defaulting to use mp for distributed inference
INFO 03-21 15:29:33 [config.py:1693] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 03-21 15:29:40 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot.py:29: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot.py:41: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
[2025-03-21 15:29:42] INFO loader.py:87: Loading faiss with AVX512 support.
[2025-03-21 15:29:42] INFO loader.py:92: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-03-21 15:29:42] INFO loader.py:99: Loading faiss with AVX2 support.
[2025-03-21 15:29:42] INFO loader.py:104: Could not load library with AVX2 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx2'")
[2025-03-21 15:29:42] INFO loader.py:110: Loading faiss.
[2025-03-21 15:29:42] INFO loader.py:112: Successfully loaded faiss.
INFO 03-21 15:29:42 [core.py:53] Initializing a V1 LLM engine (v0.8.1) with config: model='Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8', speculative_config=None, tokenizer='Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=gptq_marlin, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 03-21 15:29:42 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 64 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 03-21 15:29:42 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1], buffer_handle=(2, 10485760, 10, 'psm_3730db78'), local_subscribe_addr='ipc:///tmp/a29a0d4e-c801-440f-bc52-23e21cced7a3', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-21 15:29:48 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot.py:29: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot.py:41: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
[2025-03-21 15:29:51] INFO loader.py:87: Loading faiss with AVX512 support.
[2025-03-21 15:29:51] INFO loader.py:92: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-03-21 15:29:51] INFO loader.py:99: Loading faiss with AVX2 support.
[2025-03-21 15:29:51] INFO loader.py:104: Could not load library with AVX2 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx2'")
[2025-03-21 15:29:51] INFO loader.py:110: Loading faiss.
[2025-03-21 15:29:51] INFO loader.py:112: Successfully loaded faiss.
WARNING 03-21 15:29:51 [utils.py:2282] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7bcf9d9b1640>
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:29:51 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_4c88f070'), local_subscribe_addr='ipc:///tmp/a2b05d62-953f-4940-a7b2-b1499d4103a4', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-21 15:29:57 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot.py:29: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot.py:41: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
[2025-03-21 15:30:00] INFO loader.py:87: Loading faiss with AVX512 support.
[2025-03-21 15:30:00] INFO loader.py:92: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-03-21 15:30:00] INFO loader.py:99: Loading faiss with AVX2 support.
[2025-03-21 15:30:00] INFO loader.py:104: Could not load library with AVX2 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx2'")
[2025-03-21 15:30:00] INFO loader.py:110: Loading faiss.
[2025-03-21 15:30:00] INFO loader.py:112: Successfully loaded faiss.
WARNING 03-21 15:30:00 [utils.py:2282] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7eea287494c0>
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:00 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_d9a17b41'), local_subscribe_addr='ipc:///tmp/576249a6-cab8-4f93-a07d-1088598c3035', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:01 [utils.py:925] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:01 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:01 [utils.py:925] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:01 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:01 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/UNT/ae0589/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:01 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/UNT/ae0589/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m WARNING 03-21 15:30:01 [custom_all_reduce.py:146] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m WARNING 03-21 15:30:01 [custom_all_reduce.py:146] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:01 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_48eeff97'), local_subscribe_addr='ipc:///tmp/f802aed9-8cc1-435c-912c-a5b1370368fc', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:01 [parallel_state.py:967] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:01 [cuda.py:215] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:01 [parallel_state.py:967] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:01 [cuda.py:215] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:01 [gpu_model_runner.py:1164] Starting to load model Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8...
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:01 [gptq_marlin.py:235] Using MarlinLinearKernel for GPTQMarlinLinearMethod
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:01 [gpu_model_runner.py:1164] Starting to load model Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8...
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:01 [gptq_marlin.py:235] Using MarlinLinearKernel for GPTQMarlinLinearMethod
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m WARNING 03-21 15:30:02 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m WARNING 03-21 15:30:02 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:02 [weight_utils.py:257] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:02 [weight_utils.py:257] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/9 [00:00<?, ?it/s]
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m Loading safetensors checkpoint shards:  11% Completed | 1/9 [00:01<00:10,  1.29s/it]
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m Loading safetensors checkpoint shards:  22% Completed | 2/9 [00:02<00:08,  1.24s/it]
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m Loading safetensors checkpoint shards:  33% Completed | 3/9 [00:03<00:07,  1.21s/it]
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m Loading safetensors checkpoint shards:  44% Completed | 4/9 [00:04<00:04,  1.01it/s]
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m Loading safetensors checkpoint shards:  56% Completed | 5/9 [00:05<00:03,  1.09it/s]
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m Loading safetensors checkpoint shards:  67% Completed | 6/9 [00:06<00:02,  1.01it/s]
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m Loading safetensors checkpoint shards:  78% Completed | 7/9 [00:07<00:02,  1.05s/it]
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m Loading safetensors checkpoint shards:  89% Completed | 8/9 [00:08<00:01,  1.09s/it]
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m Loading safetensors checkpoint shards: 100% Completed | 9/9 [00:09<00:00,  1.11s/it]
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m Loading safetensors checkpoint shards: 100% Completed | 9/9 [00:09<00:00,  1.08s/it]
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m 
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:12 [loader.py:429] Loading weights took 9.82 seconds
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:12 [gpu_model_runner.py:1176] Model loading took 16.3608 GB and 10.727386 seconds
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:13 [loader.py:429] Loading weights took 11.12 seconds
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:13 [gpu_model_runner.py:1176] Model loading took 16.3608 GB and 11.893535 seconds
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:31 [backends.py:409] Using cache directory: /home/UNT/ae0589/.cache/vllm/torch_compile_cache/b66d6f0d9f/rank_1_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:31 [backends.py:419] Dynamo bytecode transform time: 17.50 s
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:30:32 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:38 [backends.py:409] Using cache directory: /home/UNT/ae0589/.cache/vllm/torch_compile_cache/b66d6f0d9f/rank_0_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:38 [backends.py:419] Dynamo bytecode transform time: 24.33 s
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:30:40 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:31:02 [monitor.py:33] torch.compile takes 24.33 s in total
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:31:02 [monitor.py:33] torch.compile takes 17.50 s in total
INFO 03-21 15:31:04 [kv_cache_utils.py:537] GPU KV cache size: 139,664 tokens
INFO 03-21 15:31:04 [kv_cache_utils.py:540] Maximum concurrency for 32,768 tokens per request: 4.26x
INFO 03-21 15:31:04 [kv_cache_utils.py:537] GPU KV cache size: 139,664 tokens
INFO 03-21 15:31:04 [kv_cache_utils.py:540] Maximum concurrency for 32,768 tokens per request: 4.26x
[1;36m(VllmWorker rank=0 pid=1446980)[0;0m INFO 03-21 15:31:46 [gpu_model_runner.py:1499] Graph capturing finished in 42 secs, took 2.28 GiB
[1;36m(VllmWorker rank=1 pid=1447051)[0;0m INFO 03-21 15:31:46 [gpu_model_runner.py:1499] Graph capturing finished in 42 secs, took 2.28 GiB
INFO 03-21 15:31:46 [core.py:138] init engine (profile, create kv cache, warmup model) took 92.42 seconds
[2025-03-21 15:31:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
------------Qwen model loaded across GPUs.------------

--- Testing level1
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.80s/it, est. speed input: 122.35 toks/s, output: 31.83 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.80s/it, est. speed input: 122.35 toks/s, output: 31.83 toks/s]
[2025-03-21 15:32:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.52s/it, est. speed input: 139.81 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.52s/it, est. speed input: 139.81 toks/s, output: 32.17 toks/s]
[2025-03-21 15:32:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.44s/it, est. speed input: 80.61 toks/s, output: 32.57 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.44s/it, est. speed input: 80.61 toks/s, output: 32.57 toks/s]
[2025-03-21 15:32:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.46s/it, est. speed input: 79.97 toks/s, output: 32.55 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.46s/it, est. speed input: 79.97 toks/s, output: 32.55 toks/s]
[2025-03-21 15:33:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.05s/it, est. speed input: 104.86 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.05s/it, est. speed input: 104.86 toks/s, output: 32.47 toks/s]
[2025-03-21 15:33:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.07s/it, est. speed input: 107.64 toks/s, output: 32.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.07s/it, est. speed input: 107.64 toks/s, output: 32.16 toks/s]
[2025-03-21 15:34:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.78s/it, est. speed input: 99.04 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.78s/it, est. speed input: 99.04 toks/s, output: 32.22 toks/s]
[2025-03-21 15:34:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.81s/it, est. speed input: 98.42 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.81s/it, est. speed input: 98.42 toks/s, output: 32.19 toks/s]
[2025-03-21 15:35:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 97.01 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 97.01 toks/s, output: 32.24 toks/s]
[2025-03-21 15:36:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 97.12 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 97.12 toks/s, output: 32.27 toks/s]
[2025-03-21 15:36:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.93s/it, est. speed input: 318.77 toks/s, output: 30.69 toks/s]Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.93s/it, est. speed input: 318.77 toks/s, output: 30.69 toks/s]
[2025-03-21 15:36:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.09s/it, est. speed input: 89.29 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.09s/it, est. speed input: 89.29 toks/s, output: 32.45 toks/s]
[2025-03-21 15:37:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 83.43 toks/s, output: 32.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 83.43 toks/s, output: 32.51 toks/s]
[2025-03-21 15:37:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.66s/it, est. speed input: 200.56 toks/s, output: 31.71 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.66s/it, est. speed input: 200.56 toks/s, output: 31.71 toks/s]
[2025-03-21 15:38:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 83.57 toks/s, output: 32.50 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 83.57 toks/s, output: 32.50 toks/s]
[2025-03-21 15:38:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.60s/it, est. speed input: 130.51 toks/s, output: 32.13 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.60s/it, est. speed input: 130.51 toks/s, output: 32.13 toks/s]
[2025-03-21 15:39:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.72s/it, est. speed input: 120.58 toks/s, output: 32.67 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.72s/it, est. speed input: 120.58 toks/s, output: 32.67 toks/s]
[2025-03-21 15:39:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.99s/it, est. speed input: 95.58 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.99s/it, est. speed input: 95.58 toks/s, output: 32.37 toks/s]
[2025-03-21 15:39:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.47s/it, est. speed input: 82.22 toks/s, output: 32.54 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.47s/it, est. speed input: 82.22 toks/s, output: 32.54 toks/s]
[2025-03-21 15:40:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 96.34 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 96.34 toks/s, output: 32.25 toks/s]
[2025-03-21 15:40:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 86.46 toks/s, output: 32.43 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 86.46 toks/s, output: 32.43 toks/s]
[2025-03-21 15:41:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 96.09 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 96.09 toks/s, output: 32.25 toks/s]
[2025-03-21 15:41:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.89s/it, est. speed input: 109.19 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.89s/it, est. speed input: 109.19 toks/s, output: 32.24 toks/s]
[2025-03-21 15:42:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.91s/it, est. speed input: 183.93 toks/s, output: 31.63 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.91s/it, est. speed input: 183.93 toks/s, output: 31.63 toks/s]
[2025-03-21 15:42:45] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it, est. speed input: 2382.13 toks/s, output: 16.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it, est. speed input: 2382.13 toks/s, output: 16.41 toks/s]
[2025-03-21 15:42:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.43s/it, est. speed input: 79.66 toks/s, output: 32.58 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.43s/it, est. speed input: 79.66 toks/s, output: 32.58 toks/s]
[2025-03-21 15:43:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.46s/it, est. speed input: 99.28 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.46s/it, est. speed input: 99.28 toks/s, output: 32.39 toks/s]
[2025-03-21 15:43:45] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.01s/it, est. speed input: 125.64 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.01s/it, est. speed input: 125.64 toks/s, output: 32.22 toks/s]
[2025-03-21 15:44:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 80.76 toks/s, output: 32.60 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 80.76 toks/s, output: 32.60 toks/s]
[2025-03-21 15:44:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 82.20 toks/s, output: 32.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 82.20 toks/s, output: 32.56 toks/s]
[2025-03-21 15:45:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.83s/it, est. speed input: 118.36 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.83s/it, est. speed input: 118.36 toks/s, output: 32.34 toks/s]
[2025-03-21 15:45:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.78s/it, est. speed input: 93.77 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.78s/it, est. speed input: 93.77 toks/s, output: 32.47 toks/s]
[2025-03-21 15:46:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.47s/it, est. speed input: 118.73 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.47s/it, est. speed input: 118.73 toks/s, output: 32.33 toks/s]
[2025-03-21 15:46:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it, est. speed input: 2411.99 toks/s, output: 14.62 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it, est. speed input: 2411.99 toks/s, output: 14.62 toks/s]
[2025-03-21 15:46:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.32s/it, est. speed input: 169.13 toks/s, output: 31.98 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.32s/it, est. speed input: 169.13 toks/s, output: 31.98 toks/s]
[2025-03-21 15:46:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.06s/it, est. speed input: 144.09 toks/s, output: 32.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.06s/it, est. speed input: 144.09 toks/s, output: 32.00 toks/s]
[2025-03-21 15:47:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.27s/it, est. speed input: 141.45 toks/s, output: 31.98 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.27s/it, est. speed input: 141.45 toks/s, output: 31.98 toks/s]
[2025-03-21 15:47:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.62s/it, est. speed input: 152.83 toks/s, output: 31.95 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.62s/it, est. speed input: 152.83 toks/s, output: 31.95 toks/s]
[2025-03-21 15:47:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.47s/it, est. speed input: 81.47 toks/s, output: 32.54 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.47s/it, est. speed input: 81.47 toks/s, output: 32.54 toks/s]
[2025-03-21 15:48:13] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.72s/it, est. speed input: 83.69 toks/s, output: 32.55 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.72s/it, est. speed input: 83.69 toks/s, output: 32.55 toks/s]
[2025-03-21 15:48:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.14s/it, est. speed input: 118.85 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.14s/it, est. speed input: 118.85 toks/s, output: 32.41 toks/s]
[2025-03-21 15:49:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 81.26 toks/s, output: 32.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 81.26 toks/s, output: 32.56 toks/s]
[2025-03-21 15:49:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.84s/it, est. speed input: 99.63 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.84s/it, est. speed input: 99.63 toks/s, output: 32.44 toks/s]
[2025-03-21 15:50:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 80.89 toks/s, output: 32.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 80.89 toks/s, output: 32.56 toks/s]
[2025-03-21 15:50:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.39s/it, est. speed input: 78.56 toks/s, output: 32.62 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.39s/it, est. speed input: 78.56 toks/s, output: 32.62 toks/s]
[2025-03-21 15:51:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.57s/it, est. speed input: 110.39 toks/s, output: 32.13 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.57s/it, est. speed input: 110.39 toks/s, output: 32.13 toks/s]
[2025-03-21 15:51:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.81s/it, est. speed input: 99.46 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.81s/it, est. speed input: 99.46 toks/s, output: 32.19 toks/s]
[2025-03-21 15:52:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.73s/it, est. speed input: 188.98 toks/s, output: 31.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.73s/it, est. speed input: 188.98 toks/s, output: 31.39 toks/s]
[2025-03-21 15:52:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.84s/it, est. speed input: 151.67 toks/s, output: 31.81 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.84s/it, est. speed input: 151.67 toks/s, output: 31.81 toks/s]
[2025-03-21 15:52:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.52s/it, est. speed input: 126.39 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.52s/it, est. speed input: 126.39 toks/s, output: 32.06 toks/s]
[2025-03-21 15:53:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.34s/it, est. speed input: 141.39 toks/s, output: 31.92 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.34s/it, est. speed input: 141.39 toks/s, output: 31.92 toks/s]
[2025-03-21 15:53:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.33s/it, est. speed input: 141.46 toks/s, output: 31.93 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.33s/it, est. speed input: 141.46 toks/s, output: 31.93 toks/s]
[2025-03-21 15:53:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.03s/it, est. speed input: 129.96 toks/s, output: 32.14 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.03s/it, est. speed input: 129.96 toks/s, output: 32.14 toks/s]
[2025-03-21 15:54:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.77s/it, est. speed input: 84.21 toks/s, output: 32.53 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.77s/it, est. speed input: 84.21 toks/s, output: 32.53 toks/s]
[2025-03-21 15:54:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.26s/it, est. speed input: 134.66 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.26s/it, est. speed input: 134.66 toks/s, output: 32.20 toks/s]
[2025-03-21 15:55:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.83s/it, est. speed input: 253.54 toks/s, output: 31.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.83s/it, est. speed input: 253.54 toks/s, output: 31.29 toks/s]
[2025-03-21 15:55:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.33s/it, est. speed input: 164.21 toks/s, output: 32.03 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.33s/it, est. speed input: 164.21 toks/s, output: 32.03 toks/s]
[2025-03-21 15:55:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.70s/it, est. speed input: 111.88 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.70s/it, est. speed input: 111.88 toks/s, output: 32.37 toks/s]
[2025-03-21 15:55:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 88.04 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 88.04 toks/s, output: 32.44 toks/s]
[2025-03-21 15:56:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.19s/it, est. speed input: 113.25 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.19s/it, est. speed input: 113.25 toks/s, output: 32.29 toks/s]
[2025-03-21 15:56:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 94.79 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 94.79 toks/s, output: 32.30 toks/s]
[2025-03-21 15:57:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 94.77 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 94.77 toks/s, output: 32.26 toks/s]
[2025-03-21 15:57:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.14s/it, est. speed input: 129.04 toks/s, output: 32.07 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.14s/it, est. speed input: 129.04 toks/s, output: 32.07 toks/s]
[2025-03-21 15:58:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.92s/it, est. speed input: 119.69 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.92s/it, est. speed input: 119.69 toks/s, output: 32.19 toks/s]
[2025-03-21 15:58:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.93s/it, est. speed input: 97.97 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.93s/it, est. speed input: 97.97 toks/s, output: 32.38 toks/s]
[2025-03-21 15:59:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.49s/it, est. speed input: 203.83 toks/s, output: 31.66 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.49s/it, est. speed input: 203.83 toks/s, output: 31.66 toks/s]
[2025-03-21 15:59:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.24s/it, est. speed input: 91.38 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.24s/it, est. speed input: 91.38 toks/s, output: 32.36 toks/s]
[2025-03-21 16:00:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.44s/it, est. speed input: 110.94 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.44s/it, est. speed input: 110.94 toks/s, output: 32.23 toks/s]
[2025-03-21 16:00:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.35s/it, est. speed input: 151.34 toks/s, output: 32.04 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.35s/it, est. speed input: 151.34 toks/s, output: 32.04 toks/s]
[2025-03-21 16:00:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.49s/it, est. speed input: 105.92 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.49s/it, est. speed input: 105.92 toks/s, output: 32.38 toks/s]
[2025-03-21 16:01:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.47s/it, est. speed input: 81.58 toks/s, output: 32.54 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.47s/it, est. speed input: 81.58 toks/s, output: 32.54 toks/s]
[2025-03-21 16:01:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.82s/it, est. speed input: 98.64 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.82s/it, est. speed input: 98.64 toks/s, output: 32.18 toks/s]
[2025-03-21 16:02:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.45s/it, est. speed input: 143.93 toks/s, output: 31.89 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.45s/it, est. speed input: 143.93 toks/s, output: 31.89 toks/s]
[2025-03-21 16:02:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.52s/it, est. speed input: 203.82 toks/s, output: 31.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.52s/it, est. speed input: 203.82 toks/s, output: 31.37 toks/s]
[2025-03-21 16:02:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.22s/it, est. speed input: 130.88 toks/s, output: 31.91 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.22s/it, est. speed input: 130.88 toks/s, output: 31.91 toks/s]
[2025-03-21 16:03:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.57s/it, est. speed input: 128.23 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.57s/it, est. speed input: 128.23 toks/s, output: 32.08 toks/s]
[2025-03-21 16:03:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.08s/it, est. speed input: 125.19 toks/s, output: 32.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.08s/it, est. speed input: 125.19 toks/s, output: 32.15 toks/s]
[2025-03-21 16:04:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.89s/it, est. speed input: 152.50 toks/s, output: 31.88 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.89s/it, est. speed input: 152.50 toks/s, output: 31.88 toks/s]
[2025-03-21 16:04:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 97.53 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 97.53 toks/s, output: 32.25 toks/s]
[2025-03-21 16:04:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 88.84 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 88.84 toks/s, output: 32.40 toks/s]
[2025-03-21 16:05:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 90.30 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 90.30 toks/s, output: 32.41 toks/s]
[2025-03-21 16:06:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.27s/it, est. speed input: 108.13 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.27s/it, est. speed input: 108.13 toks/s, output: 32.45 toks/s]
[2025-03-21 16:06:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.68s/it, est. speed input: 127.59 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.68s/it, est. speed input: 127.59 toks/s, output: 32.32 toks/s]
[2025-03-21 16:06:45] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.28s/it, est. speed input: 100.28 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.28s/it, est. speed input: 100.28 toks/s, output: 32.26 toks/s]
[2025-03-21 16:07:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.84s/it, est. speed input: 105.33 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.84s/it, est. speed input: 105.33 toks/s, output: 32.21 toks/s]
[2025-03-21 16:07:45] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.49s/it, est. speed input: 193.09 toks/s, output: 31.81 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.49s/it, est. speed input: 193.09 toks/s, output: 31.81 toks/s]
[2025-03-21 16:07:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.69s/it, est. speed input: 191.11 toks/s, output: 31.78 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.69s/it, est. speed input: 191.11 toks/s, output: 31.78 toks/s]
[2025-03-21 16:08:13] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it, est. speed input: 2040.80 toks/s, output: 18.66 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it, est. speed input: 2040.80 toks/s, output: 18.66 toks/s]
[2025-03-21 16:08:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.18s/it, est. speed input: 215.20 toks/s, output: 31.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.18s/it, est. speed input: 215.20 toks/s, output: 31.48 toks/s]
[2025-03-21 16:08:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 4018.40 toks/s, output: 1.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 4018.40 toks/s, output: 1.27 toks/s]
[2025-03-21 16:08:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.08s/it, est. speed input: 225.38 toks/s, output: 31.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.08s/it, est. speed input: 225.38 toks/s, output: 31.31 toks/s]
[2025-03-21 16:08:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.16s/it, est. speed input: 105.03 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.16s/it, est. speed input: 105.03 toks/s, output: 32.36 toks/s]
[2025-03-21 16:09:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.85s/it, est. speed input: 103.14 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.85s/it, est. speed input: 103.14 toks/s, output: 32.28 toks/s]
[2025-03-21 16:09:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.63s/it, est. speed input: 91.26 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.63s/it, est. speed input: 91.26 toks/s, output: 32.38 toks/s]
[2025-03-21 16:10:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 87.85 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 87.85 toks/s, output: 32.45 toks/s]
[2025-03-21 16:10:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.64s/it, est. speed input: 157.44 toks/s, output: 31.67 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.64s/it, est. speed input: 157.44 toks/s, output: 31.67 toks/s]
[2025-03-21 16:11:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.56s/it, est. speed input: 111.77 toks/s, output: 32.11 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.56s/it, est. speed input: 111.77 toks/s, output: 32.11 toks/s]
[2025-03-21 16:11:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.01s/it, est. speed input: 100.79 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.01s/it, est. speed input: 100.79 toks/s, output: 32.33 toks/s]
[2025-03-21 16:11:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.48s/it, est. speed input: 137.72 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.48s/it, est. speed input: 137.72 toks/s, output: 32.08 toks/s]
[2025-03-21 16:12:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.75s/it, est. speed input: 98.69 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.75s/it, est. speed input: 98.69 toks/s, output: 32.27 toks/s]
[2025-03-21 16:12:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
level1 Generation Success

--- Testing level2
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.50s/it, est. speed input: 127.17 toks/s, output: 32.09 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.50s/it, est. speed input: 127.17 toks/s, output: 32.09 toks/s]
[2025-03-21 16:13:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.28s/it, est. speed input: 139.62 toks/s, output: 32.04 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.28s/it, est. speed input: 139.62 toks/s, output: 32.04 toks/s]
[2025-03-21 16:13:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 87.06 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 87.06 toks/s, output: 32.45 toks/s]
[2025-03-21 16:14:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.82s/it, est. speed input: 109.63 toks/s, output: 32.13 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.82s/it, est. speed input: 109.63 toks/s, output: 32.13 toks/s]
[2025-03-21 16:14:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.89s/it, est. speed input: 110.33 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.89s/it, est. speed input: 110.33 toks/s, output: 32.22 toks/s]
[2025-03-21 16:14:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.12s/it, est. speed input: 95.64 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.12s/it, est. speed input: 95.64 toks/s, output: 32.36 toks/s]
[2025-03-21 16:15:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.67s/it, est. speed input: 95.14 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.67s/it, est. speed input: 95.14 toks/s, output: 32.36 toks/s]
[2025-03-21 16:15:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.41s/it, est. speed input: 126.62 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.41s/it, est. speed input: 126.62 toks/s, output: 32.08 toks/s]
[2025-03-21 16:16:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.71s/it, est. speed input: 159.44 toks/s, output: 31.71 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.71s/it, est. speed input: 159.44 toks/s, output: 31.71 toks/s]
[2025-03-21 16:16:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.34s/it, est. speed input: 129.10 toks/s, output: 32.05 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.34s/it, est. speed input: 129.10 toks/s, output: 32.05 toks/s]
[2025-03-21 16:17:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.66s/it, est. speed input: 132.94 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.66s/it, est. speed input: 132.94 toks/s, output: 32.08 toks/s]
[2025-03-21 16:17:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 96.80 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 96.80 toks/s, output: 32.26 toks/s]
[2025-03-21 16:17:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 88.95 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 88.95 toks/s, output: 32.38 toks/s]
[2025-03-21 16:18:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.61s/it, est. speed input: 103.96 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.61s/it, est. speed input: 103.96 toks/s, output: 32.17 toks/s]
[2025-03-21 16:18:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 94.74 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 94.74 toks/s, output: 32.29 toks/s]
[2025-03-21 16:19:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 84.81 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 84.81 toks/s, output: 32.44 toks/s]
[2025-03-21 16:20:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 85.09 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 85.09 toks/s, output: 32.44 toks/s]
[2025-03-21 16:20:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.98s/it, est. speed input: 97.99 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.98s/it, est. speed input: 97.99 toks/s, output: 32.28 toks/s]
[2025-03-21 16:21:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.82s/it, est. speed input: 98.18 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.82s/it, est. speed input: 98.18 toks/s, output: 32.36 toks/s]
[2025-03-21 16:21:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.49s/it, est. speed input: 101.32 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.49s/it, est. speed input: 101.32 toks/s, output: 32.25 toks/s]
[2025-03-21 16:22:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it, est. speed input: 1776.67 toks/s, output: 19.86 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it, est. speed input: 1776.67 toks/s, output: 19.86 toks/s]
[2025-03-21 16:22:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.65s/it, est. speed input: 193.61 toks/s, output: 31.73 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.65s/it, est. speed input: 193.61 toks/s, output: 31.73 toks/s]
[2025-03-21 16:22:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.45s/it, est. speed input: 104.96 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.45s/it, est. speed input: 104.96 toks/s, output: 32.29 toks/s]
[2025-03-21 16:22:45] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.92s/it, est. speed input: 117.42 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.92s/it, est. speed input: 117.42 toks/s, output: 32.19 toks/s]
[2025-03-21 16:23:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.35s/it, est. speed input: 100.48 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.35s/it, est. speed input: 100.48 toks/s, output: 32.32 toks/s]
[2025-03-21 16:23:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.03s/it, est. speed input: 230.33 toks/s, output: 31.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.03s/it, est. speed input: 230.33 toks/s, output: 31.31 toks/s]
[2025-03-21 16:23:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.42s/it, est. speed input: 169.42 toks/s, output: 31.90 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.42s/it, est. speed input: 169.42 toks/s, output: 31.90 toks/s]
[2025-03-21 16:24:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.43s/it, est. speed input: 121.48 toks/s, output: 32.13 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.43s/it, est. speed input: 121.48 toks/s, output: 32.13 toks/s]
[2025-03-21 16:24:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.07s/it, est. speed input: 130.37 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.07s/it, est. speed input: 130.37 toks/s, output: 32.19 toks/s]
[2025-03-21 16:24:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 86.17 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 86.17 toks/s, output: 32.38 toks/s]
[2025-03-21 16:25:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.44s/it, est. speed input: 95.00 toks/s, output: 32.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.44s/it, est. speed input: 95.00 toks/s, output: 32.49 toks/s]
[2025-03-21 16:25:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.81s/it, est. speed input: 98.59 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.81s/it, est. speed input: 98.59 toks/s, output: 32.19 toks/s]
[2025-03-21 16:26:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.27s/it, est. speed input: 108.83 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.27s/it, est. speed input: 108.83 toks/s, output: 32.20 toks/s]
[2025-03-21 16:26:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 91.19 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 91.19 toks/s, output: 32.33 toks/s]
[2025-03-21 16:27:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.79s/it, est. speed input: 96.66 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.79s/it, est. speed input: 96.66 toks/s, output: 32.21 toks/s]
[2025-03-21 16:27:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.46s/it, est. speed input: 99.90 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.46s/it, est. speed input: 99.90 toks/s, output: 32.34 toks/s]
[2025-03-21 16:28:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.35s/it, est. speed input: 119.36 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.35s/it, est. speed input: 119.36 toks/s, output: 32.21 toks/s]
[2025-03-21 16:28:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.39s/it, est. speed input: 88.95 toks/s, output: 32.43 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.39s/it, est. speed input: 88.95 toks/s, output: 32.43 toks/s]
[2025-03-21 16:29:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 93.07 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 93.07 toks/s, output: 32.33 toks/s]
[2025-03-21 16:29:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.49s/it, est. speed input: 219.05 toks/s, output: 31.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.49s/it, est. speed input: 219.05 toks/s, output: 31.33 toks/s]
[2025-03-21 16:30:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.04s/it, est. speed input: 103.02 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.04s/it, est. speed input: 103.02 toks/s, output: 32.36 toks/s]
[2025-03-21 16:30:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.17s/it, est. speed input: 131.39 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.17s/it, est. speed input: 131.39 toks/s, output: 32.29 toks/s]
[2025-03-21 16:30:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 95.47 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 95.47 toks/s, output: 32.26 toks/s]
[2025-03-21 16:31:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.71s/it, est. speed input: 128.81 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.71s/it, est. speed input: 128.81 toks/s, output: 32.06 toks/s]
[2025-03-21 16:31:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.73s/it, est. speed input: 102.89 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.73s/it, est. speed input: 102.89 toks/s, output: 32.38 toks/s]
[2025-03-21 16:32:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.64s/it, est. speed input: 191.33 toks/s, output: 31.75 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.64s/it, est. speed input: 191.33 toks/s, output: 31.75 toks/s]
[2025-03-21 16:32:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.04s/it, est. speed input: 142.65 toks/s, output: 32.14 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.04s/it, est. speed input: 142.65 toks/s, output: 32.14 toks/s]
[2025-03-21 16:32:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.41s/it, est. speed input: 108.67 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.41s/it, est. speed input: 108.67 toks/s, output: 32.32 toks/s]
[2025-03-21 16:33:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.40s/it, est. speed input: 103.29 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.40s/it, est. speed input: 103.29 toks/s, output: 32.26 toks/s]
[2025-03-21 16:33:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.64s/it, est. speed input: 114.49 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.64s/it, est. speed input: 114.49 toks/s, output: 32.23 toks/s]
[2025-03-21 16:34:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.44s/it, est. speed input: 145.67 toks/s, output: 32.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.44s/it, est. speed input: 145.67 toks/s, output: 32.00 toks/s]
[2025-03-21 16:34:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.29s/it, est. speed input: 92.57 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.29s/it, est. speed input: 92.57 toks/s, output: 32.37 toks/s]
[2025-03-21 16:34:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.50s/it, est. speed input: 129.10 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.50s/it, est. speed input: 129.10 toks/s, output: 32.30 toks/s]
[2025-03-21 16:35:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.35s/it, est. speed input: 82.03 toks/s, output: 32.53 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.35s/it, est. speed input: 82.03 toks/s, output: 32.53 toks/s]
[2025-03-21 16:35:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it, est. speed input: 2010.86 toks/s, output: 16.99 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it, est. speed input: 2010.86 toks/s, output: 16.99 toks/s]
[2025-03-21 16:35:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 84.66 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 84.66 toks/s, output: 32.46 toks/s]
[2025-03-21 16:36:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.29s/it, est. speed input: 116.80 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.29s/it, est. speed input: 116.80 toks/s, output: 32.31 toks/s]
[2025-03-21 16:36:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.05s/it, est. speed input: 134.11 toks/s, output: 32.12 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.05s/it, est. speed input: 134.11 toks/s, output: 32.12 toks/s]
[2025-03-21 16:37:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.72s/it, est. speed input: 147.03 toks/s, output: 32.12 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.72s/it, est. speed input: 147.03 toks/s, output: 32.12 toks/s]
[2025-03-21 16:37:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it, est. speed input: 1979.09 toks/s, output: 17.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it, est. speed input: 1979.09 toks/s, output: 17.45 toks/s]
[2025-03-21 16:37:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 86.44 toks/s, output: 32.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 86.44 toks/s, output: 32.42 toks/s]
[2025-03-21 16:37:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 86.08 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 86.08 toks/s, output: 32.41 toks/s]
[2025-03-21 16:38:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.59s/it, est. speed input: 213.00 toks/s, output: 31.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.59s/it, est. speed input: 213.00 toks/s, output: 31.40 toks/s]
[2025-03-21 16:38:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.78s/it, est. speed input: 97.15 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.79s/it, est. speed input: 97.15 toks/s, output: 32.22 toks/s]
[2025-03-21 16:39:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.24s/it, est. speed input: 95.55 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.24s/it, est. speed input: 95.55 toks/s, output: 32.27 toks/s]
[2025-03-21 16:39:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.05s/it, est. speed input: 137.88 toks/s, output: 31.93 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.05s/it, est. speed input: 137.88 toks/s, output: 31.93 toks/s]
[2025-03-21 16:40:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.33s/it, est. speed input: 249.11 toks/s, output: 31.14 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.33s/it, est. speed input: 249.11 toks/s, output: 31.14 toks/s]
[2025-03-21 16:40:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.46s/it, est. speed input: 174.09 toks/s, output: 31.76 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.46s/it, est. speed input: 174.09 toks/s, output: 31.76 toks/s]
[2025-03-21 16:40:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 82.40 toks/s, output: 32.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 82.40 toks/s, output: 32.51 toks/s]
[2025-03-21 16:41:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.38s/it, est. speed input: 180.19 toks/s, output: 31.92 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.38s/it, est. speed input: 180.19 toks/s, output: 31.92 toks/s]
[2025-03-21 16:41:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it, est. speed input: 1651.82 toks/s, output: 20.77 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it, est. speed input: 1651.82 toks/s, output: 20.77 toks/s]
[2025-03-21 16:41:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.13s/it, est. speed input: 137.89 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.13s/it, est. speed input: 137.89 toks/s, output: 32.08 toks/s]
[2025-03-21 16:41:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.13s/it, est. speed input: 145.31 toks/s, output: 32.04 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.13s/it, est. speed input: 145.31 toks/s, output: 32.04 toks/s]
[2025-03-21 16:42:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.37s/it, est. speed input: 128.07 toks/s, output: 32.14 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.37s/it, est. speed input: 128.07 toks/s, output: 32.14 toks/s]
[2025-03-21 16:42:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 79.58 toks/s, output: 32.61 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 79.58 toks/s, output: 32.61 toks/s]
[2025-03-21 16:43:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 86.85 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 86.85 toks/s, output: 32.31 toks/s]
[2025-03-21 16:43:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.63s/it, est. speed input: 184.74 toks/s, output: 31.73 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.63s/it, est. speed input: 184.74 toks/s, output: 31.73 toks/s]
[2025-03-21 16:43:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.25s/it, est. speed input: 136.33 toks/s, output: 31.95 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.25s/it, est. speed input: 136.33 toks/s, output: 31.95 toks/s]
[2025-03-21 16:44:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it, est. speed input: 1915.31 toks/s, output: 17.75 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it, est. speed input: 1915.31 toks/s, output: 17.75 toks/s]
[2025-03-21 16:44:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it, est. speed input: 2167.55 toks/s, output: 15.93 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it, est. speed input: 2167.55 toks/s, output: 15.93 toks/s]
[2025-03-21 16:44:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.79s/it, est. speed input: 131.84 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.79s/it, est. speed input: 131.84 toks/s, output: 32.17 toks/s]
[2025-03-21 16:44:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.83s/it, est. speed input: 150.67 toks/s, output: 31.92 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.83s/it, est. speed input: 150.67 toks/s, output: 31.92 toks/s]
[2025-03-21 16:45:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.28s/it, est. speed input: 138.16 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.28s/it, est. speed input: 138.16 toks/s, output: 32.23 toks/s]
[2025-03-21 16:45:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.09s/it, est. speed input: 219.23 toks/s, output: 31.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.09s/it, est. speed input: 219.23 toks/s, output: 31.47 toks/s]
[2025-03-21 16:45:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 83.05 toks/s, output: 32.50 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 83.05 toks/s, output: 32.50 toks/s]
[2025-03-21 16:46:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.15s/it, est. speed input: 121.63 toks/s, output: 32.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.15s/it, est. speed input: 121.63 toks/s, output: 32.15 toks/s]
[2025-03-21 16:46:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 95.52 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 95.52 toks/s, output: 32.25 toks/s]
[2025-03-21 16:47:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.44s/it, est. speed input: 82.95 toks/s, output: 32.57 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.44s/it, est. speed input: 82.95 toks/s, output: 32.57 toks/s]
[2025-03-21 16:47:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.32s/it, est. speed input: 184.27 toks/s, output: 31.67 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.32s/it, est. speed input: 184.27 toks/s, output: 31.67 toks/s]
[2025-03-21 16:47:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.72s/it, est. speed input: 203.58 toks/s, output: 31.71 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.72s/it, est. speed input: 203.58 toks/s, output: 31.71 toks/s]
[2025-03-21 16:48:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it, est. speed input: 2112.52 toks/s, output: 17.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it, est. speed input: 2112.52 toks/s, output: 17.48 toks/s]
[2025-03-21 16:48:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 97.03 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 97.03 toks/s, output: 32.28 toks/s]
[2025-03-21 16:48:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.33s/it, est. speed input: 115.71 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.33s/it, est. speed input: 115.71 toks/s, output: 32.28 toks/s]
[2025-03-21 16:49:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.70s/it, est. speed input: 107.19 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.70s/it, est. speed input: 107.19 toks/s, output: 32.41 toks/s]
[2025-03-21 16:49:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 83.01 toks/s, output: 32.61 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 83.01 toks/s, output: 32.61 toks/s]
[2025-03-21 16:49:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.78s/it, est. speed input: 112.12 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.78s/it, est. speed input: 112.12 toks/s, output: 32.22 toks/s]
[2025-03-21 16:50:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 96.65 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 96.65 toks/s, output: 32.29 toks/s]
[2025-03-21 16:50:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.05s/it, est. speed input: 176.81 toks/s, output: 31.78 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.05s/it, est. speed input: 176.81 toks/s, output: 31.78 toks/s]
[2025-03-21 16:51:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.43s/it, est. speed input: 114.17 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.43s/it, est. speed input: 114.17 toks/s, output: 32.30 toks/s]
[2025-03-21 16:51:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 86.97 toks/s, output: 32.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 86.97 toks/s, output: 32.48 toks/s]
[2025-03-21 16:52:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
level2 Generation Success

--- Testing level3
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 89.08 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 89.08 toks/s, output: 32.39 toks/s]
[2025-03-21 16:52:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it, est. speed input: 1912.74 toks/s, output: 18.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it, est. speed input: 1912.74 toks/s, output: 18.08 toks/s]
[2025-03-21 16:52:45] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.88s/it, est. speed input: 130.80 toks/s, output: 32.09 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.88s/it, est. speed input: 130.80 toks/s, output: 32.09 toks/s]
[2025-03-21 16:53:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 95.42 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 95.42 toks/s, output: 32.26 toks/s]
[2025-03-21 16:53:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.99s/it, est. speed input: 103.34 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.99s/it, est. speed input: 103.34 toks/s, output: 32.21 toks/s]
[2025-03-21 16:54:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.90s/it, est. speed input: 104.17 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.90s/it, est. speed input: 104.17 toks/s, output: 32.24 toks/s]
[2025-03-21 16:54:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 93.48 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 93.48 toks/s, output: 32.32 toks/s]
[2025-03-21 16:55:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.36s/it, est. speed input: 124.99 toks/s, output: 32.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.36s/it, est. speed input: 124.99 toks/s, output: 32.15 toks/s]
[2025-03-21 16:55:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 96.24 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 96.24 toks/s, output: 32.28 toks/s]
[2025-03-21 16:56:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.52s/it, est. speed input: 97.86 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.52s/it, est. speed input: 97.86 toks/s, output: 32.38 toks/s]
[2025-03-21 16:56:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.54s/it, est. speed input: 192.53 toks/s, output: 31.66 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.54s/it, est. speed input: 192.53 toks/s, output: 31.66 toks/s]
[2025-03-21 16:56:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.17s/it, est. speed input: 151.47 toks/s, output: 31.98 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.17s/it, est. speed input: 151.47 toks/s, output: 31.98 toks/s]
[2025-03-21 16:57:13] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.42s/it, est. speed input: 155.12 toks/s, output: 31.83 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.42s/it, est. speed input: 155.12 toks/s, output: 31.83 toks/s]
[2025-03-21 16:57:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.94s/it, est. speed input: 144.42 toks/s, output: 31.90 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.94s/it, est. speed input: 144.42 toks/s, output: 31.90 toks/s]
[2025-03-21 16:57:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.54s/it, est. speed input: 201.50 toks/s, output: 31.52 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.54s/it, est. speed input: 201.50 toks/s, output: 31.52 toks/s]
[2025-03-21 16:58:13] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.45s/it, est. speed input: 120.02 toks/s, output: 32.07 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.45s/it, est. speed input: 120.02 toks/s, output: 32.07 toks/s]
[2025-03-21 16:58:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.24s/it, est. speed input: 114.73 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.24s/it, est. speed input: 114.73 toks/s, output: 32.32 toks/s]
[2025-03-21 16:59:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.33s/it, est. speed input: 132.01 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.33s/it, est. speed input: 132.01 toks/s, output: 32.17 toks/s]
[2025-03-21 16:59:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.83s/it, est. speed input: 89.15 toks/s, output: 32.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.83s/it, est. speed input: 89.15 toks/s, output: 32.49 toks/s]
[2025-03-21 16:59:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.28s/it, est. speed input: 85.04 toks/s, output: 32.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.28s/it, est. speed input: 85.04 toks/s, output: 32.51 toks/s]
[2025-03-21 17:00:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.60s/it, est. speed input: 200.21 toks/s, output: 31.63 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.60s/it, est. speed input: 200.21 toks/s, output: 31.63 toks/s]
[2025-03-21 17:00:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.49s/it, est. speed input: 161.41 toks/s, output: 32.01 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.49s/it, est. speed input: 161.41 toks/s, output: 32.01 toks/s]
[2025-03-21 17:00:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 84.61 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 84.61 toks/s, output: 32.41 toks/s]
[2025-03-21 17:01:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 84.39 toks/s, output: 32.50 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 84.39 toks/s, output: 32.50 toks/s]
[2025-03-21 17:02:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 78.79 toks/s, output: 32.61 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 78.79 toks/s, output: 32.61 toks/s]
[2025-03-21 17:02:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.86s/it, est. speed input: 169.96 toks/s, output: 32.03 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.86s/it, est. speed input: 169.96 toks/s, output: 32.03 toks/s]
[2025-03-21 17:02:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.42s/it, est. speed input: 162.08 toks/s, output: 32.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.42s/it, est. speed input: 162.08 toks/s, output: 32.16 toks/s]
[2025-03-21 17:03:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.39s/it, est. speed input: 79.53 toks/s, output: 32.63 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.39s/it, est. speed input: 79.53 toks/s, output: 32.63 toks/s]
[2025-03-21 17:03:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.56s/it, est. speed input: 198.52 toks/s, output: 31.84 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.56s/it, est. speed input: 198.52 toks/s, output: 31.84 toks/s]
[2025-03-21 17:03:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.57s/it, est. speed input: 147.17 toks/s, output: 31.94 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.57s/it, est. speed input: 147.17 toks/s, output: 31.94 toks/s]
[2025-03-21 17:04:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 94.52 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 94.52 toks/s, output: 32.36 toks/s]
[2025-03-21 17:04:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.87s/it, est. speed input: 144.03 toks/s, output: 32.01 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.87s/it, est. speed input: 144.03 toks/s, output: 32.01 toks/s]
[2025-03-21 17:05:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 94.83 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 94.83 toks/s, output: 32.35 toks/s]
[2025-03-21 17:05:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.95s/it, est. speed input: 165.90 toks/s, output: 31.87 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.95s/it, est. speed input: 165.90 toks/s, output: 31.87 toks/s]
[2025-03-21 17:05:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 94.56 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 94.56 toks/s, output: 32.36 toks/s]
[2025-03-21 17:06:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 95.60 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 95.60 toks/s, output: 32.33 toks/s]
[2025-03-21 17:07:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.87s/it, est. speed input: 111.00 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.87s/it, est. speed input: 111.00 toks/s, output: 32.38 toks/s]
[2025-03-21 17:07:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 85.85 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 85.85 toks/s, output: 32.40 toks/s]
[2025-03-21 17:07:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.28s/it, est. speed input: 133.75 toks/s, output: 32.05 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.28s/it, est. speed input: 133.75 toks/s, output: 32.05 toks/s]
[2025-03-21 17:08:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.10s/it, est. speed input: 242.84 toks/s, output: 31.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.10s/it, est. speed input: 242.84 toks/s, output: 31.26 toks/s]
[2025-03-21 17:08:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 88.99 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 88.99 toks/s, output: 32.46 toks/s]
[2025-03-21 17:09:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.29s/it, est. speed input: 130.18 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.29s/it, est. speed input: 130.18 toks/s, output: 32.27 toks/s]
[2025-03-21 17:09:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.09s/it, est. speed input: 128.31 toks/s, output: 32.10 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.09s/it, est. speed input: 128.31 toks/s, output: 32.10 toks/s]
[2025-03-21 17:09:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.79s/it, est. speed input: 105.91 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.79s/it, est. speed input: 105.91 toks/s, output: 32.31 toks/s]
[2025-03-21 17:10:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.16s/it, est. speed input: 195.99 toks/s, output: 31.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.16s/it, est. speed input: 195.99 toks/s, output: 31.56 toks/s]
[2025-03-21 17:10:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.27s/it, est. speed input: 101.51 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.27s/it, est. speed input: 101.51 toks/s, output: 32.39 toks/s]
[2025-03-21 17:10:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.32s/it, est. speed input: 1275.75 toks/s, output: 23.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.33s/it, est. speed input: 1275.75 toks/s, output: 23.23 toks/s]
[2025-03-21 17:11:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.97s/it, est. speed input: 93.71 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.97s/it, est. speed input: 93.71 toks/s, output: 32.41 toks/s]
[2025-03-21 17:11:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.94s/it, est. speed input: 135.54 toks/s, output: 32.10 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.94s/it, est. speed input: 135.54 toks/s, output: 32.10 toks/s]
[2025-03-21 17:11:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.12s/it, est. speed input: 129.43 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.12s/it, est. speed input: 129.43 toks/s, output: 32.19 toks/s]
[2025-03-21 17:12:13] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 91.04 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 91.04 toks/s, output: 32.45 toks/s]
[2025-03-21 17:12:45] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.01s/it, est. speed input: 102.64 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.01s/it, est. speed input: 102.64 toks/s, output: 32.38 toks/s]
[2025-03-21 17:13:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.83s/it, est. speed input: 115.81 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.83s/it, est. speed input: 115.81 toks/s, output: 32.29 toks/s]
[2025-03-21 17:13:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.85s/it, est. speed input: 109.76 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.85s/it, est. speed input: 109.76 toks/s, output: 32.24 toks/s]
[2025-03-21 17:14:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.19s/it, est. speed input: 107.87 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.19s/it, est. speed input: 107.87 toks/s, output: 32.36 toks/s]
[2025-03-21 17:14:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.28s/it, est. speed input: 135.86 toks/s, output: 32.09 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.28s/it, est. speed input: 135.86 toks/s, output: 32.09 toks/s]
[2025-03-21 17:14:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.41s/it, est. speed input: 114.54 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.41s/it, est. speed input: 114.54 toks/s, output: 32.18 toks/s]
[2025-03-21 17:15:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 97.76 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 97.76 toks/s, output: 32.31 toks/s]
[2025-03-21 17:15:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.37s/it, est. speed input: 152.06 toks/s, output: 33.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.37s/it, est. speed input: 152.06 toks/s, output: 33.08 toks/s]
[2025-03-21 17:16:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.22s/it, est. speed input: 430.10 toks/s, output: 29.79 toks/s]Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.22s/it, est. speed input: 430.10 toks/s, output: 29.79 toks/s]
[2025-03-21 17:16:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.40s/it, est. speed input: 129.48 toks/s, output: 31.97 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.40s/it, est. speed input: 129.48 toks/s, output: 31.97 toks/s]
[2025-03-21 17:16:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.54s/it, est. speed input: 131.31 toks/s, output: 32.07 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.54s/it, est. speed input: 131.31 toks/s, output: 32.07 toks/s]
[2025-03-21 17:17:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.58s/it, est. speed input: 115.66 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.58s/it, est. speed input: 115.66 toks/s, output: 32.17 toks/s]
[2025-03-21 17:17:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 94.95 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 94.95 toks/s, output: 32.29 toks/s]
[2025-03-21 17:18:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.90s/it, est. speed input: 154.28 toks/s, output: 31.96 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.90s/it, est. speed input: 154.28 toks/s, output: 31.96 toks/s]
[2025-03-21 17:18:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 97.35 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 97.35 toks/s, output: 32.32 toks/s]
[2025-03-21 17:19:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.47s/it, est. speed input: 103.53 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.47s/it, est. speed input: 103.53 toks/s, output: 32.36 toks/s]
[2025-03-21 17:19:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.03s/it, est. speed input: 158.07 toks/s, output: 32.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.03s/it, est. speed input: 158.07 toks/s, output: 32.00 toks/s]
[2025-03-21 17:19:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 92.71 toks/s, output: 32.43 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 92.71 toks/s, output: 32.43 toks/s]
[2025-03-21 17:20:21] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.21s/it, est. speed input: 90.69 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.21s/it, est. speed input: 90.69 toks/s, output: 32.46 toks/s]
[2025-03-21 17:20:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 92.39 toks/s, output: 32.43 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 92.39 toks/s, output: 32.43 toks/s]
[2025-03-21 17:21:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.14s/it, est. speed input: 119.07 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.14s/it, est. speed input: 119.07 toks/s, output: 32.27 toks/s]
[2025-03-21 17:21:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.78s/it, est. speed input: 158.48 toks/s, output: 31.95 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.78s/it, est. speed input: 158.48 toks/s, output: 31.95 toks/s]
[2025-03-21 17:22:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 92.75 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 92.75 toks/s, output: 32.46 toks/s]
[2025-03-21 17:22:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 92.20 toks/s, output: 32.43 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 92.20 toks/s, output: 32.43 toks/s]
[2025-03-21 17:23:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 89.65 toks/s, output: 32.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 89.65 toks/s, output: 32.48 toks/s]
[2025-03-21 17:23:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 81.06 toks/s, output: 32.61 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 81.06 toks/s, output: 32.61 toks/s]
[2025-03-21 17:24:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.21s/it, est. speed input: 97.85 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.21s/it, est. speed input: 97.85 toks/s, output: 32.39 toks/s]
[2025-03-21 17:24:45] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 97.15 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 97.15 toks/s, output: 32.31 toks/s]
[2025-03-21 17:25:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.83s/it, est. speed input: 140.46 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.83s/it, est. speed input: 140.46 toks/s, output: 32.20 toks/s]
[2025-03-21 17:25:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.67s/it, est. speed input: 111.08 toks/s, output: 32.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.67s/it, est. speed input: 111.08 toks/s, output: 32.42 toks/s]
[2025-03-21 17:25:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.83s/it, est. speed input: 81.68 toks/s, output: 33.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.83s/it, est. speed input: 81.68 toks/s, output: 33.22 toks/s]
[2025-03-21 17:26:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 82.10 toks/s, output: 32.60 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 82.10 toks/s, output: 32.60 toks/s]
[2025-03-21 17:27:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 94.87 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 94.87 toks/s, output: 32.32 toks/s]
[2025-03-21 17:27:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 94.87 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 94.87 toks/s, output: 32.33 toks/s]
[2025-03-21 17:28:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.39s/it, est. speed input: 79.13 toks/s, output: 32.62 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.39s/it, est. speed input: 79.13 toks/s, output: 32.62 toks/s]
[2025-03-21 17:28:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.82s/it, est. speed input: 154.67 toks/s, output: 31.93 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.82s/it, est. speed input: 154.67 toks/s, output: 31.93 toks/s]
[2025-03-21 17:28:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.29s/it, est. speed input: 144.33 toks/s, output: 31.94 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.29s/it, est. speed input: 144.33 toks/s, output: 31.94 toks/s]
[2025-03-21 17:29:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.44s/it, est. speed input: 81.24 toks/s, output: 32.57 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.44s/it, est. speed input: 81.24 toks/s, output: 32.57 toks/s]
[2025-03-21 17:29:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.72s/it, est. speed input: 95.77 toks/s, output: 32.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.72s/it, est. speed input: 95.77 toks/s, output: 32.49 toks/s]
[2025-03-21 17:30:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.29s/it, est. speed input: 170.75 toks/s, output: 31.93 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.29s/it, est. speed input: 170.75 toks/s, output: 31.93 toks/s]
[2025-03-21 17:30:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.98s/it, est. speed input: 130.19 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.98s/it, est. speed input: 130.19 toks/s, output: 32.18 toks/s]
[2025-03-21 17:30:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.99s/it, est. speed input: 185.56 toks/s, output: 33.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.99s/it, est. speed input: 185.56 toks/s, output: 33.23 toks/s]
[2025-03-21 17:31:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 93.49 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 93.49 toks/s, output: 32.23 toks/s]
[2025-03-21 17:31:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.65s/it, est. speed input: 132.87 toks/s, output: 32.02 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.65s/it, est. speed input: 132.87 toks/s, output: 32.02 toks/s]
[2025-03-21 17:32:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.84s/it, est. speed input: 143.69 toks/s, output: 31.87 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.84s/it, est. speed input: 143.69 toks/s, output: 31.87 toks/s]
[2025-03-21 17:32:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.25s/it, est. speed input: 102.79 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.25s/it, est. speed input: 102.79 toks/s, output: 32.30 toks/s]
[2025-03-21 17:32:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.76s/it, est. speed input: 104.56 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.76s/it, est. speed input: 104.56 toks/s, output: 32.26 toks/s]
[2025-03-21 17:33:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.50s/it, est. speed input: 98.53 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.50s/it, est. speed input: 98.53 toks/s, output: 32.36 toks/s]
[2025-03-21 17:33:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.54s/it, est. speed input: 90.02 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.54s/it, est. speed input: 90.02 toks/s, output: 32.45 toks/s]
level3 Generation Success

Total testing execution time: 7359.76 seconds
finished
INFO 03-21 17:34:38 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot_COT.py:29: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot_COT.py:41: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
Model Name:  Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8
Runnig on Parallel - Loading tokenizer...
Loading model across multiple GPUs...
INFO 03-21 17:34:48 [config.py:583] This model supports multiple tasks: {'reward', 'score', 'embed', 'classify', 'generate'}. Defaulting to 'generate'.
INFO 03-21 17:34:49 [gptq_marlin.py:143] The model is convertible to gptq_marlin during runtime. Using gptq_marlin kernel.
INFO 03-21 17:34:49 [config.py:1515] Defaulting to use mp for distributed inference
INFO 03-21 17:34:49 [config.py:1693] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 03-21 17:34:57 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot_COT.py:29: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot_COT.py:41: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
[2025-03-21 17:34:59] INFO loader.py:87: Loading faiss with AVX512 support.
[2025-03-21 17:34:59] INFO loader.py:92: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-03-21 17:34:59] INFO loader.py:99: Loading faiss with AVX2 support.
[2025-03-21 17:34:59] INFO loader.py:104: Could not load library with AVX2 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx2'")
[2025-03-21 17:34:59] INFO loader.py:110: Loading faiss.
[2025-03-21 17:34:59] INFO loader.py:112: Successfully loaded faiss.
INFO 03-21 17:34:59 [core.py:53] Initializing a V1 LLM engine (v0.8.1) with config: model='Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8', speculative_config=None, tokenizer='Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=gptq_marlin, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 03-21 17:34:59 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 64 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 03-21 17:34:59 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1], buffer_handle=(2, 10485760, 10, 'psm_044f844f'), local_subscribe_addr='ipc:///tmp/b861c3b9-a208-47d0-8984-87229f15b865', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-21 17:35:05 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot_COT.py:29: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot_COT.py:41: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
[2025-03-21 17:35:07] INFO loader.py:87: Loading faiss with AVX512 support.
[2025-03-21 17:35:07] INFO loader.py:92: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-03-21 17:35:07] INFO loader.py:99: Loading faiss with AVX2 support.
[2025-03-21 17:35:07] INFO loader.py:104: Could not load library with AVX2 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx2'")
[2025-03-21 17:35:07] INFO loader.py:110: Loading faiss.
[2025-03-21 17:35:07] INFO loader.py:112: Successfully loaded faiss.
WARNING 03-21 17:35:08 [utils.py:2282] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x786ab6530590>
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:08 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_3d460325'), local_subscribe_addr='ipc:///tmp/8be7fde5-a9da-4c52-94a4-3581a78c8bce', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-21 17:35:14 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot_COT.py:29: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/fewshot_COT.py:41: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
[2025-03-21 17:35:16] INFO loader.py:87: Loading faiss with AVX512 support.
[2025-03-21 17:35:16] INFO loader.py:92: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-03-21 17:35:16] INFO loader.py:99: Loading faiss with AVX2 support.
[2025-03-21 17:35:16] INFO loader.py:104: Could not load library with AVX2 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx2'")
[2025-03-21 17:35:16] INFO loader.py:110: Loading faiss.
[2025-03-21 17:35:16] INFO loader.py:112: Successfully loaded faiss.
WARNING 03-21 17:35:17 [utils.py:2282] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x77f92c79f890>
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:17 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a7e14b53'), local_subscribe_addr='ipc:///tmp/be1b30e0-c60f-4cf5-9170-72103c395391', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:18 [utils.py:925] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:18 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:18 [utils.py:925] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:18 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:18 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/UNT/ae0589/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:18 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/UNT/ae0589/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m WARNING 03-21 17:35:18 [custom_all_reduce.py:146] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m WARNING 03-21 17:35:18 [custom_all_reduce.py:146] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:18 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_bbfc51b7'), local_subscribe_addr='ipc:///tmp/b1dd1636-d6a0-45f0-875f-2f18c70d3747', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:18 [parallel_state.py:967] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:18 [cuda.py:215] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:18 [parallel_state.py:967] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:18 [cuda.py:215] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:18 [gpu_model_runner.py:1164] Starting to load model Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8...
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:18 [gptq_marlin.py:235] Using MarlinLinearKernel for GPTQMarlinLinearMethod
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:18 [gpu_model_runner.py:1164] Starting to load model Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8...
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:18 [gptq_marlin.py:235] Using MarlinLinearKernel for GPTQMarlinLinearMethod
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m WARNING 03-21 17:35:19 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m WARNING 03-21 17:35:19 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:19 [weight_utils.py:257] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:19 [weight_utils.py:257] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/9 [00:00<?, ?it/s]
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m Loading safetensors checkpoint shards:  11% Completed | 1/9 [00:01<00:10,  1.27s/it]
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m Loading safetensors checkpoint shards:  22% Completed | 2/9 [00:02<00:09,  1.31s/it]
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m Loading safetensors checkpoint shards:  33% Completed | 3/9 [00:03<00:08,  1.34s/it]
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m Loading safetensors checkpoint shards:  44% Completed | 4/9 [00:04<00:05,  1.11s/it]
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m Loading safetensors checkpoint shards:  56% Completed | 5/9 [00:05<00:04,  1.04s/it]
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m Loading safetensors checkpoint shards:  67% Completed | 6/9 [00:06<00:03,  1.13s/it]
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m Loading safetensors checkpoint shards:  78% Completed | 7/9 [00:08<00:02,  1.19s/it]
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m Loading safetensors checkpoint shards:  89% Completed | 8/9 [00:09<00:01,  1.24s/it]
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:29 [loader.py:429] Loading weights took 10.40 seconds
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m Loading safetensors checkpoint shards: 100% Completed | 9/9 [00:10<00:00,  1.26s/it]
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m Loading safetensors checkpoint shards: 100% Completed | 9/9 [00:10<00:00,  1.21s/it]
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m 
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:30 [gpu_model_runner.py:1176] Model loading took 16.3608 GB and 11.297773 seconds
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:30 [loader.py:429] Loading weights took 11.02 seconds
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:30 [gpu_model_runner.py:1176] Model loading took 16.3608 GB and 11.741817 seconds
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:54 [backends.py:409] Using cache directory: /home/UNT/ae0589/.cache/vllm/torch_compile_cache/b66d6f0d9f/rank_1_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:54 [backends.py:419] Dynamo bytecode transform time: 24.07 s
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:55 [backends.py:409] Using cache directory: /home/UNT/ae0589/.cache/vllm/torch_compile_cache/b66d6f0d9f/rank_0_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:55 [backends.py:419] Dynamo bytecode transform time: 24.67 s
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:35:56 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:35:57 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:36:19 [monitor.py:33] torch.compile takes 24.07 s in total
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:36:19 [monitor.py:33] torch.compile takes 24.67 s in total
INFO 03-21 17:36:22 [kv_cache_utils.py:537] GPU KV cache size: 139,664 tokens
INFO 03-21 17:36:22 [kv_cache_utils.py:540] Maximum concurrency for 32,768 tokens per request: 4.26x
INFO 03-21 17:36:22 [kv_cache_utils.py:537] GPU KV cache size: 139,664 tokens
INFO 03-21 17:36:22 [kv_cache_utils.py:540] Maximum concurrency for 32,768 tokens per request: 4.26x
[1;36m(VllmWorker rank=0 pid=1480157)[0;0m INFO 03-21 17:37:03 [gpu_model_runner.py:1499] Graph capturing finished in 41 secs, took 2.28 GiB
[1;36m(VllmWorker rank=1 pid=1480175)[0;0m INFO 03-21 17:37:03 [gpu_model_runner.py:1499] Graph capturing finished in 41 secs, took 2.28 GiB
INFO 03-21 17:37:03 [core.py:138] init engine (profile, create kv cache, warmup model) took 93.17 seconds
[2025-03-21 17:37:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
------------Qwen model loaded across GPUs.------------

--- Testing level1
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.38s/it, est. speed input: 96.48 toks/s, output: 32.11 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.38s/it, est. speed input: 96.48 toks/s, output: 32.11 toks/s]
[2025-03-21 17:37:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.11s/it, est. speed input: 142.98 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.11s/it, est. speed input: 142.98 toks/s, output: 32.18 toks/s]
[2025-03-21 17:37:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.96s/it, est. speed input: 158.73 toks/s, output: 32.14 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.96s/it, est. speed input: 158.73 toks/s, output: 32.14 toks/s]
[2025-03-21 17:38:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 80.13 toks/s, output: 32.61 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 80.13 toks/s, output: 32.61 toks/s]
[2025-03-21 17:38:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.54s/it, est. speed input: 173.46 toks/s, output: 32.05 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.54s/it, est. speed input: 173.46 toks/s, output: 32.05 toks/s]
[2025-03-21 17:38:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it, est. speed input: 2087.39 toks/s, output: 16.68 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it, est. speed input: 2087.39 toks/s, output: 16.68 toks/s]
[2025-03-21 17:38:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.67s/it, est. speed input: 132.98 toks/s, output: 32.02 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.67s/it, est. speed input: 132.98 toks/s, output: 32.02 toks/s]
[2025-03-21 17:39:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.63s/it, est. speed input: 177.55 toks/s, output: 31.70 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.63s/it, est. speed input: 177.55 toks/s, output: 31.70 toks/s]
[2025-03-21 17:39:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 97.14 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 97.14 toks/s, output: 32.28 toks/s]
[2025-03-21 17:40:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.69s/it, est. speed input: 115.13 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.69s/it, est. speed input: 115.13 toks/s, output: 32.18 toks/s]
[2025-03-21 17:40:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.90s/it, est. speed input: 1495.21 toks/s, output: 21.54 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.90s/it, est. speed input: 1495.21 toks/s, output: 21.54 toks/s]
[2025-03-21 17:40:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.54s/it, est. speed input: 113.14 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.54s/it, est. speed input: 113.14 toks/s, output: 32.36 toks/s]
[2025-03-21 17:41:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.47s/it, est. speed input: 111.96 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.47s/it, est. speed input: 111.96 toks/s, output: 32.34 toks/s]
[2025-03-21 17:41:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 86.91 toks/s, output: 32.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 86.91 toks/s, output: 32.49 toks/s]
[2025-03-21 17:41:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.17s/it, est. speed input: 113.66 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.17s/it, est. speed input: 113.66 toks/s, output: 32.29 toks/s]
[2025-03-21 17:42:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.63s/it, est. speed input: 197.28 toks/s, output: 31.69 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.63s/it, est. speed input: 197.28 toks/s, output: 31.69 toks/s]
[2025-03-21 17:42:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.58s/it, est. speed input: 187.86 toks/s, output: 33.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.58s/it, est. speed input: 187.86 toks/s, output: 33.20 toks/s]
[2025-03-21 17:42:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.48s/it, est. speed input: 104.97 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.48s/it, est. speed input: 104.97 toks/s, output: 32.37 toks/s]
[2025-03-21 17:43:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 81.51 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 81.51 toks/s, output: 32.27 toks/s]
[2025-03-21 17:43:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.41s/it, est. speed input: 130.66 toks/s, output: 32.04 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.41s/it, est. speed input: 130.66 toks/s, output: 32.04 toks/s]
[2025-03-21 17:44:13] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.97s/it, est. speed input: 97.60 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.97s/it, est. speed input: 97.60 toks/s, output: 32.39 toks/s]
[2025-03-21 17:44:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 96.26 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 96.26 toks/s, output: 32.31 toks/s]
[2025-03-21 17:45:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.62s/it, est. speed input: 102.82 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.62s/it, est. speed input: 102.82 toks/s, output: 32.31 toks/s]
[2025-03-21 17:45:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.60s/it, est. speed input: 131.84 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.60s/it, est. speed input: 131.84 toks/s, output: 32.08 toks/s]
[2025-03-21 17:46:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it, est. speed input: 2448.88 toks/s, output: 15.88 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it, est. speed input: 2448.88 toks/s, output: 15.88 toks/s]
[2025-03-21 17:46:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.74s/it, est. speed input: 115.19 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.74s/it, est. speed input: 115.19 toks/s, output: 32.34 toks/s]
[2025-03-21 17:46:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it, est. speed input: 151.19 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it, est. speed input: 151.19 toks/s, output: 32.06 toks/s]
[2025-03-21 17:46:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.71s/it, est. speed input: 106.82 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.71s/it, est. speed input: 106.82 toks/s, output: 32.41 toks/s]
[2025-03-21 17:47:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.32s/it, est. speed input: 138.49 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.32s/it, est. speed input: 138.49 toks/s, output: 32.32 toks/s]
[2025-03-21 17:47:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.84s/it, est. speed input: 89.64 toks/s, output: 32.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.84s/it, est. speed input: 89.64 toks/s, output: 32.56 toks/s]
[2025-03-21 17:48:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.49s/it, est. speed input: 139.75 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.49s/it, est. speed input: 139.75 toks/s, output: 32.23 toks/s]
[2025-03-21 17:48:21] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.43s/it, est. speed input: 116.16 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.43s/it, est. speed input: 116.16 toks/s, output: 32.28 toks/s]
[2025-03-21 17:48:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.90s/it, est. speed input: 85.24 toks/s, output: 32.50 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.90s/it, est. speed input: 85.24 toks/s, output: 32.50 toks/s]
[2025-03-21 17:49:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.02s/it, est. speed input: 87.95 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.02s/it, est. speed input: 87.95 toks/s, output: 32.45 toks/s]
[2025-03-21 17:49:45] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.75s/it, est. speed input: 943.80 toks/s, output: 26.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.75s/it, est. speed input: 943.80 toks/s, output: 26.23 toks/s]
[2025-03-21 17:49:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.63s/it, est. speed input: 127.77 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.63s/it, est. speed input: 127.77 toks/s, output: 32.17 toks/s]
[2025-03-21 17:50:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.02s/it, est. speed input: 136.61 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.02s/it, est. speed input: 136.61 toks/s, output: 32.06 toks/s]
[2025-03-21 17:50:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.38s/it, est. speed input: 173.79 toks/s, output: 31.88 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.38s/it, est. speed input: 173.79 toks/s, output: 31.88 toks/s]
[2025-03-21 17:50:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.53s/it, est. speed input: 93.13 toks/s, output: 32.58 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.53s/it, est. speed input: 93.13 toks/s, output: 32.58 toks/s]
[2025-03-21 17:51:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.76s/it, est. speed input: 144.75 toks/s, output: 32.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.76s/it, est. speed input: 144.75 toks/s, output: 32.15 toks/s]
[2025-03-21 17:51:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it, est. speed input: 1739.99 toks/s, output: 20.78 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it, est. speed input: 1739.99 toks/s, output: 20.78 toks/s]
[2025-03-21 17:51:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.75s/it, est. speed input: 112.36 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.75s/it, est. speed input: 112.36 toks/s, output: 32.44 toks/s]
[2025-03-21 17:52:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.39s/it, est. speed input: 81.99 toks/s, output: 32.62 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.39s/it, est. speed input: 81.99 toks/s, output: 32.62 toks/s]
[2025-03-21 17:52:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.15s/it, est. speed input: 114.84 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.15s/it, est. speed input: 114.84 toks/s, output: 32.37 toks/s]
[2025-03-21 17:52:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.01s/it, est. speed input: 205.31 toks/s, output: 31.89 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.01s/it, est. speed input: 205.31 toks/s, output: 31.89 toks/s]
[2025-03-21 17:53:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.88s/it, est. speed input: 98.92 toks/s, output: 32.12 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.88s/it, est. speed input: 98.92 toks/s, output: 32.12 toks/s]
[2025-03-21 17:53:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.94s/it, est. speed input: 353.92 toks/s, output: 30.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.94s/it, est. speed input: 353.92 toks/s, output: 30.31 toks/s]
[2025-03-21 17:53:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 99.55 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 99.55 toks/s, output: 32.25 toks/s]
[2025-03-21 17:54:21] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.95s/it, est. speed input: 150.87 toks/s, output: 31.88 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.95s/it, est. speed input: 150.87 toks/s, output: 31.88 toks/s]
[2025-03-21 17:54:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 97.70 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 97.70 toks/s, output: 32.28 toks/s]
[2025-03-21 17:55:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 99.55 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 99.55 toks/s, output: 32.28 toks/s]
[2025-03-21 17:55:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 99.64 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 99.64 toks/s, output: 32.30 toks/s]
[2025-03-21 17:56:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.91s/it, est. speed input: 196.50 toks/s, output: 31.71 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.91s/it, est. speed input: 196.50 toks/s, output: 31.71 toks/s]
[2025-03-21 17:56:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 24.00s/it, est. speed input: 107.98 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 24.00s/it, est. speed input: 107.98 toks/s, output: 32.46 toks/s]
[2025-03-21 17:56:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.04s/it, est. speed input: 161.69 toks/s, output: 32.11 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.04s/it, est. speed input: 161.69 toks/s, output: 32.11 toks/s]
[2025-03-21 17:57:13] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.10s/it, est. speed input: 118.92 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.10s/it, est. speed input: 118.92 toks/s, output: 32.29 toks/s]
[2025-03-21 17:57:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it, est. speed input: 1777.89 toks/s, output: 20.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it, est. speed input: 1777.89 toks/s, output: 20.48 toks/s]
[2025-03-21 17:57:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.76s/it, est. speed input: 102.60 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.76s/it, est. speed input: 102.60 toks/s, output: 32.44 toks/s]
[2025-03-21 17:58:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.86s/it, est. speed input: 121.55 toks/s, output: 32.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.86s/it, est. speed input: 121.55 toks/s, output: 32.15 toks/s]
[2025-03-21 17:58:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.29s/it, est. speed input: 104.19 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.29s/it, est. speed input: 104.19 toks/s, output: 32.33 toks/s]
[2025-03-21 17:58:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 95.08 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 95.08 toks/s, output: 32.40 toks/s]
[2025-03-21 17:59:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.50s/it, est. speed input: 139.89 toks/s, output: 32.09 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.50s/it, est. speed input: 139.89 toks/s, output: 32.09 toks/s]
[2025-03-21 17:59:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 90.58 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 90.58 toks/s, output: 32.47 toks/s]
[2025-03-21 18:00:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.87s/it, est. speed input: 119.94 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.87s/it, est. speed input: 119.94 toks/s, output: 32.26 toks/s]
[2025-03-21 18:00:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 92.79 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 92.79 toks/s, output: 32.41 toks/s]
[2025-03-21 18:01:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.36s/it, est. speed input: 205.82 toks/s, output: 31.75 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.36s/it, est. speed input: 205.82 toks/s, output: 31.75 toks/s]
[2025-03-21 18:01:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 90.49 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 90.49 toks/s, output: 32.46 toks/s]
[2025-03-21 18:02:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.81s/it, est. speed input: 212.46 toks/s, output: 31.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.81s/it, est. speed input: 212.46 toks/s, output: 31.51 toks/s]
[2025-03-21 18:02:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.60s/it, est. speed input: 168.36 toks/s, output: 31.93 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.60s/it, est. speed input: 168.36 toks/s, output: 31.93 toks/s]
[2025-03-21 18:02:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.67s/it, est. speed input: 299.18 toks/s, output: 31.03 toks/s]Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.67s/it, est. speed input: 299.18 toks/s, output: 31.03 toks/s]
[2025-03-21 18:02:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.20s/it, est. speed input: 194.44 toks/s, output: 31.81 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.20s/it, est. speed input: 194.44 toks/s, output: 31.81 toks/s]
[2025-03-21 18:02:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.81s/it, est. speed input: 98.68 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.81s/it, est. speed input: 98.68 toks/s, output: 32.19 toks/s]
[2025-03-21 18:03:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 97.41 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 97.41 toks/s, output: 32.31 toks/s]
[2025-03-21 18:03:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.30s/it, est. speed input: 279.98 toks/s, output: 30.97 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.30s/it, est. speed input: 279.98 toks/s, output: 30.97 toks/s]
[2025-03-21 18:04:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.90s/it, est. speed input: 144.76 toks/s, output: 31.92 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.90s/it, est. speed input: 144.76 toks/s, output: 31.92 toks/s]
[2025-03-21 18:04:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 91.61 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 91.61 toks/s, output: 32.41 toks/s]
[2025-03-21 18:05:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.32s/it, est. speed input: 123.90 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.32s/it, est. speed input: 123.90 toks/s, output: 32.21 toks/s]
[2025-03-21 18:05:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 95.57 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 95.57 toks/s, output: 32.27 toks/s]
[2025-03-21 18:06:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.73s/it, est. speed input: 104.18 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.73s/it, est. speed input: 104.18 toks/s, output: 32.19 toks/s]
[2025-03-21 18:06:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.84s/it, est. speed input: 113.04 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.84s/it, est. speed input: 113.04 toks/s, output: 32.24 toks/s]
[2025-03-21 18:06:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.54s/it, est. speed input: 138.93 toks/s, output: 32.04 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.54s/it, est. speed input: 138.93 toks/s, output: 32.04 toks/s]
[2025-03-21 18:07:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.63s/it, est. speed input: 142.68 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.63s/it, est. speed input: 142.68 toks/s, output: 32.27 toks/s]
[2025-03-21 18:07:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.58s/it, est. speed input: 974.09 toks/s, output: 26.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.58s/it, est. speed input: 974.09 toks/s, output: 26.38 toks/s]
[2025-03-21 18:07:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.84s/it, est. speed input: 98.48 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.84s/it, est. speed input: 98.48 toks/s, output: 32.36 toks/s]
[2025-03-21 18:08:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 96.03 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 96.03 toks/s, output: 32.37 toks/s]
[2025-03-21 18:08:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.05s/it, est. speed input: 323.39 toks/s, output: 30.92 toks/s]Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.05s/it, est. speed input: 323.39 toks/s, output: 30.92 toks/s]
[2025-03-21 18:08:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.42s/it, est. speed input: 83.27 toks/s, output: 32.60 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.42s/it, est. speed input: 83.27 toks/s, output: 32.60 toks/s]
[2025-03-21 18:09:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.87s/it, est. speed input: 140.78 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.87s/it, est. speed input: 140.78 toks/s, output: 32.30 toks/s]
[2025-03-21 18:09:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.59s/it, est. speed input: 373.90 toks/s, output: 30.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.59s/it, est. speed input: 373.90 toks/s, output: 30.31 toks/s]
[2025-03-21 18:09:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 99.88 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 99.88 toks/s, output: 32.26 toks/s]
[2025-03-21 18:10:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 100.00 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 100.00 toks/s, output: 32.26 toks/s]
[2025-03-21 18:10:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.82s/it, est. speed input: 102.33 toks/s, output: 32.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.82s/it, est. speed input: 102.33 toks/s, output: 32.42 toks/s]
[2025-03-21 18:11:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 90.99 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 90.99 toks/s, output: 32.44 toks/s]
[2025-03-21 18:11:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.22s/it, est. speed input: 110.05 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.22s/it, est. speed input: 110.05 toks/s, output: 32.30 toks/s]
[2025-03-21 18:12:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 88.02 toks/s, output: 32.52 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 88.02 toks/s, output: 32.52 toks/s]
[2025-03-21 18:12:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.85s/it, est. speed input: 195.07 toks/s, output: 31.61 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.85s/it, est. speed input: 195.07 toks/s, output: 31.61 toks/s]
[2025-03-21 18:13:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.15s/it, est. speed input: 166.64 toks/s, output: 31.74 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.16s/it, est. speed input: 166.64 toks/s, output: 31.74 toks/s]
[2025-03-21 18:13:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.37s/it, est. speed input: 121.66 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.37s/it, est. speed input: 121.66 toks/s, output: 32.22 toks/s]
[2025-03-21 18:13:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 85.13 toks/s, output: 32.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 85.13 toks/s, output: 32.49 toks/s]
[2025-03-21 18:14:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.29s/it, est. speed input: 96.94 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.29s/it, est. speed input: 96.94 toks/s, output: 32.39 toks/s]
[2025-03-21 18:14:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
level1 Generation Success

--- Testing level2
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.50s/it, est. speed input: 104.05 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.50s/it, est. speed input: 104.05 toks/s, output: 32.33 toks/s]
[2025-03-21 18:15:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.62s/it, est. speed input: 102.53 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.62s/it, est. speed input: 102.53 toks/s, output: 32.33 toks/s]
[2025-03-21 18:15:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 87.24 toks/s, output: 32.52 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 87.24 toks/s, output: 32.52 toks/s]
[2025-03-21 18:16:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.87s/it, est. speed input: 109.45 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.87s/it, est. speed input: 109.45 toks/s, output: 32.21 toks/s]
[2025-03-21 18:16:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.55s/it, est. speed input: 132.56 toks/s, output: 32.12 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.55s/it, est. speed input: 132.56 toks/s, output: 32.12 toks/s]
[2025-03-21 18:17:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 84.38 toks/s, output: 32.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 84.38 toks/s, output: 32.48 toks/s]
[2025-03-21 18:17:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 86.45 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 86.45 toks/s, output: 32.45 toks/s]
[2025-03-21 18:18:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 93.84 toks/s, output: 32.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 93.84 toks/s, output: 32.42 toks/s]
[2025-03-21 18:18:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.80s/it, est. speed input: 126.73 toks/s, output: 32.10 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.80s/it, est. speed input: 126.73 toks/s, output: 32.10 toks/s]
[2025-03-21 18:19:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 95.31 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 95.31 toks/s, output: 32.39 toks/s]
[2025-03-21 18:19:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.91s/it, est. speed input: 115.61 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.91s/it, est. speed input: 115.61 toks/s, output: 32.31 toks/s]
[2025-03-21 18:20:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 96.86 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 96.86 toks/s, output: 32.28 toks/s]
[2025-03-21 18:20:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.76s/it, est. speed input: 91.45 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.76s/it, est. speed input: 91.45 toks/s, output: 32.41 toks/s]
[2025-03-21 18:21:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.42s/it, est. speed input: 122.53 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.42s/it, est. speed input: 122.53 toks/s, output: 32.23 toks/s]
[2025-03-21 18:21:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 94.95 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 94.95 toks/s, output: 32.35 toks/s]
[2025-03-21 18:22:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.43s/it, est. speed input: 153.61 toks/s, output: 32.02 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.43s/it, est. speed input: 153.61 toks/s, output: 32.02 toks/s]
[2025-03-21 18:22:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 85.28 toks/s, output: 32.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 85.28 toks/s, output: 32.51 toks/s]
[2025-03-21 18:22:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.04s/it, est. speed input: 117.31 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.04s/it, est. speed input: 117.31 toks/s, output: 32.22 toks/s]
[2025-03-21 18:23:21] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.93s/it, est. speed input: 161.32 toks/s, output: 31.96 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.93s/it, est. speed input: 161.32 toks/s, output: 31.96 toks/s]
[2025-03-21 18:23:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.30s/it, est. speed input: 113.63 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.30s/it, est. speed input: 113.63 toks/s, output: 32.25 toks/s]
[2025-03-21 18:24:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.51s/it, est. speed input: 304.86 toks/s, output: 31.03 toks/s]Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.51s/it, est. speed input: 304.86 toks/s, output: 31.03 toks/s]
[2025-03-21 18:24:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it, est. speed input: 1937.98 toks/s, output: 18.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it, est. speed input: 1937.98 toks/s, output: 18.34 toks/s]
[2025-03-21 18:24:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.57s/it, est. speed input: 100.68 toks/s, output: 32.43 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.57s/it, est. speed input: 100.68 toks/s, output: 32.43 toks/s]
[2025-03-21 18:24:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 89.12 toks/s, output: 32.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 89.12 toks/s, output: 32.49 toks/s]
[2025-03-21 18:25:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 90.12 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 90.12 toks/s, output: 32.40 toks/s]
[2025-03-21 18:25:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.24s/it, est. speed input: 196.89 toks/s, output: 31.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.24s/it, est. speed input: 196.89 toks/s, output: 31.56 toks/s]
[2025-03-21 18:26:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.47s/it, est. speed input: 83.02 toks/s, output: 32.54 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.47s/it, est. speed input: 83.02 toks/s, output: 32.54 toks/s]
[2025-03-21 18:26:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.58s/it, est. speed input: 107.62 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.58s/it, est. speed input: 107.62 toks/s, output: 32.27 toks/s]
[2025-03-21 18:27:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 83.18 toks/s, output: 32.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 83.18 toks/s, output: 32.56 toks/s]
[2025-03-21 18:27:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 86.42 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 86.42 toks/s, output: 32.47 toks/s]
[2025-03-21 18:28:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.81s/it, est. speed input: 93.70 toks/s, output: 32.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.81s/it, est. speed input: 93.70 toks/s, output: 32.56 toks/s]
[2025-03-21 18:28:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.02s/it, est. speed input: 125.32 toks/s, output: 32.09 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.02s/it, est. speed input: 125.32 toks/s, output: 32.09 toks/s]
[2025-03-21 18:28:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.20s/it, est. speed input: 97.90 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.20s/it, est. speed input: 97.90 toks/s, output: 32.36 toks/s]
[2025-03-21 18:29:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 91.40 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 91.40 toks/s, output: 32.41 toks/s]
[2025-03-21 18:30:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.92s/it, est. speed input: 123.30 toks/s, output: 32.10 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.92s/it, est. speed input: 123.30 toks/s, output: 32.10 toks/s]
[2025-03-21 18:30:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.47s/it, est. speed input: 99.84 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.47s/it, est. speed input: 99.84 toks/s, output: 32.47 toks/s]
[2025-03-21 18:30:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.19s/it, est. speed input: 145.23 toks/s, output: 32.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.19s/it, est. speed input: 145.23 toks/s, output: 32.15 toks/s]
[2025-03-21 18:31:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 88.61 toks/s, output: 32.50 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 88.61 toks/s, output: 32.50 toks/s]
[2025-03-21 18:31:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.34s/it, est. speed input: 221.01 toks/s, output: 31.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.34s/it, est. speed input: 221.01 toks/s, output: 31.49 toks/s]
[2025-03-21 18:32:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.15s/it, est. speed input: 209.57 toks/s, output: 31.50 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.15s/it, est. speed input: 209.57 toks/s, output: 31.50 toks/s]
[2025-03-21 18:32:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.31s/it, est. speed input: 181.97 toks/s, output: 31.81 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.31s/it, est. speed input: 181.97 toks/s, output: 31.81 toks/s]
[2025-03-21 18:32:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.68s/it, est. speed input: 128.02 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.68s/it, est. speed input: 128.02 toks/s, output: 32.37 toks/s]
[2025-03-21 18:32:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 95.76 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 95.76 toks/s, output: 32.36 toks/s]
[2025-03-21 18:33:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 96.28 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 96.28 toks/s, output: 32.28 toks/s]
[2025-03-21 18:33:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.75s/it, est. speed input: 141.16 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.75s/it, est. speed input: 141.16 toks/s, output: 32.21 toks/s]
[2025-03-21 18:34:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.90s/it, est. speed input: 202.23 toks/s, output: 31.78 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.90s/it, est. speed input: 202.23 toks/s, output: 31.78 toks/s]
[2025-03-21 18:34:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.32s/it, est. speed input: 1110.13 toks/s, output: 25.01 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.32s/it, est. speed input: 1110.13 toks/s, output: 25.01 toks/s]
[2025-03-21 18:34:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.87s/it, est. speed input: 127.10 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.87s/it, est. speed input: 127.10 toks/s, output: 32.29 toks/s]
[2025-03-21 18:34:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 89.72 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 89.72 toks/s, output: 32.46 toks/s]
[2025-03-21 18:35:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 89.13 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 89.13 toks/s, output: 32.35 toks/s]
[2025-03-21 18:35:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.22s/it, est. speed input: 93.69 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.22s/it, est. speed input: 93.69 toks/s, output: 32.37 toks/s]
[2025-03-21 18:36:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.46s/it, est. speed input: 86.17 toks/s, output: 32.55 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.46s/it, est. speed input: 86.17 toks/s, output: 32.55 toks/s]
[2025-03-21 18:36:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.54s/it, est. speed input: 116.92 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.54s/it, est. speed input: 116.92 toks/s, output: 32.46 toks/s]
[2025-03-21 18:37:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it, est. speed input: 927.28 toks/s, output: 26.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it, est. speed input: 927.28 toks/s, output: 26.32 toks/s]
[2025-03-21 18:37:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it, est. speed input: 1969.25 toks/s, output: 17.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it, est. speed input: 1969.25 toks/s, output: 17.36 toks/s]
[2025-03-21 18:37:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.43s/it, est. speed input: 84.98 toks/s, output: 32.58 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.43s/it, est. speed input: 84.98 toks/s, output: 32.58 toks/s]
[2025-03-21 18:37:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.67s/it, est. speed input: 139.42 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.67s/it, est. speed input: 139.42 toks/s, output: 32.19 toks/s]
[2025-03-21 18:38:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 85.27 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 85.27 toks/s, output: 32.47 toks/s]
[2025-03-21 18:38:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.36s/it, est. speed input: 181.38 toks/s, output: 31.96 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.36s/it, est. speed input: 181.38 toks/s, output: 31.96 toks/s]
[2025-03-21 18:39:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.58s/it, est. speed input: 162.15 toks/s, output: 31.87 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.58s/it, est. speed input: 162.15 toks/s, output: 31.87 toks/s]
[2025-03-21 18:39:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.68s/it, est. speed input: 125.93 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.68s/it, est. speed input: 125.93 toks/s, output: 32.24 toks/s]
[2025-03-21 18:39:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 86.36 toks/s, output: 32.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 86.36 toks/s, output: 32.51 toks/s]
[2025-03-21 18:40:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.85s/it, est. speed input: 164.81 toks/s, output: 31.83 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.85s/it, est. speed input: 164.81 toks/s, output: 31.83 toks/s]
[2025-03-21 18:40:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.90s/it, est. speed input: 106.85 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.90s/it, est. speed input: 106.85 toks/s, output: 32.21 toks/s]
[2025-03-21 18:41:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 94.26 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 94.26 toks/s, output: 32.34 toks/s]
[2025-03-21 18:41:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 100.09 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 100.09 toks/s, output: 32.25 toks/s]
[2025-03-21 18:42:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.54s/it, est. speed input: 165.69 toks/s, output: 31.82 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.54s/it, est. speed input: 165.69 toks/s, output: 31.82 toks/s]
[2025-03-21 18:42:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.10s/it, est. speed input: 205.37 toks/s, output: 31.60 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.10s/it, est. speed input: 205.37 toks/s, output: 31.60 toks/s]
[2025-03-21 18:42:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.43s/it, est. speed input: 82.56 toks/s, output: 32.58 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.43s/it, est. speed input: 82.56 toks/s, output: 32.58 toks/s]
[2025-03-21 18:43:13] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.08s/it, est. speed input: 842.17 toks/s, output: 26.98 toks/s]Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.08s/it, est. speed input: 842.17 toks/s, output: 26.98 toks/s]
[2025-03-21 18:43:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.96s/it, est. speed input: 159.49 toks/s, output: 32.09 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.96s/it, est. speed input: 159.49 toks/s, output: 32.09 toks/s]
[2025-03-21 18:43:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.87s/it, est. speed input: 108.44 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.87s/it, est. speed input: 108.44 toks/s, output: 32.30 toks/s]
[2025-03-21 18:44:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.23s/it, est. speed input: 130.94 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.23s/it, est. speed input: 130.94 toks/s, output: 32.22 toks/s]
[2025-03-21 18:44:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.12s/it, est. speed input: 149.81 toks/s, output: 32.05 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.12s/it, est. speed input: 149.81 toks/s, output: 32.05 toks/s]
[2025-03-21 18:44:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it, est. speed input: 1665.79 toks/s, output: 21.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it, est. speed input: 1665.79 toks/s, output: 21.33 toks/s]
[2025-03-21 18:44:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.59s/it, est. speed input: 156.53 toks/s, output: 32.07 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.59s/it, est. speed input: 156.53 toks/s, output: 32.07 toks/s]
[2025-03-21 18:45:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.29s/it, est. speed input: 217.39 toks/s, output: 31.54 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.29s/it, est. speed input: 217.39 toks/s, output: 31.54 toks/s]
[2025-03-21 18:45:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.75s/it, est. speed input: 230.61 toks/s, output: 31.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.75s/it, est. speed input: 230.61 toks/s, output: 31.28 toks/s]
[2025-03-21 18:45:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.50s/it, est. speed input: 105.79 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.50s/it, est. speed input: 105.79 toks/s, output: 32.35 toks/s]
[2025-03-21 18:45:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it, est. speed input: 1926.06 toks/s, output: 17.85 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it, est. speed input: 1926.06 toks/s, output: 17.85 toks/s]
[2025-03-21 18:45:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.16s/it, est. speed input: 135.79 toks/s, output: 32.14 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.16s/it, est. speed input: 135.79 toks/s, output: 32.14 toks/s]
[2025-03-21 18:46:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.63s/it, est. speed input: 94.45 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 94.45 toks/s, output: 32.37 toks/s]
[2025-03-21 18:46:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.37s/it, est. speed input: 80.49 toks/s, output: 32.64 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.37s/it, est. speed input: 80.49 toks/s, output: 32.64 toks/s]
[2025-03-21 18:47:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.99s/it, est. speed input: 221.01 toks/s, output: 31.50 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.99s/it, est. speed input: 221.01 toks/s, output: 31.50 toks/s]
[2025-03-21 18:47:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.48s/it, est. speed input: 83.14 toks/s, output: 32.53 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.48s/it, est. speed input: 83.14 toks/s, output: 32.53 toks/s]
[2025-03-21 18:48:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it, est. speed input: 1955.74 toks/s, output: 17.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it, est. speed input: 1955.74 toks/s, output: 17.42 toks/s]
[2025-03-21 18:48:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.84s/it, est. speed input: 236.26 toks/s, output: 31.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.84s/it, est. speed input: 236.26 toks/s, output: 31.31 toks/s]
[2025-03-21 18:48:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.14s/it, est. speed input: 830.55 toks/s, output: 27.07 toks/s]Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.14s/it, est. speed input: 830.55 toks/s, output: 27.07 toks/s]
[2025-03-21 18:48:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.63s/it, est. speed input: 95.09 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.63s/it, est. speed input: 95.09 toks/s, output: 32.37 toks/s]
[2025-03-21 18:49:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.74s/it, est. speed input: 189.53 toks/s, output: 31.83 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.74s/it, est. speed input: 189.53 toks/s, output: 31.83 toks/s]
[2025-03-21 18:49:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.18s/it, est. speed input: 114.96 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.18s/it, est. speed input: 114.96 toks/s, output: 32.30 toks/s]
[2025-03-21 18:49:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 97.11 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 97.11 toks/s, output: 32.31 toks/s]
[2025-03-21 18:50:13] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.42s/it, est. speed input: 201.05 toks/s, output: 31.66 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.42s/it, est. speed input: 201.05 toks/s, output: 31.66 toks/s]
[2025-03-21 18:50:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.06s/it, est. speed input: 101.81 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.06s/it, est. speed input: 101.81 toks/s, output: 32.41 toks/s]
[2025-03-21 18:50:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.39s/it, est. speed input: 1090.87 toks/s, output: 25.11 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.39s/it, est. speed input: 1090.87 toks/s, output: 25.11 toks/s]
[2025-03-21 18:50:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.38s/it, est. speed input: 123.20 toks/s, output: 32.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.38s/it, est. speed input: 123.20 toks/s, output: 32.16 toks/s]
[2025-03-21 18:51:21] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 96.68 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 96.68 toks/s, output: 32.30 toks/s]
[2025-03-21 18:51:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.46s/it, est. speed input: 111.42 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.46s/it, est. speed input: 111.42 toks/s, output: 32.32 toks/s]
[2025-03-21 18:52:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it, est. speed input: 160.53 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it, est. speed input: 160.53 toks/s, output: 32.06 toks/s]
[2025-03-21 18:52:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.09s/it, est. speed input: 105.08 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.09s/it, est. speed input: 105.08 toks/s, output: 32.38 toks/s]
[2025-03-21 18:53:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
level2 Generation Success

--- Testing level3
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 89.21 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 89.21 toks/s, output: 32.44 toks/s]
[2025-03-21 18:53:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.04s/it, est. speed input: 178.00 toks/s, output: 31.81 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.04s/it, est. speed input: 178.00 toks/s, output: 31.81 toks/s]
[2025-03-21 18:53:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.05s/it, est. speed input: 124.42 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.05s/it, est. speed input: 124.42 toks/s, output: 32.23 toks/s]
[2025-03-21 18:54:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.35s/it, est. speed input: 103.21 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.35s/it, est. speed input: 103.21 toks/s, output: 32.30 toks/s]
[2025-03-21 18:54:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 97.55 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 97.55 toks/s, output: 32.23 toks/s]
[2025-03-21 18:55:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 95.12 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 95.12 toks/s, output: 32.35 toks/s]
[2025-03-21 18:55:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.66s/it, est. speed input: 120.13 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.66s/it, est. speed input: 120.13 toks/s, output: 32.20 toks/s]
[2025-03-21 18:56:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.13s/it, est. speed input: 121.00 toks/s, output: 32.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.13s/it, est. speed input: 121.00 toks/s, output: 32.16 toks/s]
[2025-03-21 18:56:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.39s/it, est. speed input: 111.47 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.39s/it, est. speed input: 111.47 toks/s, output: 32.24 toks/s]
[2025-03-21 18:57:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.88s/it, est. speed input: 132.05 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.88s/it, est. speed input: 132.05 toks/s, output: 32.18 toks/s]
[2025-03-21 18:57:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.04s/it, est. speed input: 114.90 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.04s/it, est. speed input: 114.90 toks/s, output: 32.26 toks/s]
[2025-03-21 18:57:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.61s/it, est. speed input: 109.09 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.61s/it, est. speed input: 109.09 toks/s, output: 32.32 toks/s]
[2025-03-21 18:58:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 99.84 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 99.84 toks/s, output: 32.27 toks/s]
[2025-03-21 18:58:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.21s/it, est. speed input: 174.06 toks/s, output: 31.75 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.21s/it, est. speed input: 174.06 toks/s, output: 31.75 toks/s]
[2025-03-21 18:59:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.71s/it, est. speed input: 212.88 toks/s, output: 31.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.71s/it, est. speed input: 212.88 toks/s, output: 31.47 toks/s]
[2025-03-21 18:59:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.35s/it, est. speed input: 116.03 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.36s/it, est. speed input: 116.03 toks/s, output: 32.17 toks/s]
[2025-03-21 18:59:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.23s/it, est. speed input: 119.91 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.23s/it, est. speed input: 119.91 toks/s, output: 32.29 toks/s]
[2025-03-21 19:00:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.39s/it, est. speed input: 101.72 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.39s/it, est. speed input: 101.72 toks/s, output: 32.40 toks/s]
[2025-03-21 19:00:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.48s/it, est. speed input: 84.45 toks/s, output: 32.52 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.48s/it, est. speed input: 84.45 toks/s, output: 32.52 toks/s]
[2025-03-21 19:01:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.04s/it, est. speed input: 165.86 toks/s, output: 31.93 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.04s/it, est. speed input: 165.86 toks/s, output: 31.93 toks/s]
[2025-03-21 19:01:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it, est. speed input: 973.35 toks/s, output: 25.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it, est. speed input: 973.35 toks/s, output: 25.39 toks/s]
[2025-03-21 19:01:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.11s/it, est. speed input: 219.74 toks/s, output: 31.53 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.11s/it, est. speed input: 219.74 toks/s, output: 31.53 toks/s]
[2025-03-21 19:01:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.06s/it, est. speed input: 91.98 toks/s, output: 32.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.06s/it, est. speed input: 91.98 toks/s, output: 32.42 toks/s]
[2025-03-21 19:02:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 84.40 toks/s, output: 32.50 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 84.40 toks/s, output: 32.50 toks/s]
[2025-03-21 19:02:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.38s/it, est. speed input: 78.84 toks/s, output: 32.63 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.38s/it, est. speed input: 78.84 toks/s, output: 32.63 toks/s]
[2025-03-21 19:03:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.42s/it, est. speed input: 112.69 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.42s/it, est. speed input: 112.69 toks/s, output: 32.39 toks/s]
[2025-03-21 19:03:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 17.00s/it, est. speed input: 147.06 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 17.00s/it, est. speed input: 147.06 toks/s, output: 32.24 toks/s]
[2025-03-21 19:04:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.31s/it, est. speed input: 79.71 toks/s, output: 32.70 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.31s/it, est. speed input: 79.71 toks/s, output: 32.70 toks/s]
[2025-03-21 19:04:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.36s/it, est. speed input: 79.54 toks/s, output: 32.66 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.36s/it, est. speed input: 79.54 toks/s, output: 32.66 toks/s]
[2025-03-21 19:05:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 95.58 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 95.58 toks/s, output: 32.33 toks/s]
[2025-03-21 19:05:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 94.55 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 94.55 toks/s, output: 32.37 toks/s]
[2025-03-21 19:06:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 94.75 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 94.75 toks/s, output: 32.28 toks/s]
[2025-03-21 19:06:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.70s/it, est. speed input: 104.59 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.70s/it, est. speed input: 104.59 toks/s, output: 32.23 toks/s]
[2025-03-21 19:07:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.53s/it, est. speed input: 152.47 toks/s, output: 31.90 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.53s/it, est. speed input: 152.47 toks/s, output: 31.90 toks/s]
[2025-03-21 19:07:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 94.38 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 94.38 toks/s, output: 32.30 toks/s]
[2025-03-21 19:08:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.55s/it, est. speed input: 109.89 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.55s/it, est. speed input: 109.89 toks/s, output: 32.19 toks/s]
[2025-03-21 19:08:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.81s/it, est. speed input: 88.91 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.81s/it, est. speed input: 88.91 toks/s, output: 32.44 toks/s]
[2025-03-21 19:09:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.19s/it, est. speed input: 149.18 toks/s, output: 31.95 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.19s/it, est. speed input: 149.18 toks/s, output: 31.95 toks/s]
[2025-03-21 19:09:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 89.94 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 89.94 toks/s, output: 32.36 toks/s]
[2025-03-21 19:09:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 85.48 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 85.48 toks/s, output: 32.47 toks/s]
[2025-03-21 19:10:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.56s/it, est. speed input: 105.68 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.56s/it, est. speed input: 105.68 toks/s, output: 32.34 toks/s]
[2025-03-21 19:10:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 87.90 toks/s, output: 32.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 87.90 toks/s, output: 32.48 toks/s]
[2025-03-21 19:11:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.68s/it, est. speed input: 111.02 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.68s/it, est. speed input: 111.02 toks/s, output: 32.20 toks/s]
[2025-03-21 19:11:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.91s/it, est. speed input: 98.63 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.91s/it, est. speed input: 98.63 toks/s, output: 32.35 toks/s]
[2025-03-21 19:12:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.25s/it, est. speed input: 164.50 toks/s, output: 31.84 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.25s/it, est. speed input: 164.50 toks/s, output: 31.84 toks/s]
[2025-03-21 19:12:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.72s/it, est. speed input: 107.90 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.72s/it, est. speed input: 107.90 toks/s, output: 32.45 toks/s]
[2025-03-21 19:13:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 93.80 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 93.80 toks/s, output: 32.38 toks/s]
[2025-03-21 19:13:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 86.12 toks/s, output: 32.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 86.12 toks/s, output: 32.48 toks/s]
[2025-03-21 19:14:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.83s/it, est. speed input: 151.53 toks/s, output: 32.02 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.83s/it, est. speed input: 151.53 toks/s, output: 32.02 toks/s]
[2025-03-21 19:14:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 86.69 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 86.69 toks/s, output: 32.47 toks/s]
[2025-03-21 19:15:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 90.93 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 90.93 toks/s, output: 32.41 toks/s]
[2025-03-21 19:15:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 91.01 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 91.01 toks/s, output: 32.41 toks/s]
[2025-03-21 19:16:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.33s/it, est. speed input: 118.20 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.33s/it, est. speed input: 118.20 toks/s, output: 32.30 toks/s]
[2025-03-21 19:16:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.53s/it, est. speed input: 174.38 toks/s, output: 31.72 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.53s/it, est. speed input: 174.38 toks/s, output: 31.72 toks/s]
[2025-03-21 19:16:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 85.96 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 85.96 toks/s, output: 32.40 toks/s]
[2025-03-21 19:17:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.96s/it, est. speed input: 144.44 toks/s, output: 31.92 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.96s/it, est. speed input: 144.44 toks/s, output: 31.92 toks/s]
[2025-03-21 19:17:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.47s/it, est. speed input: 106.26 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.47s/it, est. speed input: 106.26 toks/s, output: 32.28 toks/s]
[2025-03-21 19:18:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.81s/it, est. speed input: 124.85 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.81s/it, est. speed input: 124.85 toks/s, output: 32.08 toks/s]
[2025-03-21 19:18:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.86s/it, est. speed input: 195.31 toks/s, output: 33.10 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.86s/it, est. speed input: 195.31 toks/s, output: 33.10 toks/s]
[2025-03-21 19:18:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.48s/it, est. speed input: 327.47 toks/s, output: 30.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.48s/it, est. speed input: 327.47 toks/s, output: 30.49 toks/s]
[2025-03-21 19:19:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.31s/it, est. speed input: 129.95 toks/s, output: 32.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.31s/it, est. speed input: 129.95 toks/s, output: 32.00 toks/s]
[2025-03-21 19:19:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.23s/it, est. speed input: 117.33 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.23s/it, est. speed input: 117.33 toks/s, output: 32.22 toks/s]
[2025-03-21 19:19:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.30s/it, est. speed input: 127.01 toks/s, output: 32.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.30s/it, est. speed input: 127.01 toks/s, output: 32.15 toks/s]
[2025-03-21 19:20:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.14s/it, est. speed input: 115.19 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.14s/it, est. speed input: 115.19 toks/s, output: 32.21 toks/s]
[2025-03-21 19:20:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 92.34 toks/s, output: 32.43 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 92.34 toks/s, output: 32.43 toks/s]
[2025-03-21 19:21:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 97.33 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 97.33 toks/s, output: 32.32 toks/s]
[2025-03-21 19:21:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.79s/it, est. speed input: 114.75 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.79s/it, est. speed input: 114.75 toks/s, output: 32.28 toks/s]
[2025-03-21 19:22:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.32s/it, est. speed input: 260.75 toks/s, output: 31.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.32s/it, est. speed input: 260.75 toks/s, output: 31.19 toks/s]
[2025-03-21 19:22:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it, est. speed input: 2470.78 toks/s, output: 14.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it, est. speed input: 2470.78 toks/s, output: 14.35 toks/s]
[2025-03-21 19:22:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 89.69 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 89.69 toks/s, output: 32.45 toks/s]
[2025-03-21 19:22:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 92.40 toks/s, output: 32.43 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 92.40 toks/s, output: 32.43 toks/s]
[2025-03-21 19:23:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.09s/it, est. speed input: 150.58 toks/s, output: 32.01 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.09s/it, est. speed input: 150.58 toks/s, output: 32.01 toks/s]
[2025-03-21 19:23:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.39s/it, est. speed input: 122.01 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.39s/it, est. speed input: 122.01 toks/s, output: 32.18 toks/s]
[2025-03-21 19:24:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.72s/it, est. speed input: 123.34 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.72s/it, est. speed input: 123.34 toks/s, output: 32.21 toks/s]
[2025-03-21 19:24:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.94s/it, est. speed input: 100.60 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.94s/it, est. speed input: 100.60 toks/s, output: 32.38 toks/s]
[2025-03-21 19:25:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 89.49 toks/s, output: 32.43 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 89.49 toks/s, output: 32.43 toks/s]
[2025-03-21 19:25:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.58s/it, est. speed input: 136.95 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.58s/it, est. speed input: 136.95 toks/s, output: 32.23 toks/s]
[2025-03-21 19:25:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.00s/it, est. speed input: 150.39 toks/s, output: 32.05 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.00s/it, est. speed input: 150.39 toks/s, output: 32.05 toks/s]
[2025-03-21 19:26:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 97.16 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 97.16 toks/s, output: 32.31 toks/s]
[2025-03-21 19:26:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.15s/it, est. speed input: 124.26 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.15s/it, est. speed input: 124.26 toks/s, output: 32.35 toks/s]
[2025-03-21 19:27:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 80.18 toks/s, output: 32.61 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 80.18 toks/s, output: 32.61 toks/s]
[2025-03-21 19:27:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.93s/it, est. speed input: 81.40 toks/s, output: 33.10 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.93s/it, est. speed input: 81.40 toks/s, output: 33.10 toks/s]
[2025-03-21 19:28:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.86s/it, est. speed input: 186.14 toks/s, output: 31.90 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.86s/it, est. speed input: 186.14 toks/s, output: 31.90 toks/s]
[2025-03-21 19:28:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.83s/it, est. speed input: 108.03 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.83s/it, est. speed input: 108.03 toks/s, output: 32.27 toks/s]
[2025-03-21 19:28:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 94.82 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 94.82 toks/s, output: 32.31 toks/s]
[2025-03-21 19:29:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.37s/it, est. speed input: 90.75 toks/s, output: 32.59 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.37s/it, est. speed input: 90.75 toks/s, output: 32.59 toks/s]
[2025-03-21 19:29:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 96.71 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 96.71 toks/s, output: 32.30 toks/s]
[2025-03-21 19:30:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.14s/it, est. speed input: 127.32 toks/s, output: 32.07 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.14s/it, est. speed input: 127.32 toks/s, output: 32.07 toks/s]
[2025-03-21 19:30:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.12s/it, est. speed input: 252.43 toks/s, output: 31.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.12s/it, est. speed input: 252.43 toks/s, output: 31.33 toks/s]
[2025-03-21 19:31:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 81.48 toks/s, output: 32.61 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 81.48 toks/s, output: 32.61 toks/s]
[2025-03-21 19:31:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.76s/it, est. speed input: 202.10 toks/s, output: 31.76 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.76s/it, est. speed input: 202.10 toks/s, output: 31.76 toks/s]
[2025-03-21 19:31:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 86.62 toks/s, output: 32.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 86.62 toks/s, output: 32.48 toks/s]
[2025-03-21 19:32:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.73s/it, est. speed input: 202.61 toks/s, output: 33.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.73s/it, est. speed input: 202.61 toks/s, output: 33.15 toks/s]
[2025-03-21 19:32:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.53s/it, est. speed input: 104.12 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.53s/it, est. speed input: 104.12 toks/s, output: 32.25 toks/s]
[2025-03-21 19:33:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.78s/it, est. speed input: 111.57 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.78s/it, est. speed input: 111.57 toks/s, output: 32.28 toks/s]
[2025-03-21 19:33:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.56s/it, est. speed input: 102.68 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.56s/it, est. speed input: 102.68 toks/s, output: 32.26 toks/s]
[2025-03-21 19:33:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.63s/it, est. speed input: 95.05 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.63s/it, est. speed input: 95.05 toks/s, output: 32.37 toks/s]
[2025-03-21 19:34:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 98.17 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 98.17 toks/s, output: 32.30 toks/s]
[2025-03-21 19:35:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.64s/it, est. speed input: 88.46 toks/s, output: 32.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.64s/it, est. speed input: 88.46 toks/s, output: 32.48 toks/s]
[2025-03-21 19:35:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 87.29 toks/s, output: 32.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 87.29 toks/s, output: 32.51 toks/s]
level3 Generation Success

Total testing execution time: 7142.63 seconds
finished
INFO 03-21 19:36:18 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot.py:30: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot.py:42: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
Model Name:  Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8
Runnig on Parallel - Loading tokenizer...
Loading model across multiple GPUs...
INFO 03-21 19:36:28 [config.py:583] This model supports multiple tasks: {'score', 'classify', 'generate', 'embed', 'reward'}. Defaulting to 'generate'.
INFO 03-21 19:36:29 [gptq_marlin.py:143] The model is convertible to gptq_marlin during runtime. Using gptq_marlin kernel.
INFO 03-21 19:36:29 [config.py:1515] Defaulting to use mp for distributed inference
INFO 03-21 19:36:29 [config.py:1693] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 03-21 19:36:35 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot.py:30: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot.py:42: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
[2025-03-21 19:36:38] INFO loader.py:87: Loading faiss with AVX512 support.
[2025-03-21 19:36:38] INFO loader.py:92: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-03-21 19:36:38] INFO loader.py:99: Loading faiss with AVX2 support.
[2025-03-21 19:36:38] INFO loader.py:104: Could not load library with AVX2 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx2'")
[2025-03-21 19:36:38] INFO loader.py:110: Loading faiss.
[2025-03-21 19:36:38] INFO loader.py:112: Successfully loaded faiss.
INFO 03-21 19:36:38 [core.py:53] Initializing a V1 LLM engine (v0.8.1) with config: model='Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8', speculative_config=None, tokenizer='Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=gptq_marlin, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 03-21 19:36:38 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 64 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 03-21 19:36:38 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1], buffer_handle=(2, 10485760, 10, 'psm_26f396c0'), local_subscribe_addr='ipc:///tmp/bb62f025-7d1e-402f-9c09-40cfb8a6b60e', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-21 19:36:44 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot.py:30: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot.py:42: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
[2025-03-21 19:36:46] INFO loader.py:87: Loading faiss with AVX512 support.
[2025-03-21 19:36:46] INFO loader.py:92: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-03-21 19:36:46] INFO loader.py:99: Loading faiss with AVX2 support.
[2025-03-21 19:36:46] INFO loader.py:104: Could not load library with AVX2 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx2'")
[2025-03-21 19:36:46] INFO loader.py:110: Loading faiss.
[2025-03-21 19:36:46] INFO loader.py:112: Successfully loaded faiss.
WARNING 03-21 19:36:46 [utils.py:2282] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x77e83f1173e0>
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:36:46 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a00bc9f2'), local_subscribe_addr='ipc:///tmp/51eee6ff-4197-4009-8136-8bcf5d0680da', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-21 19:36:52 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot.py:30: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot.py:42: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
[2025-03-21 19:36:55] INFO loader.py:87: Loading faiss with AVX512 support.
[2025-03-21 19:36:55] INFO loader.py:92: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-03-21 19:36:55] INFO loader.py:99: Loading faiss with AVX2 support.
[2025-03-21 19:36:55] INFO loader.py:104: Could not load library with AVX2 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx2'")
[2025-03-21 19:36:55] INFO loader.py:110: Loading faiss.
[2025-03-21 19:36:55] INFO loader.py:112: Successfully loaded faiss.
WARNING 03-21 19:36:55 [utils.py:2282] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x77cd80c868a0>
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:36:55 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_d9504d6a'), local_subscribe_addr='ipc:///tmp/96bc76cc-5cca-4e5a-9344-4244dc2ab0f5', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:36:56 [utils.py:925] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:36:56 [utils.py:925] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:36:56 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:36:56 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:36:56 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/UNT/ae0589/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m WARNING 03-21 19:36:56 [custom_all_reduce.py:146] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:36:56 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/UNT/ae0589/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m WARNING 03-21 19:36:56 [custom_all_reduce.py:146] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:36:56 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_c775c0cc'), local_subscribe_addr='ipc:///tmp/4f3bf644-d873-4960-af00-f44e99dd4ad7', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:36:56 [parallel_state.py:967] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:36:56 [cuda.py:215] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:36:56 [parallel_state.py:967] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:36:56 [cuda.py:215] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:36:56 [gpu_model_runner.py:1164] Starting to load model Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8...
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:36:56 [gptq_marlin.py:235] Using MarlinLinearKernel for GPTQMarlinLinearMethod
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:36:56 [gpu_model_runner.py:1164] Starting to load model Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8...
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:36:56 [gptq_marlin.py:235] Using MarlinLinearKernel for GPTQMarlinLinearMethod
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m WARNING 03-21 19:36:57 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m WARNING 03-21 19:36:57 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:36:57 [weight_utils.py:257] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:36:57 [weight_utils.py:257] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/9 [00:00<?, ?it/s]
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m Loading safetensors checkpoint shards:  11% Completed | 1/9 [00:01<00:10,  1.28s/it]
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m Loading safetensors checkpoint shards:  22% Completed | 2/9 [00:02<00:09,  1.33s/it]
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m Loading safetensors checkpoint shards:  33% Completed | 3/9 [00:03<00:08,  1.34s/it]
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m Loading safetensors checkpoint shards:  44% Completed | 4/9 [00:04<00:05,  1.12s/it]
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m Loading safetensors checkpoint shards:  56% Completed | 5/9 [00:05<00:04,  1.05s/it]
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m Loading safetensors checkpoint shards:  67% Completed | 6/9 [00:07<00:03,  1.15s/it]
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m Loading safetensors checkpoint shards:  78% Completed | 7/9 [00:08<00:02,  1.22s/it]
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:37:07 [loader.py:429] Loading weights took 9.95 seconds
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m Loading safetensors checkpoint shards:  89% Completed | 8/9 [00:09<00:01,  1.27s/it]
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:37:07 [gpu_model_runner.py:1176] Model loading took 16.3608 GB and 10.669561 seconds
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m Loading safetensors checkpoint shards: 100% Completed | 9/9 [00:11<00:00,  1.29s/it]
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m Loading safetensors checkpoint shards: 100% Completed | 9/9 [00:11<00:00,  1.23s/it]
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m 
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:37:08 [loader.py:429] Loading weights took 11.20 seconds
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:37:09 [gpu_model_runner.py:1176] Model loading took 16.3608 GB and 12.283572 seconds
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:37:33 [backends.py:409] Using cache directory: /home/UNT/ae0589/.cache/vllm/torch_compile_cache/b66d6f0d9f/rank_0_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:37:33 [backends.py:419] Dynamo bytecode transform time: 24.63 s
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:37:34 [backends.py:409] Using cache directory: /home/UNT/ae0589/.cache/vllm/torch_compile_cache/b66d6f0d9f/rank_1_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:37:34 [backends.py:419] Dynamo bytecode transform time: 25.37 s
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:37:36 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:37:36 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:37:58 [monitor.py:33] torch.compile takes 24.63 s in total
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:37:58 [monitor.py:33] torch.compile takes 25.37 s in total
INFO 03-21 19:38:00 [kv_cache_utils.py:537] GPU KV cache size: 139,664 tokens
INFO 03-21 19:38:00 [kv_cache_utils.py:540] Maximum concurrency for 32,768 tokens per request: 4.26x
INFO 03-21 19:38:00 [kv_cache_utils.py:537] GPU KV cache size: 139,664 tokens
INFO 03-21 19:38:00 [kv_cache_utils.py:540] Maximum concurrency for 32,768 tokens per request: 4.26x
[1;36m(VllmWorker rank=1 pid=1481453)[0;0m INFO 03-21 19:38:42 [gpu_model_runner.py:1499] Graph capturing finished in 42 secs, took 2.28 GiB
[1;36m(VllmWorker rank=0 pid=1481435)[0;0m INFO 03-21 19:38:42 [gpu_model_runner.py:1499] Graph capturing finished in 42 secs, took 2.28 GiB
INFO 03-21 19:38:43 [core.py:138] init engine (profile, create kv cache, warmup model) took 93.92 seconds
[2025-03-21 19:38:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
------------Qwen model loaded across GPUs.------------

--- Testing level1
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.37s/it, est. speed input: 119.09 toks/s, output: 31.91 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.37s/it, est. speed input: 119.09 toks/s, output: 31.91 toks/s]
[2025-03-21 19:39:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.57s/it, est. speed input: 206.12 toks/s, output: 31.75 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.57s/it, est. speed input: 206.12 toks/s, output: 31.75 toks/s]
[2025-03-21 19:39:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.68s/it, est. speed input: 111.71 toks/s, output: 32.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.68s/it, est. speed input: 111.71 toks/s, output: 32.49 toks/s]
[2025-03-21 19:39:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.43s/it, est. speed input: 98.94 toks/s, output: 32.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.43s/it, est. speed input: 98.94 toks/s, output: 32.56 toks/s]
[2025-03-21 19:40:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.20s/it, est. speed input: 131.38 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.20s/it, est. speed input: 131.38 toks/s, output: 32.35 toks/s]
[2025-03-21 19:40:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.02s/it, est. speed input: 183.85 toks/s, output: 31.67 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.02s/it, est. speed input: 183.85 toks/s, output: 31.67 toks/s]
[2025-03-21 19:40:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.78s/it, est. speed input: 105.72 toks/s, output: 32.10 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.78s/it, est. speed input: 105.72 toks/s, output: 32.10 toks/s]
[2025-03-21 19:41:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.69s/it, est. speed input: 159.00 toks/s, output: 31.79 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.69s/it, est. speed input: 159.00 toks/s, output: 31.79 toks/s]
[2025-03-21 19:41:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 97.15 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 97.15 toks/s, output: 32.29 toks/s]
[2025-03-21 19:42:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.48s/it, est. speed input: 107.89 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.48s/it, est. speed input: 107.89 toks/s, output: 32.19 toks/s]
[2025-03-21 19:42:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.07s/it, est. speed input: 166.75 toks/s, output: 31.87 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.07s/it, est. speed input: 166.75 toks/s, output: 31.87 toks/s]
[2025-03-21 19:42:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.84s/it, est. speed input: 200.62 toks/s, output: 31.73 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.84s/it, est. speed input: 200.62 toks/s, output: 31.73 toks/s]
[2025-03-21 19:43:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.51s/it, est. speed input: 159.17 toks/s, output: 32.04 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.51s/it, est. speed input: 159.17 toks/s, output: 32.04 toks/s]
[2025-03-21 19:43:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.93s/it, est. speed input: 161.80 toks/s, output: 32.02 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.93s/it, est. speed input: 161.80 toks/s, output: 32.02 toks/s]
[2025-03-21 19:43:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.91s/it, est. speed input: 105.70 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.91s/it, est. speed input: 105.70 toks/s, output: 32.40 toks/s]
[2025-03-21 19:44:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 85.32 toks/s, output: 32.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 85.32 toks/s, output: 32.49 toks/s]
[2025-03-21 19:44:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.89s/it, est. speed input: 88.68 toks/s, output: 33.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.89s/it, est. speed input: 88.68 toks/s, output: 33.15 toks/s]
[2025-03-21 19:45:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.13s/it, est. speed input: 139.87 toks/s, output: 32.10 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.13s/it, est. speed input: 139.87 toks/s, output: 32.10 toks/s]
[2025-03-21 19:45:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.55s/it, est. speed input: 190.96 toks/s, output: 31.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.55s/it, est. speed input: 190.96 toks/s, output: 31.08 toks/s]
[2025-03-21 19:45:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.36s/it, est. speed input: 130.96 toks/s, output: 32.07 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.36s/it, est. speed input: 130.96 toks/s, output: 32.07 toks/s]
[2025-03-21 19:46:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.40s/it, est. speed input: 140.71 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.40s/it, est. speed input: 140.71 toks/s, output: 32.06 toks/s]
[2025-03-21 19:46:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.10s/it, est. speed input: 138.03 toks/s, output: 32.03 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.10s/it, est. speed input: 138.03 toks/s, output: 32.03 toks/s]
[2025-03-21 19:46:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 96.03 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 96.03 toks/s, output: 32.29 toks/s]
[2025-03-21 19:47:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 98.07 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 98.07 toks/s, output: 32.28 toks/s]
[2025-03-21 19:47:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it, est. speed input: 2383.21 toks/s, output: 16.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it, est. speed input: 2383.21 toks/s, output: 16.42 toks/s]
[2025-03-21 19:47:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.36s/it, est. speed input: 79.84 toks/s, output: 32.65 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.36s/it, est. speed input: 79.84 toks/s, output: 32.65 toks/s]
[2025-03-21 19:48:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.42s/it, est. speed input: 83.61 toks/s, output: 32.59 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.42s/it, est. speed input: 83.61 toks/s, output: 32.59 toks/s]
[2025-03-21 19:48:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.29s/it, est. speed input: 84.38 toks/s, output: 32.57 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.29s/it, est. speed input: 84.38 toks/s, output: 32.57 toks/s]
[2025-03-21 19:49:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.98s/it, est. speed input: 87.54 toks/s, output: 32.64 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.98s/it, est. speed input: 87.54 toks/s, output: 32.64 toks/s]
[2025-03-21 19:50:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 82.29 toks/s, output: 32.60 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 82.29 toks/s, output: 32.60 toks/s]
[2025-03-21 19:50:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.22s/it, est. speed input: 141.82 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.22s/it, est. speed input: 141.82 toks/s, output: 32.22 toks/s]
[2025-03-21 19:50:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.42s/it, est. speed input: 82.94 toks/s, output: 32.59 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.42s/it, est. speed input: 82.94 toks/s, output: 32.59 toks/s]
[2025-03-21 19:51:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.28s/it, est. speed input: 104.97 toks/s, output: 32.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.28s/it, est. speed input: 104.97 toks/s, output: 32.49 toks/s]
[2025-03-21 19:51:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.19s/it, est. speed input: 124.58 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.19s/it, est. speed input: 124.58 toks/s, output: 32.33 toks/s]
[2025-03-21 19:52:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.36s/it, est. speed input: 141.14 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.36s/it, est. speed input: 141.14 toks/s, output: 32.25 toks/s]
[2025-03-21 19:52:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.10s/it, est. speed input: 143.87 toks/s, output: 32.10 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.10s/it, est. speed input: 143.87 toks/s, output: 32.10 toks/s]
[2025-03-21 19:52:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.49s/it, est. speed input: 133.75 toks/s, output: 32.10 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.49s/it, est. speed input: 133.75 toks/s, output: 32.10 toks/s]
[2025-03-21 19:53:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.44s/it, est. speed input: 111.86 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.44s/it, est. speed input: 111.86 toks/s, output: 32.31 toks/s]
[2025-03-21 19:53:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.39s/it, est. speed input: 81.69 toks/s, output: 32.63 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.39s/it, est. speed input: 81.69 toks/s, output: 32.63 toks/s]
[2025-03-21 19:54:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.31s/it, est. speed input: 208.89 toks/s, output: 31.77 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.31s/it, est. speed input: 208.89 toks/s, output: 31.77 toks/s]
[2025-03-21 19:54:21] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it, est. speed input: 1994.29 toks/s, output: 19.05 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it, est. speed input: 1994.29 toks/s, output: 19.05 toks/s]
[2025-03-21 19:54:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.62s/it, est. speed input: 240.60 toks/s, output: 31.53 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.62s/it, est. speed input: 240.60 toks/s, output: 31.53 toks/s]
[2025-03-21 19:54:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.56s/it, est. speed input: 243.83 toks/s, output: 31.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.56s/it, est. speed input: 243.83 toks/s, output: 31.45 toks/s]
[2025-03-21 19:54:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.70s/it, est. speed input: 122.87 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.71s/it, est. speed input: 122.87 toks/s, output: 32.36 toks/s]
[2025-03-21 19:55:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.19s/it, est. speed input: 135.53 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.20s/it, est. speed input: 135.53 toks/s, output: 32.32 toks/s]
[2025-03-21 19:55:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.59s/it, est. speed input: 128.27 toks/s, output: 32.01 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.59s/it, est. speed input: 128.27 toks/s, output: 32.01 toks/s]
[2025-03-21 19:55:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.05s/it, est. speed input: 175.28 toks/s, output: 31.69 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.05s/it, est. speed input: 175.28 toks/s, output: 31.69 toks/s]
[2025-03-21 19:56:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 99.50 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 99.50 toks/s, output: 32.23 toks/s]
[2025-03-21 19:56:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.89s/it, est. speed input: 151.33 toks/s, output: 31.88 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.89s/it, est. speed input: 151.33 toks/s, output: 31.88 toks/s]
[2025-03-21 19:57:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 97.68 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 97.68 toks/s, output: 32.28 toks/s]
[2025-03-21 19:57:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.14s/it, est. speed input: 116.34 toks/s, output: 32.09 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.14s/it, est. speed input: 116.34 toks/s, output: 32.09 toks/s]
[2025-03-21 19:58:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.81s/it, est. speed input: 99.31 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.81s/it, est. speed input: 99.31 toks/s, output: 32.19 toks/s]
[2025-03-21 19:58:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.46s/it, est. speed input: 133.58 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.46s/it, est. speed input: 133.58 toks/s, output: 32.06 toks/s]
[2025-03-21 19:58:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.65s/it, est. speed input: 119.70 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.65s/it, est. speed input: 119.70 toks/s, output: 32.34 toks/s]
[2025-03-21 19:59:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.02s/it, est. speed input: 161.86 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.02s/it, est. speed input: 161.86 toks/s, output: 32.08 toks/s]
[2025-03-21 19:59:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.81s/it, est. speed input: 198.87 toks/s, output: 31.78 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.81s/it, est. speed input: 198.87 toks/s, output: 31.78 toks/s]
[2025-03-21 19:59:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.28s/it, est. speed input: 164.74 toks/s, output: 32.14 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.28s/it, est. speed input: 164.74 toks/s, output: 32.14 toks/s]
[2025-03-21 20:00:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.15s/it, est. speed input: 132.61 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.15s/it, est. speed input: 132.61 toks/s, output: 32.32 toks/s]
[2025-03-21 20:00:21] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 88.14 toks/s, output: 32.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 88.14 toks/s, output: 32.48 toks/s]
[2025-03-21 20:00:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.48s/it, est. speed input: 121.84 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.48s/it, est. speed input: 121.84 toks/s, output: 32.30 toks/s]
[2025-03-21 20:01:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 94.90 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 94.90 toks/s, output: 32.34 toks/s]
[2025-03-21 20:01:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.84s/it, est. speed input: 126.19 toks/s, output: 32.13 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.84s/it, est. speed input: 126.19 toks/s, output: 32.13 toks/s]
[2025-03-21 20:02:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.22s/it, est. speed input: 113.27 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.22s/it, est. speed input: 113.27 toks/s, output: 32.27 toks/s]
[2025-03-21 20:02:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 90.69 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 90.69 toks/s, output: 32.44 toks/s]
[2025-03-21 20:03:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.18s/it, est. speed input: 104.06 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.18s/it, est. speed input: 104.06 toks/s, output: 32.30 toks/s]
[2025-03-21 20:03:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.50s/it, est. speed input: 107.81 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.50s/it, est. speed input: 107.81 toks/s, output: 32.36 toks/s]
[2025-03-21 20:04:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 90.29 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 90.29 toks/s, output: 32.38 toks/s]
[2025-03-21 20:04:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.11s/it, est. speed input: 100.77 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.11s/it, est. speed input: 100.77 toks/s, output: 32.30 toks/s]
[2025-03-21 20:05:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.78s/it, est. speed input: 177.65 toks/s, output: 31.86 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.78s/it, est. speed input: 177.65 toks/s, output: 31.86 toks/s]
[2025-03-21 20:05:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.44s/it, est. speed input: 82.52 toks/s, output: 32.57 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.44s/it, est. speed input: 82.52 toks/s, output: 32.57 toks/s]
[2025-03-21 20:05:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.98s/it, est. speed input: 160.69 toks/s, output: 32.05 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.98s/it, est. speed input: 160.69 toks/s, output: 32.05 toks/s]
[2025-03-21 20:06:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 98.90 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 98.90 toks/s, output: 32.26 toks/s]
[2025-03-21 20:06:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.81s/it, est. speed input: 1098.29 toks/s, output: 24.55 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.81s/it, est. speed input: 1098.29 toks/s, output: 24.55 toks/s]
[2025-03-21 20:06:45] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.40s/it, est. speed input: 277.45 toks/s, output: 30.95 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.40s/it, est. speed input: 277.45 toks/s, output: 30.95 toks/s]
[2025-03-21 20:06:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 99.90 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 99.90 toks/s, output: 32.27 toks/s]
[2025-03-21 20:07:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.65s/it, est. speed input: 97.59 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.65s/it, est. speed input: 97.59 toks/s, output: 32.41 toks/s]
[2025-03-21 20:07:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.41s/it, est. speed input: 98.25 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.41s/it, est. speed input: 98.25 toks/s, output: 32.37 toks/s]
[2025-03-21 20:08:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 95.80 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 95.80 toks/s, output: 32.34 toks/s]
[2025-03-21 20:09:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 97.71 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 97.71 toks/s, output: 32.31 toks/s]
[2025-03-21 20:09:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 89.00 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 89.00 toks/s, output: 32.46 toks/s]
[2025-03-21 20:10:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.68s/it, est. speed input: 125.78 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.68s/it, est. speed input: 125.78 toks/s, output: 32.18 toks/s]
[2025-03-21 20:10:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.21s/it, est. speed input: 113.30 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.21s/it, est. speed input: 113.30 toks/s, output: 32.47 toks/s]
[2025-03-21 20:10:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.51s/it, est. speed input: 152.05 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.51s/it, est. speed input: 152.05 toks/s, output: 32.22 toks/s]
[2025-03-21 20:11:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 95.96 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 95.96 toks/s, output: 32.36 toks/s]
[2025-03-21 20:11:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.20s/it, est. speed input: 100.58 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.20s/it, est. speed input: 100.58 toks/s, output: 32.35 toks/s]
[2025-03-21 20:12:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.99s/it, est. speed input: 217.20 toks/s, output: 31.70 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.99s/it, est. speed input: 217.20 toks/s, output: 31.70 toks/s]
[2025-03-21 20:12:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 83.29 toks/s, output: 32.60 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 83.29 toks/s, output: 32.60 toks/s]
[2025-03-21 20:12:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it, est. speed input: 1783.17 toks/s, output: 20.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it, est. speed input: 1783.17 toks/s, output: 20.56 toks/s]
[2025-03-21 20:12:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.35s/it, est. speed input: 303.33 toks/s, output: 30.90 toks/s]Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.35s/it, est. speed input: 303.33 toks/s, output: 30.90 toks/s]
[2025-03-21 20:13:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.65s/it, est. speed input: 103.44 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.65s/it, est. speed input: 103.44 toks/s, output: 32.27 toks/s]
[2025-03-21 20:13:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.03s/it, est. speed input: 198.05 toks/s, output: 31.57 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.03s/it, est. speed input: 198.05 toks/s, output: 31.57 toks/s]
[2025-03-21 20:13:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.42s/it, est. speed input: 84.07 toks/s, output: 32.59 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.43s/it, est. speed input: 84.07 toks/s, output: 32.59 toks/s]
[2025-03-21 20:14:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.75s/it, est. speed input: 107.37 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.75s/it, est. speed input: 107.37 toks/s, output: 32.34 toks/s]
[2025-03-21 20:14:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 91.42 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 91.42 toks/s, output: 32.44 toks/s]
[2025-03-21 20:15:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.29s/it, est. speed input: 101.56 toks/s, output: 32.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.29s/it, est. speed input: 101.56 toks/s, output: 32.42 toks/s]
[2025-03-21 20:15:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.63s/it, est. speed input: 130.84 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.63s/it, est. speed input: 130.84 toks/s, output: 32.08 toks/s]
[2025-03-21 20:16:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 100.50 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 100.50 toks/s, output: 32.24 toks/s]
[2025-03-21 20:16:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.35s/it, est. speed input: 148.33 toks/s, output: 31.99 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.35s/it, est. speed input: 148.33 toks/s, output: 31.99 toks/s]
[2025-03-21 20:17:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 85.18 toks/s, output: 32.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 85.18 toks/s, output: 32.51 toks/s]
[2025-03-21 20:17:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 92.88 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 92.88 toks/s, output: 32.39 toks/s]
[2025-03-21 20:18:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
level1 Generation Success

--- Testing level2
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.01s/it, est. speed input: 102.14 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.01s/it, est. speed input: 102.14 toks/s, output: 32.34 toks/s]
[2025-03-21 20:18:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.47s/it, est. speed input: 96.09 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.47s/it, est. speed input: 96.09 toks/s, output: 32.40 toks/s]
[2025-03-21 20:19:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 87.24 toks/s, output: 32.52 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 87.24 toks/s, output: 32.52 toks/s]
[2025-03-21 20:19:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 99.59 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 99.59 toks/s, output: 32.27 toks/s]
[2025-03-21 20:20:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.85s/it, est. speed input: 169.54 toks/s, output: 31.88 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.85s/it, est. speed input: 169.54 toks/s, output: 31.88 toks/s]
[2025-03-21 20:20:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.67s/it, est. speed input: 99.75 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.67s/it, est. speed input: 99.75 toks/s, output: 32.44 toks/s]
[2025-03-21 20:20:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.48s/it, est. speed input: 103.00 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.48s/it, est. speed input: 103.00 toks/s, output: 32.36 toks/s]
[2025-03-21 20:21:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.65s/it, est. speed input: 115.53 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.66s/it, est. speed input: 115.53 toks/s, output: 32.24 toks/s]
[2025-03-21 20:21:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.95s/it, est. speed input: 98.38 toks/s, output: 32.05 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.95s/it, est. speed input: 98.38 toks/s, output: 32.05 toks/s]
[2025-03-21 20:22:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.36s/it, est. speed input: 123.68 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.36s/it, est. speed input: 123.68 toks/s, output: 32.18 toks/s]
[2025-03-21 20:22:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.89s/it, est. speed input: 120.55 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.89s/it, est. speed input: 120.55 toks/s, output: 32.27 toks/s]
[2025-03-21 20:23:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.77s/it, est. speed input: 124.07 toks/s, output: 32.10 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.77s/it, est. speed input: 124.07 toks/s, output: 32.10 toks/s]
[2025-03-21 20:23:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.60s/it, est. speed input: 95.04 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.60s/it, est. speed input: 95.04 toks/s, output: 32.40 toks/s]
[2025-03-21 20:24:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.23s/it, est. speed input: 129.11 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.23s/it, est. speed input: 129.11 toks/s, output: 32.08 toks/s]
[2025-03-21 20:24:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.28s/it, est. speed input: 93.10 toks/s, output: 31.73 toks/s]Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.28s/it, est. speed input: 93.10 toks/s, output: 31.73 toks/s]
[2025-03-21 20:25:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.88s/it, est. speed input: 116.99 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.88s/it, est. speed input: 116.99 toks/s, output: 32.25 toks/s]
[2025-03-21 20:25:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 85.27 toks/s, output: 32.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 85.27 toks/s, output: 32.51 toks/s]
[2025-03-21 20:25:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.81s/it, est. speed input: 113.81 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.81s/it, est. speed input: 113.81 toks/s, output: 32.27 toks/s]
[2025-03-21 20:26:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.20s/it, est. speed input: 158.81 toks/s, output: 31.98 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.20s/it, est. speed input: 158.81 toks/s, output: 31.98 toks/s]
[2025-03-21 20:26:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.63s/it, est. speed input: 94.47 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.63s/it, est. speed input: 94.47 toks/s, output: 32.38 toks/s]
[2025-03-21 20:27:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.19s/it, est. speed input: 142.63 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.19s/it, est. speed input: 142.63 toks/s, output: 32.22 toks/s]
[2025-03-21 20:27:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.93s/it, est. speed input: 165.86 toks/s, output: 32.02 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.93s/it, est. speed input: 165.86 toks/s, output: 32.02 toks/s]
[2025-03-21 20:27:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 88.15 toks/s, output: 32.52 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 88.15 toks/s, output: 32.52 toks/s]
[2025-03-21 20:28:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 89.05 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 89.05 toks/s, output: 32.46 toks/s]
[2025-03-21 20:28:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 90.24 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 90.24 toks/s, output: 32.45 toks/s]
[2025-03-21 20:29:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 94.81 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 94.81 toks/s, output: 32.35 toks/s]
[2025-03-21 20:29:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 83.10 toks/s, output: 32.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 83.10 toks/s, output: 32.56 toks/s]
[2025-03-21 20:30:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.60s/it, est. speed input: 100.29 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.60s/it, est. speed input: 100.29 toks/s, output: 32.34 toks/s]
[2025-03-21 20:30:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.44s/it, est. speed input: 83.19 toks/s, output: 32.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 83.19 toks/s, output: 32.56 toks/s]
[2025-03-21 20:31:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 86.45 toks/s, output: 32.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 86.45 toks/s, output: 32.49 toks/s]
[2025-03-21 20:32:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.34s/it, est. speed input: 80.15 toks/s, output: 32.67 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.34s/it, est. speed input: 80.15 toks/s, output: 32.67 toks/s]
[2025-03-21 20:32:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.60s/it, est. speed input: 201.05 toks/s, output: 31.54 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.60s/it, est. speed input: 201.05 toks/s, output: 31.54 toks/s]
[2025-03-21 20:32:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.33s/it, est. speed input: 97.46 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.33s/it, est. speed input: 97.46 toks/s, output: 32.39 toks/s]
[2025-03-21 20:33:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.39s/it, est. speed input: 118.40 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.39s/it, est. speed input: 118.40 toks/s, output: 32.26 toks/s]
[2025-03-21 20:33:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.17s/it, est. speed input: 145.13 toks/s, output: 31.97 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.18s/it, est. speed input: 145.13 toks/s, output: 31.97 toks/s]
[2025-03-21 20:34:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 87.08 toks/s, output: 32.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 87.08 toks/s, output: 32.51 toks/s]
[2025-03-21 20:34:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.18s/it, est. speed input: 110.66 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.18s/it, est. speed input: 110.66 toks/s, output: 32.36 toks/s]
[2025-03-21 20:35:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 26.00s/it, est. speed input: 107.40 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 26.00s/it, est. speed input: 107.40 toks/s, output: 32.39 toks/s]
[2025-03-21 20:35:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it, est. speed input: 2128.88 toks/s, output: 16.61 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it, est. speed input: 2128.88 toks/s, output: 16.61 toks/s]
[2025-03-21 20:35:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.83s/it, est. speed input: 214.08 toks/s, output: 31.43 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.83s/it, est. speed input: 214.08 toks/s, output: 31.43 toks/s]
[2025-03-21 20:35:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.11s/it, est. speed input: 120.53 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.11s/it, est. speed input: 120.53 toks/s, output: 32.32 toks/s]
[2025-03-21 20:36:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.34s/it, est. speed input: 80.38 toks/s, output: 32.67 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.34s/it, est. speed input: 80.38 toks/s, output: 32.67 toks/s]
[2025-03-21 20:36:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.93s/it, est. speed input: 121.54 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.93s/it, est. speed input: 121.54 toks/s, output: 32.17 toks/s]
[2025-03-21 20:37:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.20s/it, est. speed input: 97.89 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.20s/it, est. speed input: 97.89 toks/s, output: 32.31 toks/s]
[2025-03-21 20:37:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.17s/it, est. speed input: 114.22 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.17s/it, est. speed input: 114.22 toks/s, output: 32.36 toks/s]
[2025-03-21 20:38:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.28s/it, est. speed input: 135.34 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.28s/it, est. speed input: 135.34 toks/s, output: 32.21 toks/s]
[2025-03-21 20:38:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.82s/it, est. speed input: 173.72 toks/s, output: 31.99 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.82s/it, est. speed input: 173.72 toks/s, output: 31.99 toks/s]
[2025-03-21 20:38:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.47s/it, est. speed input: 84.31 toks/s, output: 32.54 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.47s/it, est. speed input: 84.31 toks/s, output: 32.54 toks/s]
[2025-03-21 20:39:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.51s/it, est. speed input: 138.00 toks/s, output: 32.13 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.51s/it, est. speed input: 138.00 toks/s, output: 32.13 toks/s]
[2025-03-21 20:39:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.14s/it, est. speed input: 133.46 toks/s, output: 32.12 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.14s/it, est. speed input: 133.46 toks/s, output: 32.12 toks/s]
[2025-03-21 20:39:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.99s/it, est. speed input: 91.34 toks/s, output: 32.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.99s/it, est. speed input: 91.34 toks/s, output: 32.42 toks/s]
[2025-03-21 20:40:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 85.93 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 85.93 toks/s, output: 32.46 toks/s]
[2025-03-21 20:40:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.25s/it, est. speed input: 190.05 toks/s, output: 31.93 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.25s/it, est. speed input: 190.05 toks/s, output: 31.93 toks/s]
[2025-03-21 20:41:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.69s/it, est. speed input: 130.62 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.69s/it, est. speed input: 130.62 toks/s, output: 32.25 toks/s]
[2025-03-21 20:41:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it, est. speed input: 1929.71 toks/s, output: 17.72 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it, est. speed input: 1929.71 toks/s, output: 17.72 toks/s]
[2025-03-21 20:41:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 84.79 toks/s, output: 32.50 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 84.79 toks/s, output: 32.50 toks/s]
[2025-03-21 20:42:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.47s/it, est. speed input: 82.70 toks/s, output: 32.54 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.47s/it, est. speed input: 82.70 toks/s, output: 32.54 toks/s]
[2025-03-21 20:42:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.33s/it, est. speed input: 175.39 toks/s, output: 31.76 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.33s/it, est. speed input: 175.39 toks/s, output: 31.76 toks/s]
[2025-03-21 20:42:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.04s/it, est. speed input: 144.38 toks/s, output: 32.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.04s/it, est. speed input: 144.38 toks/s, output: 32.15 toks/s]
[2025-03-21 20:43:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it, est. speed input: 2187.46 toks/s, output: 15.85 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it, est. speed input: 2187.46 toks/s, output: 15.85 toks/s]
[2025-03-21 20:43:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.91s/it, est. speed input: 114.20 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.91s/it, est. speed input: 114.20 toks/s, output: 32.29 toks/s]
[2025-03-21 20:43:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 86.21 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 86.21 toks/s, output: 32.46 toks/s]
[2025-03-21 20:44:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 97.87 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 97.87 toks/s, output: 32.26 toks/s]
[2025-03-21 20:44:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 97.29 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 97.29 toks/s, output: 32.26 toks/s]
[2025-03-21 20:45:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 94.15 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 94.15 toks/s, output: 32.30 toks/s]
[2025-03-21 20:45:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.12s/it, est. speed input: 117.17 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.12s/it, est. speed input: 117.17 toks/s, output: 32.08 toks/s]
[2025-03-21 20:46:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.72s/it, est. speed input: 241.57 toks/s, output: 31.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.72s/it, est. speed input: 241.57 toks/s, output: 31.22 toks/s]
[2025-03-21 20:46:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.03s/it, est. speed input: 141.38 toks/s, output: 32.05 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.03s/it, est. speed input: 141.38 toks/s, output: 32.05 toks/s]
[2025-03-21 20:46:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.95s/it, est. speed input: 186.08 toks/s, output: 31.84 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.95s/it, est. speed input: 186.08 toks/s, output: 31.84 toks/s]
[2025-03-21 20:46:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.46s/it, est. speed input: 82.35 toks/s, output: 32.55 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.46s/it, est. speed input: 82.35 toks/s, output: 32.55 toks/s]
[2025-03-21 20:47:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.10s/it, est. speed input: 158.12 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.10s/it, est. speed input: 158.12 toks/s, output: 32.06 toks/s]
[2025-03-21 20:47:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.24s/it, est. speed input: 131.03 toks/s, output: 32.10 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.24s/it, est. speed input: 131.03 toks/s, output: 32.10 toks/s]
[2025-03-21 20:48:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.79s/it, est. speed input: 188.02 toks/s, output: 31.79 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.79s/it, est. speed input: 188.02 toks/s, output: 31.79 toks/s]
[2025-03-21 20:48:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.89s/it, est. speed input: 1511.98 toks/s, output: 21.64 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.90s/it, est. speed input: 1511.98 toks/s, output: 21.64 toks/s]
[2025-03-21 20:48:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.38s/it, est. speed input: 79.64 toks/s, output: 32.63 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.38s/it, est. speed input: 79.64 toks/s, output: 32.63 toks/s]
[2025-03-21 20:48:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 87.31 toks/s, output: 32.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 87.31 toks/s, output: 32.48 toks/s]
[2025-03-21 20:49:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 91.44 toks/s, output: 32.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 91.44 toks/s, output: 32.42 toks/s]
[2025-03-21 20:50:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 99.85 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 99.85 toks/s, output: 32.25 toks/s]
[2025-03-21 20:50:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it, est. speed input: 1803.89 toks/s, output: 18.72 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it, est. speed input: 1803.89 toks/s, output: 18.72 toks/s]
[2025-03-21 20:50:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it, est. speed input: 2126.31 toks/s, output: 16.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it, est. speed input: 2126.31 toks/s, output: 16.31 toks/s]
[2025-03-21 20:50:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.61s/it, est. speed input: 139.42 toks/s, output: 32.13 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.61s/it, est. speed input: 139.42 toks/s, output: 32.13 toks/s]
[2025-03-21 20:50:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.55s/it, est. speed input: 145.41 toks/s, output: 32.02 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.55s/it, est. speed input: 145.41 toks/s, output: 32.02 toks/s]
[2025-03-21 20:51:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.14s/it, est. speed input: 147.28 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.14s/it, est. speed input: 147.28 toks/s, output: 32.26 toks/s]
[2025-03-21 20:51:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 90.84 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 90.84 toks/s, output: 32.41 toks/s]
[2025-03-21 20:52:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 83.22 toks/s, output: 32.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 83.22 toks/s, output: 32.56 toks/s]
[2025-03-21 20:52:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 85.44 toks/s, output: 32.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.53s/it, est. speed input: 85.44 toks/s, output: 32.48 toks/s]
[2025-03-21 20:53:13] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.49s/it, est. speed input: 110.32 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.49s/it, est. speed input: 110.32 toks/s, output: 32.23 toks/s]
[2025-03-21 20:53:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 82.92 toks/s, output: 32.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 82.92 toks/s, output: 32.56 toks/s]
[2025-03-21 20:54:13] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.95s/it, est. speed input: 215.63 toks/s, output: 31.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.95s/it, est. speed input: 215.63 toks/s, output: 31.47 toks/s]
[2025-03-21 20:54:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 88.55 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 88.55 toks/s, output: 32.47 toks/s]
[2025-03-21 20:54:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 88.15 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 88.15 toks/s, output: 32.47 toks/s]
[2025-03-21 20:55:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 97.02 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 97.02 toks/s, output: 32.28 toks/s]
[2025-03-21 20:56:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.88s/it, est. speed input: 169.95 toks/s, output: 31.86 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.88s/it, est. speed input: 169.95 toks/s, output: 31.86 toks/s]
[2025-03-21 20:56:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 87.42 toks/s, output: 32.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 87.42 toks/s, output: 32.49 toks/s]
[2025-03-21 20:56:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.20s/it, est. speed input: 171.55 toks/s, output: 31.98 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.20s/it, est. speed input: 171.55 toks/s, output: 31.98 toks/s]
[2025-03-21 20:57:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.15s/it, est. speed input: 96.41 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.15s/it, est. speed input: 96.41 toks/s, output: 32.20 toks/s]
[2025-03-21 20:57:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 97.28 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 97.28 toks/s, output: 32.28 toks/s]
[2025-03-21 20:58:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 89.62 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 89.62 toks/s, output: 32.35 toks/s]
[2025-03-21 20:58:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.99s/it, est. speed input: 164.18 toks/s, output: 31.96 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.99s/it, est. speed input: 164.18 toks/s, output: 31.96 toks/s]
[2025-03-21 20:59:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.40s/it, est. speed input: 149.05 toks/s, output: 32.07 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.40s/it, est. speed input: 149.05 toks/s, output: 32.07 toks/s]
[2025-03-21 20:59:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
level2 Generation Success

--- Testing level3
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.35s/it, est. speed input: 138.37 toks/s, output: 32.04 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.35s/it, est. speed input: 138.37 toks/s, output: 32.04 toks/s]
[2025-03-21 20:59:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 95.70 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 95.70 toks/s, output: 32.31 toks/s]
[2025-03-21 21:00:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.61s/it, est. speed input: 828.54 toks/s, output: 26.86 toks/s]Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.61s/it, est. speed input: 828.54 toks/s, output: 26.86 toks/s]
[2025-03-21 21:00:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.12s/it, est. speed input: 107.72 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.12s/it, est. speed input: 107.72 toks/s, output: 32.25 toks/s]
[2025-03-21 21:00:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 97.74 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 97.74 toks/s, output: 32.30 toks/s]
[2025-03-21 21:01:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.50s/it, est. speed input: 118.06 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.50s/it, est. speed input: 118.06 toks/s, output: 32.19 toks/s]
[2025-03-21 21:01:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it, est. speed input: 2134.42 toks/s, output: 16.57 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it, est. speed input: 2134.42 toks/s, output: 16.57 toks/s]
[2025-03-21 21:01:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.57s/it, est. speed input: 92.48 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 92.48 toks/s, output: 32.40 toks/s]
[2025-03-21 21:02:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 96.34 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 96.34 toks/s, output: 32.31 toks/s]
[2025-03-21 21:02:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.32s/it, est. speed input: 149.51 toks/s, output: 32.03 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.32s/it, est. speed input: 149.51 toks/s, output: 32.03 toks/s]
[2025-03-21 21:03:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 94.55 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 94.55 toks/s, output: 32.36 toks/s]
[2025-03-21 21:03:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.50s/it, est. speed input: 113.85 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.50s/it, est. speed input: 113.85 toks/s, output: 32.28 toks/s]
[2025-03-21 21:04:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 173.09 toks/s, output: 31.74 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 173.09 toks/s, output: 31.74 toks/s]
[2025-03-21 21:04:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.58s/it, est. speed input: 128.95 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.58s/it, est. speed input: 128.95 toks/s, output: 32.06 toks/s]
[2025-03-21 21:04:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 98.72 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 98.72 toks/s, output: 32.28 toks/s]
[2025-03-21 21:05:21] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.73s/it, est. speed input: 114.48 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.73s/it, est. speed input: 114.48 toks/s, output: 32.17 toks/s]
[2025-03-21 21:05:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 84.76 toks/s, output: 32.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.45s/it, est. speed input: 84.76 toks/s, output: 32.56 toks/s]
[2025-03-21 21:06:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.03s/it, est. speed input: 148.87 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.03s/it, est. speed input: 148.87 toks/s, output: 32.06 toks/s]
[2025-03-21 21:06:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.67s/it, est. speed input: 92.74 toks/s, output: 32.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.67s/it, est. speed input: 92.74 toks/s, output: 32.51 toks/s]
[2025-03-21 21:07:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.30s/it, est. speed input: 137.81 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.30s/it, est. speed input: 137.81 toks/s, output: 32.17 toks/s]
[2025-03-21 21:07:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.62s/it, est. speed input: 125.89 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.62s/it, est. speed input: 125.89 toks/s, output: 32.19 toks/s]
[2025-03-21 21:07:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it, est. speed input: 1759.44 toks/s, output: 19.83 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it, est. speed input: 1759.44 toks/s, output: 19.83 toks/s]
[2025-03-21 21:07:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.40s/it, est. speed input: 137.77 toks/s, output: 32.11 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.40s/it, est. speed input: 137.77 toks/s, output: 32.11 toks/s]
[2025-03-21 21:08:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.74s/it, est. speed input: 107.47 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.74s/it, est. speed input: 107.47 toks/s, output: 32.38 toks/s]
[2025-03-21 21:08:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.34s/it, est. speed input: 78.95 toks/s, output: 32.68 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.34s/it, est. speed input: 78.95 toks/s, output: 32.68 toks/s]
[2025-03-21 21:09:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s, est. speed input: 4404.57 toks/s, output: 1.74 toks/s]Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s, est. speed input: 4404.57 toks/s, output: 1.74 toks/s]
[2025-03-21 21:09:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.93s/it, est. speed input: 119.45 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.93s/it, est. speed input: 119.45 toks/s, output: 32.44 toks/s]
[2025-03-21 21:09:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.35s/it, est. speed input: 79.62 toks/s, output: 32.67 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.35s/it, est. speed input: 79.62 toks/s, output: 32.67 toks/s]
[2025-03-21 21:10:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.35s/it, est. speed input: 79.54 toks/s, output: 32.66 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.35s/it, est. speed input: 79.54 toks/s, output: 32.66 toks/s]
[2025-03-21 21:10:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.77s/it, est. speed input: 122.20 toks/s, output: 32.09 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.77s/it, est. speed input: 122.20 toks/s, output: 32.09 toks/s]
[2025-03-21 21:10:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.14s/it, est. speed input: 197.51 toks/s, output: 31.63 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.14s/it, est. speed input: 197.51 toks/s, output: 31.63 toks/s]
[2025-03-21 21:11:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 94.88 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 94.88 toks/s, output: 32.32 toks/s]
[2025-03-21 21:11:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.48s/it, est. speed input: 146.58 toks/s, output: 31.93 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.48s/it, est. speed input: 146.58 toks/s, output: 31.93 toks/s]
[2025-03-21 21:12:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.97s/it, est. speed input: 124.24 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.97s/it, est. speed input: 124.24 toks/s, output: 32.08 toks/s]
[2025-03-21 21:12:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 94.49 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 94.49 toks/s, output: 32.34 toks/s]
[2025-03-21 21:13:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 95.56 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 95.56 toks/s, output: 32.32 toks/s]
[2025-03-21 21:13:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.48s/it, est. speed input: 84.19 toks/s, output: 32.53 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.48s/it, est. speed input: 84.19 toks/s, output: 32.53 toks/s]
[2025-03-21 21:14:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 86.03 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 86.03 toks/s, output: 32.47 toks/s]
[2025-03-21 21:14:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.16s/it, est. speed input: 156.68 toks/s, output: 31.93 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.16s/it, est. speed input: 156.68 toks/s, output: 31.93 toks/s]
[2025-03-21 21:14:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.93s/it, est. speed input: 208.50 toks/s, output: 31.55 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.93s/it, est. speed input: 208.50 toks/s, output: 31.55 toks/s]
[2025-03-21 21:15:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.25s/it, est. speed input: 132.09 toks/s, output: 32.14 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.25s/it, est. speed input: 132.09 toks/s, output: 32.14 toks/s]
[2025-03-21 21:15:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 87.87 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 87.87 toks/s, output: 32.47 toks/s]
[2025-03-21 21:16:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 93.56 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 93.56 toks/s, output: 32.35 toks/s]
[2025-03-21 21:16:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.56s/it, est. speed input: 129.42 toks/s, output: 32.05 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.56s/it, est. speed input: 129.42 toks/s, output: 32.05 toks/s]
[2025-03-21 21:17:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.18s/it, est. speed input: 195.77 toks/s, output: 31.53 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.18s/it, est. speed input: 195.77 toks/s, output: 31.53 toks/s]
[2025-03-21 21:17:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.86s/it, est. speed input: 95.73 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.86s/it, est. speed input: 95.73 toks/s, output: 32.45 toks/s]
[2025-03-21 21:17:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.48s/it, est. speed input: 169.72 toks/s, output: 31.82 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.48s/it, est. speed input: 169.72 toks/s, output: 31.82 toks/s]
[2025-03-21 21:18:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 86.04 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 86.04 toks/s, output: 32.45 toks/s]
[2025-03-21 21:18:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.72s/it, est. speed input: 105.04 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.72s/it, est. speed input: 105.04 toks/s, output: 32.34 toks/s]
[2025-03-21 21:19:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.37s/it, est. speed input: 141.13 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.37s/it, est. speed input: 141.13 toks/s, output: 32.06 toks/s]
[2025-03-21 21:19:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 90.86 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 90.86 toks/s, output: 32.39 toks/s]
[2025-03-21 21:19:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.57s/it, est. speed input: 104.27 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.57s/it, est. speed input: 104.27 toks/s, output: 32.24 toks/s]
[2025-03-21 21:20:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.87s/it, est. speed input: 120.51 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.87s/it, est. speed input: 120.51 toks/s, output: 32.18 toks/s]
[2025-03-21 21:20:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.12s/it, est. speed input: 101.50 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.12s/it, est. speed input: 101.50 toks/s, output: 32.27 toks/s]
[2025-03-21 21:21:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.47s/it, est. speed input: 95.44 toks/s, output: 32.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.47s/it, est. speed input: 95.44 toks/s, output: 32.42 toks/s]
[2025-03-21 21:21:45] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.63s/it, est. speed input: 162.45 toks/s, output: 31.88 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.63s/it, est. speed input: 162.45 toks/s, output: 31.88 toks/s]
[2025-03-21 21:22:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.59s/it, est. speed input: 102.24 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.59s/it, est. speed input: 102.24 toks/s, output: 32.31 toks/s]
[2025-03-21 21:22:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.69s/it, est. speed input: 116.05 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.69s/it, est. speed input: 116.05 toks/s, output: 32.18 toks/s]
[2025-03-21 21:23:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.98s/it, est. speed input: 99.99 toks/s, output: 33.05 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.98s/it, est. speed input: 99.99 toks/s, output: 33.05 toks/s]
[2025-03-21 21:23:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.60s/it, est. speed input: 292.95 toks/s, output: 30.86 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.60s/it, est. speed input: 292.95 toks/s, output: 30.86 toks/s]
[2025-03-21 21:23:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.07s/it, est. speed input: 261.75 toks/s, output: 31.07 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.07s/it, est. speed input: 261.75 toks/s, output: 31.07 toks/s]
[2025-03-21 21:23:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.25s/it, est. speed input: 133.01 toks/s, output: 32.13 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.25s/it, est. speed input: 133.01 toks/s, output: 32.13 toks/s]
[2025-03-21 21:24:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.75s/it, est. speed input: 124.57 toks/s, output: 32.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.75s/it, est. speed input: 124.57 toks/s, output: 32.16 toks/s]
[2025-03-21 21:24:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 95.07 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 95.07 toks/s, output: 32.33 toks/s]
[2025-03-21 21:25:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it, est. speed input: 1928.15 toks/s, output: 18.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it, est. speed input: 1928.15 toks/s, output: 18.51 toks/s]
[2025-03-21 21:25:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 97.21 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 97.21 toks/s, output: 32.28 toks/s]
[2025-03-21 21:25:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.10s/it, est. speed input: 113.31 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.10s/it, est. speed input: 113.31 toks/s, output: 32.27 toks/s]
[2025-03-21 21:26:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.52s/it, est. speed input: 199.06 toks/s, output: 31.65 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.52s/it, est. speed input: 199.06 toks/s, output: 31.65 toks/s]
[2025-03-21 21:26:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.66s/it, est. speed input: 118.69 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.66s/it, est. speed input: 118.69 toks/s, output: 32.24 toks/s]
[2025-03-21 21:26:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.08s/it, est. speed input: 165.65 toks/s, output: 31.90 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.08s/it, est. speed input: 165.65 toks/s, output: 31.90 toks/s]
[2025-03-21 21:27:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 92.17 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 92.17 toks/s, output: 32.36 toks/s]
[2025-03-21 21:27:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.45s/it, est. speed input: 122.55 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.45s/it, est. speed input: 122.55 toks/s, output: 32.19 toks/s]
[2025-03-21 21:28:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.20s/it, est. speed input: 163.55 toks/s, output: 31.87 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.20s/it, est. speed input: 163.55 toks/s, output: 31.87 toks/s]
[2025-03-21 21:28:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.04s/it, est. speed input: 97.39 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.04s/it, est. speed input: 97.39 toks/s, output: 32.35 toks/s]
[2025-03-21 21:28:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.15s/it, est. speed input: 152.03 toks/s, output: 31.65 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.15s/it, est. speed input: 152.03 toks/s, output: 31.65 toks/s]
[2025-03-21 21:29:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 89.54 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 89.54 toks/s, output: 32.45 toks/s]
[2025-03-21 21:29:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.37s/it, est. speed input: 81.14 toks/s, output: 32.65 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.37s/it, est. speed input: 81.14 toks/s, output: 32.65 toks/s]
[2025-03-21 21:30:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.40s/it, est. speed input: 94.01 toks/s, output: 32.43 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.40s/it, est. speed input: 94.01 toks/s, output: 32.43 toks/s]
[2025-03-21 21:30:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.84s/it, est. speed input: 1085.37 toks/s, output: 24.68 toks/s]Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.84s/it, est. speed input: 1085.37 toks/s, output: 24.68 toks/s]
[2025-03-21 21:30:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.06s/it, est. speed input: 108.58 toks/s, output: 32.52 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.06s/it, est. speed input: 108.58 toks/s, output: 32.52 toks/s]
[2025-03-21 21:31:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.35s/it, est. speed input: 80.31 toks/s, output: 32.66 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.35s/it, est. speed input: 80.31 toks/s, output: 32.66 toks/s]
[2025-03-21 21:31:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.55s/it, est. speed input: 152.12 toks/s, output: 33.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.55s/it, est. speed input: 152.12 toks/s, output: 33.23 toks/s]
[2025-03-21 21:32:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.16s/it, est. speed input: 127.92 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.16s/it, est. speed input: 127.92 toks/s, output: 32.29 toks/s]
[2025-03-21 21:32:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.12s/it, est. speed input: 198.76 toks/s, output: 31.61 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.12s/it, est. speed input: 198.76 toks/s, output: 31.61 toks/s]
[2025-03-21 21:32:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.42s/it, est. speed input: 113.74 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.42s/it, est. speed input: 113.74 toks/s, output: 32.21 toks/s]
[2025-03-21 21:33:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.27s/it, est. speed input: 94.55 toks/s, output: 32.58 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.27s/it, est. speed input: 94.55 toks/s, output: 32.58 toks/s]
[2025-03-21 21:33:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.55s/it, est. speed input: 290.52 toks/s, output: 30.89 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.55s/it, est. speed input: 290.52 toks/s, output: 30.89 toks/s]
[2025-03-21 21:33:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.77s/it, est. speed input: 134.95 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.77s/it, est. speed input: 134.95 toks/s, output: 32.06 toks/s]
[2025-03-21 21:34:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.50s/it, est. speed input: 222.06 toks/s, output: 31.65 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.50s/it, est. speed input: 222.06 toks/s, output: 31.65 toks/s]
[2025-03-21 21:34:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.38s/it, est. speed input: 125.55 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.38s/it, est. speed input: 125.55 toks/s, output: 32.33 toks/s]
[2025-03-21 21:34:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.64s/it, est. speed input: 189.96 toks/s, output: 31.83 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.64s/it, est. speed input: 189.96 toks/s, output: 31.83 toks/s]
[2025-03-21 21:34:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.91s/it, est. speed input: 161.49 toks/s, output: 31.93 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.91s/it, est. speed input: 161.49 toks/s, output: 31.93 toks/s]
[2025-03-21 21:35:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, est. speed input: 3157.14 toks/s, output: 32.92 toks/s]Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, est. speed input: 3157.14 toks/s, output: 32.92 toks/s]
[2025-03-21 21:35:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 93.84 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.65s/it, est. speed input: 93.84 toks/s, output: 32.35 toks/s]
[2025-03-21 21:35:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.73s/it, est. speed input: 100.11 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.73s/it, est. speed input: 100.11 toks/s, output: 32.30 toks/s]
[2025-03-21 21:36:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 98.76 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 98.76 toks/s, output: 32.23 toks/s]
[2025-03-21 21:36:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.91s/it, est. speed input: 120.73 toks/s, output: 32.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.91s/it, est. speed input: 120.73 toks/s, output: 32.16 toks/s]
[2025-03-21 21:37:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.05s/it, est. speed input: 163.36 toks/s, output: 31.81 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.05s/it, est. speed input: 163.36 toks/s, output: 31.81 toks/s]
[2025-03-21 21:37:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 85.90 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 85.90 toks/s, output: 32.46 toks/s]
[2025-03-21 21:38:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.60s/it, est. speed input: 156.18 toks/s, output: 32.04 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.60s/it, est. speed input: 156.18 toks/s, output: 32.04 toks/s]
level3 Generation Success

Total testing execution time: 7180.51 seconds
finished
INFO 03-21 21:38:34 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot_COT.py:30: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot_COT.py:42: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
Model Name:  Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8
Runnig on Parallel - Loading tokenizer...
Loading model across multiple GPUs...
INFO 03-21 21:38:45 [config.py:583] This model supports multiple tasks: {'embed', 'classify', 'score', 'reward', 'generate'}. Defaulting to 'generate'.
INFO 03-21 21:38:46 [gptq_marlin.py:143] The model is convertible to gptq_marlin during runtime. Using gptq_marlin kernel.
INFO 03-21 21:38:46 [config.py:1515] Defaulting to use mp for distributed inference
INFO 03-21 21:38:46 [config.py:1693] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 03-21 21:38:52 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot_COT.py:30: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot_COT.py:42: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
[2025-03-21 21:38:54] INFO loader.py:87: Loading faiss with AVX512 support.
[2025-03-21 21:38:54] INFO loader.py:92: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-03-21 21:38:54] INFO loader.py:99: Loading faiss with AVX2 support.
[2025-03-21 21:38:54] INFO loader.py:104: Could not load library with AVX2 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx2'")
[2025-03-21 21:38:54] INFO loader.py:110: Loading faiss.
[2025-03-21 21:38:54] INFO loader.py:112: Successfully loaded faiss.
INFO 03-21 21:38:55 [core.py:53] Initializing a V1 LLM engine (v0.8.1) with config: model='Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8', speculative_config=None, tokenizer='Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=gptq_marlin, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 03-21 21:38:55 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 64 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 03-21 21:38:55 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1], buffer_handle=(2, 10485760, 10, 'psm_3a11288d'), local_subscribe_addr='ipc:///tmp/c3cedf99-c58e-4e48-aa90-830bf4e2386b', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-21 21:39:01 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot_COT.py:30: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot_COT.py:42: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
[2025-03-21 21:39:03] INFO loader.py:87: Loading faiss with AVX512 support.
[2025-03-21 21:39:03] INFO loader.py:92: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-03-21 21:39:03] INFO loader.py:99: Loading faiss with AVX2 support.
[2025-03-21 21:39:03] INFO loader.py:104: Could not load library with AVX2 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx2'")
[2025-03-21 21:39:03] INFO loader.py:110: Loading faiss.
[2025-03-21 21:39:03] INFO loader.py:112: Successfully loaded faiss.
WARNING 03-21 21:39:03 [utils.py:2282] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x799c7779a900>
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:03 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_8ebfd88b'), local_subscribe_addr='ipc:///tmp/1e174c99-81ae-4e65-82f1-bf88eaf6c4b4', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 03-21 21:39:09 [__init__.py:256] Automatically detected platform cuda.
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot_COT.py:30: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import OpenAIEmbeddings
/home/UNT/ae0589/project/action_engine/eval/data/predict/zeroshot_COT.py:42: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
[2025-03-21 21:39:11] INFO loader.py:87: Loading faiss with AVX512 support.
[2025-03-21 21:39:11] INFO loader.py:92: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-03-21 21:39:11] INFO loader.py:99: Loading faiss with AVX2 support.
[2025-03-21 21:39:11] INFO loader.py:104: Could not load library with AVX2 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx2'")
[2025-03-21 21:39:11] INFO loader.py:110: Loading faiss.
[2025-03-21 21:39:11] INFO loader.py:112: Successfully loaded faiss.
WARNING 03-21 21:39:12 [utils.py:2282] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7c6dfd3a79e0>
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:12 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a56a73b5'), local_subscribe_addr='ipc:///tmp/86653aa9-3c1e-424b-b574-44241cdf346d', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:12 [utils.py:925] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:12 [utils.py:925] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:12 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:12 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:13 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/UNT/ae0589/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:13 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/UNT/ae0589/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m WARNING 03-21 21:39:13 [custom_all_reduce.py:146] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m WARNING 03-21 21:39:13 [custom_all_reduce.py:146] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:13 [shm_broadcast.py:258] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_edd8aa84'), local_subscribe_addr='ipc:///tmp/1829f803-177b-4565-9bb7-a06ca244ef18', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:13 [parallel_state.py:967] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:13 [cuda.py:215] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:13 [parallel_state.py:967] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:13 [cuda.py:215] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:13 [gpu_model_runner.py:1164] Starting to load model Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8...
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:13 [gptq_marlin.py:235] Using MarlinLinearKernel for GPTQMarlinLinearMethod
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:13 [gpu_model_runner.py:1164] Starting to load model Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int8...
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:13 [gptq_marlin.py:235] Using MarlinLinearKernel for GPTQMarlinLinearMethod
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m WARNING 03-21 21:39:13 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m WARNING 03-21 21:39:13 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:13 [weight_utils.py:257] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/9 [00:00<?, ?it/s]
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:14 [weight_utils.py:257] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m Loading safetensors checkpoint shards:  11% Completed | 1/9 [00:01<00:10,  1.28s/it]
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m Loading safetensors checkpoint shards:  22% Completed | 2/9 [00:02<00:09,  1.33s/it]
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m Loading safetensors checkpoint shards:  33% Completed | 3/9 [00:04<00:08,  1.35s/it]
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m Loading safetensors checkpoint shards:  44% Completed | 4/9 [00:04<00:05,  1.13s/it]
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m Loading safetensors checkpoint shards:  56% Completed | 5/9 [00:05<00:04,  1.06s/it]
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m Loading safetensors checkpoint shards:  67% Completed | 6/9 [00:07<00:03,  1.16s/it]
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m Loading safetensors checkpoint shards:  78% Completed | 7/9 [00:08<00:02,  1.24s/it]
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m Loading safetensors checkpoint shards:  89% Completed | 8/9 [00:09<00:01,  1.28s/it]
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m Loading safetensors checkpoint shards: 100% Completed | 9/9 [00:11<00:00,  1.31s/it]
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m Loading safetensors checkpoint shards: 100% Completed | 9/9 [00:11<00:00,  1.25s/it]
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m 
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:25 [loader.py:429] Loading weights took 11.33 seconds
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:25 [gpu_model_runner.py:1176] Model loading took 16.3608 GB and 12.067118 seconds
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:26 [loader.py:429] Loading weights took 11.33 seconds
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:26 [gpu_model_runner.py:1176] Model loading took 16.3608 GB and 13.043898 seconds
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:51 [backends.py:409] Using cache directory: /home/UNT/ae0589/.cache/vllm/torch_compile_cache/b66d6f0d9f/rank_0_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:51 [backends.py:409] Using cache directory: /home/UNT/ae0589/.cache/vllm/torch_compile_cache/b66d6f0d9f/rank_1_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:51 [backends.py:419] Dynamo bytecode transform time: 24.68 s
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:51 [backends.py:419] Dynamo bytecode transform time: 24.68 s
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:39:53 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:39:53 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:40:15 [monitor.py:33] torch.compile takes 24.68 s in total
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:40:15 [monitor.py:33] torch.compile takes 24.68 s in total
INFO 03-21 21:40:17 [kv_cache_utils.py:537] GPU KV cache size: 139,664 tokens
INFO 03-21 21:40:17 [kv_cache_utils.py:540] Maximum concurrency for 32,768 tokens per request: 4.26x
INFO 03-21 21:40:17 [kv_cache_utils.py:537] GPU KV cache size: 139,664 tokens
INFO 03-21 21:40:17 [kv_cache_utils.py:540] Maximum concurrency for 32,768 tokens per request: 4.26x
[1;36m(VllmWorker rank=0 pid=1482675)[0;0m INFO 03-21 21:41:06 [gpu_model_runner.py:1499] Graph capturing finished in 49 secs, took 2.28 GiB
[1;36m(VllmWorker rank=1 pid=1482693)[0;0m INFO 03-21 21:41:06 [gpu_model_runner.py:1499] Graph capturing finished in 49 secs, took 2.28 GiB
INFO 03-21 21:41:07 [core.py:138] init engine (profile, create kv cache, warmup model) took 100.53 seconds
[2025-03-21 21:41:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
------------Qwen model loaded across GPUs.------------

--- Testing level1
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 80.19 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 80.19 toks/s, output: 32.26 toks/s]
[2025-03-21 21:41:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.98s/it, est. speed input: 136.44 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.98s/it, est. speed input: 136.44 toks/s, output: 32.24 toks/s]
[2025-03-21 21:42:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.62s/it, est. speed input: 173.31 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.62s/it, est. speed input: 173.31 toks/s, output: 32.08 toks/s]
[2025-03-21 21:42:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.29s/it, est. speed input: 222.82 toks/s, output: 31.71 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.29s/it, est. speed input: 222.82 toks/s, output: 31.71 toks/s]
[2025-03-21 21:42:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.32s/it, est. speed input: 124.11 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.32s/it, est. speed input: 124.11 toks/s, output: 32.38 toks/s]
[2025-03-21 21:42:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.20s/it, est. speed input: 119.45 toks/s, output: 32.11 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.20s/it, est. speed input: 119.45 toks/s, output: 32.11 toks/s]
[2025-03-21 21:43:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.13s/it, est. speed input: 130.44 toks/s, output: 32.03 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.13s/it, est. speed input: 130.44 toks/s, output: 32.03 toks/s]
[2025-03-21 21:43:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.42s/it, est. speed input: 179.78 toks/s, output: 31.64 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.42s/it, est. speed input: 179.78 toks/s, output: 31.64 toks/s]
[2025-03-21 21:43:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.06s/it, est. speed input: 102.49 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.06s/it, est. speed input: 102.49 toks/s, output: 32.20 toks/s]
[2025-03-21 21:44:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 96.80 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.75s/it, est. speed input: 96.80 toks/s, output: 32.26 toks/s]
[2025-03-21 21:45:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 90.08 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 90.08 toks/s, output: 32.41 toks/s]
[2025-03-21 21:45:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.30s/it, est. speed input: 119.17 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.30s/it, est. speed input: 119.17 toks/s, output: 32.28 toks/s]
[2025-03-21 21:45:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.46s/it, est. speed input: 83.53 toks/s, output: 32.55 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.46s/it, est. speed input: 83.53 toks/s, output: 32.55 toks/s]
[2025-03-21 21:46:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.86s/it, est. speed input: 88.75 toks/s, output: 32.50 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.86s/it, est. speed input: 88.75 toks/s, output: 32.50 toks/s]
[2025-03-21 21:47:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.46s/it, est. speed input: 83.69 toks/s, output: 32.55 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.46s/it, est. speed input: 83.69 toks/s, output: 32.55 toks/s]
[2025-03-21 21:47:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 85.25 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 85.25 toks/s, output: 32.47 toks/s]
[2025-03-21 21:48:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.90s/it, est. speed input: 88.65 toks/s, output: 33.14 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.90s/it, est. speed input: 88.65 toks/s, output: 33.14 toks/s]
[2025-03-21 21:48:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.56s/it, est. speed input: 124.07 toks/s, output: 31.77 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.56s/it, est. speed input: 124.07 toks/s, output: 31.77 toks/s]
[2025-03-21 21:48:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.50s/it, est. speed input: 206.96 toks/s, output: 31.76 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.50s/it, est. speed input: 206.96 toks/s, output: 31.76 toks/s]
[2025-03-21 21:49:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 96.56 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 96.56 toks/s, output: 32.32 toks/s]
[2025-03-21 21:49:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.05s/it, est. speed input: 151.28 toks/s, output: 32.03 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.05s/it, est. speed input: 151.28 toks/s, output: 32.03 toks/s]
[2025-03-21 21:50:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.70s/it, est. speed input: 163.14 toks/s, output: 31.87 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.70s/it, est. speed input: 163.14 toks/s, output: 31.87 toks/s]
[2025-03-21 21:50:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 96.04 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 96.04 toks/s, output: 32.30 toks/s]
[2025-03-21 21:50:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.39s/it, est. speed input: 133.00 toks/s, output: 32.02 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.39s/it, est. speed input: 133.00 toks/s, output: 32.02 toks/s]
[2025-03-21 21:51:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.38s/it, est. speed input: 78.66 toks/s, output: 32.64 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.38s/it, est. speed input: 78.66 toks/s, output: 32.64 toks/s]
[2025-03-21 21:51:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.09s/it, est. speed input: 108.46 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.09s/it, est. speed input: 108.46 toks/s, output: 32.44 toks/s]
[2025-03-21 21:52:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.57s/it, est. speed input: 116.39 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.57s/it, est. speed input: 116.39 toks/s, output: 32.30 toks/s]
[2025-03-21 21:52:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.25s/it, est. speed input: 257.55 toks/s, output: 31.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.25s/it, est. speed input: 257.55 toks/s, output: 31.32 toks/s]
[2025-03-21 21:52:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.12s/it, est. speed input: 120.10 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.13s/it, est. speed input: 120.10 toks/s, output: 32.38 toks/s]
[2025-03-21 21:53:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.23s/it, est. speed input: 116.28 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.23s/it, est. speed input: 116.28 toks/s, output: 32.34 toks/s]
[2025-03-21 21:53:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.44s/it, est. speed input: 140.16 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.44s/it, est. speed input: 140.16 toks/s, output: 32.22 toks/s]
[2025-03-21 21:53:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.88s/it, est. speed input: 154.36 toks/s, output: 32.10 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.88s/it, est. speed input: 154.36 toks/s, output: 32.10 toks/s]
[2025-03-21 21:54:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 81.17 toks/s, output: 32.61 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 81.17 toks/s, output: 32.61 toks/s]
[2025-03-21 21:54:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it, est. speed input: 2421.83 toks/s, output: 14.68 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it, est. speed input: 2421.83 toks/s, output: 14.68 toks/s]
[2025-03-21 21:54:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.29s/it, est. speed input: 181.36 toks/s, output: 31.92 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.29s/it, est. speed input: 181.36 toks/s, output: 31.92 toks/s]
[2025-03-21 21:54:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 91.54 toks/s, output: 32.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 91.54 toks/s, output: 32.42 toks/s]
[2025-03-21 21:55:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.23s/it, est. speed input: 124.17 toks/s, output: 32.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.23s/it, est. speed input: 124.17 toks/s, output: 32.16 toks/s]
[2025-03-21 21:55:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.06s/it, est. speed input: 188.92 toks/s, output: 31.73 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.06s/it, est. speed input: 188.92 toks/s, output: 31.73 toks/s]
[2025-03-21 21:56:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 81.62 toks/s, output: 32.60 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 81.62 toks/s, output: 32.60 toks/s]
[2025-03-21 21:56:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 81.87 toks/s, output: 32.61 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 81.87 toks/s, output: 32.61 toks/s]
[2025-03-21 21:57:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it, est. speed input: 1641.11 toks/s, output: 21.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it, est. speed input: 1641.11 toks/s, output: 21.56 toks/s]
[2025-03-21 21:57:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.27s/it, est. speed input: 93.72 toks/s, output: 32.52 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.27s/it, est. speed input: 93.72 toks/s, output: 32.52 toks/s]
[2025-03-21 21:57:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.02s/it, est. speed input: 151.27 toks/s, output: 32.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.02s/it, est. speed input: 151.27 toks/s, output: 32.15 toks/s]
[2025-03-21 21:57:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.25s/it, est. speed input: 2029.35 toks/s, output: 18.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.25s/it, est. speed input: 2029.35 toks/s, output: 18.35 toks/s]
[2025-03-21 21:57:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.35s/it, est. speed input: 78.67 toks/s, output: 32.67 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.35s/it, est. speed input: 78.67 toks/s, output: 32.67 toks/s]
[2025-03-21 21:58:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 99.29 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 99.29 toks/s, output: 32.24 toks/s]
[2025-03-21 21:59:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.96s/it, est. speed input: 211.48 toks/s, output: 31.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.96s/it, est. speed input: 211.48 toks/s, output: 31.42 toks/s]
[2025-03-21 21:59:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.44s/it, est. speed input: 162.61 toks/s, output: 31.79 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.44s/it, est. speed input: 162.61 toks/s, output: 31.79 toks/s]
[2025-03-21 21:59:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.62s/it, est. speed input: 139.73 toks/s, output: 31.96 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.62s/it, est. speed input: 139.73 toks/s, output: 31.96 toks/s]
[2025-03-21 21:59:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.27s/it, est. speed input: 133.17 toks/s, output: 32.01 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.27s/it, est. speed input: 133.17 toks/s, output: 32.01 toks/s]
[2025-03-21 22:00:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.99s/it, est. speed input: 131.61 toks/s, output: 32.01 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 24.00s/it, est. speed input: 131.61 toks/s, output: 32.01 toks/s]
[2025-03-21 22:00:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.86s/it, est. speed input: 199.15 toks/s, output: 31.52 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.86s/it, est. speed input: 199.15 toks/s, output: 31.52 toks/s]
[2025-03-21 22:01:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.09s/it, est. speed input: 104.77 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.09s/it, est. speed input: 104.77 toks/s, output: 32.32 toks/s]
[2025-03-21 22:01:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it, est. speed input: 1937.97 toks/s, output: 18.70 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it, est. speed input: 1937.97 toks/s, output: 18.70 toks/s]
[2025-03-21 22:01:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.93s/it, est. speed input: 144.62 toks/s, output: 32.13 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.93s/it, est. speed input: 144.62 toks/s, output: 32.13 toks/s]
[2025-03-21 22:01:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.74s/it, est. speed input: 146.55 toks/s, output: 32.12 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.74s/it, est. speed input: 146.55 toks/s, output: 32.12 toks/s]
[2025-03-21 22:02:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it, est. speed input: 1705.70 toks/s, output: 21.01 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it, est. speed input: 1705.70 toks/s, output: 21.01 toks/s]
[2025-03-21 22:02:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it, est. speed input: 1956.89 toks/s, output: 19.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it, est. speed input: 1956.89 toks/s, output: 19.26 toks/s]
[2025-03-21 22:02:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.75s/it, est. speed input: 112.30 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.75s/it, est. speed input: 112.30 toks/s, output: 32.29 toks/s]
[2025-03-21 22:02:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 86.81 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.55s/it, est. speed input: 86.81 toks/s, output: 32.46 toks/s]
[2025-03-21 22:03:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 94.81 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 94.81 toks/s, output: 32.31 toks/s]
[2025-03-21 22:03:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it, est. speed input: 2100.74 toks/s, output: 16.76 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it, est. speed input: 2100.74 toks/s, output: 16.76 toks/s]
[2025-03-21 22:03:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.13s/it, est. speed input: 123.52 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.13s/it, est. speed input: 123.52 toks/s, output: 32.17 toks/s]
[2025-03-21 22:04:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.81s/it, est. speed input: 106.78 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.81s/it, est. speed input: 106.78 toks/s, output: 32.30 toks/s]
[2025-03-21 22:04:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 92.62 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 92.62 toks/s, output: 32.35 toks/s]
[2025-03-21 22:05:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.53s/it, est. speed input: 116.82 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.53s/it, est. speed input: 116.82 toks/s, output: 32.30 toks/s]
[2025-03-21 22:05:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.99s/it, est. speed input: 168.08 toks/s, output: 31.85 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.99s/it, est. speed input: 168.08 toks/s, output: 31.85 toks/s]
[2025-03-21 22:05:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.68s/it, est. speed input: 118.86 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.68s/it, est. speed input: 118.86 toks/s, output: 32.18 toks/s]
[2025-03-21 22:06:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.53s/it, est. speed input: 102.85 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.53s/it, est. speed input: 102.85 toks/s, output: 32.39 toks/s]
[2025-03-21 22:06:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.37s/it, est. speed input: 102.23 toks/s, output: 32.44 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.37s/it, est. speed input: 102.23 toks/s, output: 32.44 toks/s]
[2025-03-21 22:07:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.44s/it, est. speed input: 81.65 toks/s, output: 32.57 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.44s/it, est. speed input: 81.65 toks/s, output: 32.57 toks/s]
[2025-03-21 22:07:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 98.82 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 98.82 toks/s, output: 32.24 toks/s]
[2025-03-21 22:08:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.29s/it, est. speed input: 201.88 toks/s, output: 31.52 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.29s/it, est. speed input: 201.88 toks/s, output: 31.52 toks/s]
[2025-03-21 22:08:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.02s/it, est. speed input: 117.10 toks/s, output: 32.12 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.02s/it, est. speed input: 117.10 toks/s, output: 32.12 toks/s]
[2025-03-21 22:08:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 99.78 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 99.78 toks/s, output: 32.23 toks/s]
[2025-03-21 22:09:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 91.56 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 91.56 toks/s, output: 32.40 toks/s]
[2025-03-21 22:09:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.48s/it, est. speed input: 165.25 toks/s, output: 31.92 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.48s/it, est. speed input: 165.25 toks/s, output: 31.92 toks/s]
[2025-03-21 22:10:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.45s/it, est. speed input: 141.37 toks/s, output: 31.97 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.46s/it, est. speed input: 141.37 toks/s, output: 31.97 toks/s]
[2025-03-21 22:10:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.48s/it, est. speed input: 144.17 toks/s, output: 31.93 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.48s/it, est. speed input: 144.17 toks/s, output: 31.93 toks/s]
[2025-03-21 22:10:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.52s/it, est. speed input: 143.88 toks/s, output: 32.02 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.52s/it, est. speed input: 143.88 toks/s, output: 32.02 toks/s]
[2025-03-21 22:11:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.16s/it, est. speed input: 113.38 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.16s/it, est. speed input: 113.38 toks/s, output: 32.23 toks/s]
[2025-03-21 22:11:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.89s/it, est. speed input: 126.52 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.89s/it, est. speed input: 126.52 toks/s, output: 32.33 toks/s]
[2025-03-21 22:12:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.19s/it, est. speed input: 177.01 toks/s, output: 32.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.19s/it, est. speed input: 177.01 toks/s, output: 32.00 toks/s]
[2025-03-21 22:12:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.77s/it, est. speed input: 105.55 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.77s/it, est. speed input: 105.55 toks/s, output: 32.18 toks/s]
[2025-03-21 22:12:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.47s/it, est. speed input: 110.58 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.47s/it, est. speed input: 110.58 toks/s, output: 32.21 toks/s]
[2025-03-21 22:13:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.11s/it, est. speed input: 257.55 toks/s, output: 31.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.11s/it, est. speed input: 257.55 toks/s, output: 31.35 toks/s]
[2025-03-21 22:13:26] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.32s/it, est. speed input: 182.67 toks/s, output: 31.84 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.32s/it, est. speed input: 182.67 toks/s, output: 31.84 toks/s]
[2025-03-21 22:13:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.60s/it, est. speed input: 237.18 toks/s, output: 31.59 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.60s/it, est. speed input: 237.18 toks/s, output: 31.59 toks/s]
[2025-03-21 22:13:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.90s/it, est. speed input: 204.17 toks/s, output: 31.59 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.90s/it, est. speed input: 204.17 toks/s, output: 31.59 toks/s]
[2025-03-21 22:14:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.78s/it, est. speed input: 133.29 toks/s, output: 32.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.78s/it, est. speed input: 133.29 toks/s, output: 32.00 toks/s]
[2025-03-21 22:14:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.78s/it, est. speed input: 99.87 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.78s/it, est. speed input: 99.87 toks/s, output: 32.22 toks/s]
[2025-03-21 22:15:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.30s/it, est. speed input: 130.12 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.30s/it, est. speed input: 130.12 toks/s, output: 32.21 toks/s]
[2025-03-21 22:15:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.44s/it, est. speed input: 117.50 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.44s/it, est. speed input: 117.50 toks/s, output: 32.24 toks/s]
[2025-03-21 22:15:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.84s/it, est. speed input: 93.58 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.84s/it, est. speed input: 93.58 toks/s, output: 32.30 toks/s]
[2025-03-21 22:16:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 87.71 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 87.71 toks/s, output: 32.40 toks/s]
[2025-03-21 22:16:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.95s/it, est. speed input: 114.73 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.95s/it, est. speed input: 114.73 toks/s, output: 32.17 toks/s]
[2025-03-21 22:17:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.78s/it, est. speed input: 100.43 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.78s/it, est. speed input: 100.43 toks/s, output: 32.22 toks/s]
[2025-03-21 22:17:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.70s/it, est. speed input: 105.92 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.70s/it, est. speed input: 105.92 toks/s, output: 32.34 toks/s]
[2025-03-21 22:18:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.75s/it, est. speed input: 143.13 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.75s/it, est. speed input: 143.13 toks/s, output: 32.06 toks/s]
[2025-03-21 22:18:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.66s/it, est. speed input: 106.16 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.66s/it, est. speed input: 106.16 toks/s, output: 32.25 toks/s]
[2025-03-21 22:19:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
level1 Generation Success

--- Testing level2
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.38s/it, est. speed input: 94.19 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.38s/it, est. speed input: 94.19 toks/s, output: 32.39 toks/s]
[2025-03-21 22:19:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 89.51 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 89.51 toks/s, output: 32.37 toks/s]
[2025-03-21 22:20:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.79s/it, est. speed input: 106.52 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.79s/it, est. speed input: 106.52 toks/s, output: 32.30 toks/s]
[2025-03-21 22:20:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.76s/it, est. speed input: 159.90 toks/s, output: 31.78 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.76s/it, est. speed input: 159.90 toks/s, output: 31.78 toks/s]
[2025-03-21 22:20:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 90.36 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 90.36 toks/s, output: 32.40 toks/s]
[2025-03-21 22:21:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.24s/it, est. speed input: 101.37 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.24s/it, est. speed input: 101.37 toks/s, output: 32.39 toks/s]
[2025-03-21 22:21:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.53s/it, est. speed input: 121.10 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.53s/it, est. speed input: 121.10 toks/s, output: 32.18 toks/s]
[2025-03-21 22:22:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.03s/it, est. speed input: 118.43 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.03s/it, est. speed input: 118.43 toks/s, output: 32.20 toks/s]
[2025-03-21 22:22:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.69s/it, est. speed input: 132.69 toks/s, output: 32.04 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.69s/it, est. speed input: 132.69 toks/s, output: 32.04 toks/s]
[2025-03-21 22:23:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 95.10 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 95.10 toks/s, output: 32.32 toks/s]
[2025-03-21 22:23:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.57s/it, est. speed input: 140.01 toks/s, output: 32.09 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.57s/it, est. speed input: 140.01 toks/s, output: 32.09 toks/s]
[2025-03-21 22:24:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 96.93 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 96.93 toks/s, output: 32.30 toks/s]
[2025-03-21 22:24:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.62s/it, est. speed input: 105.66 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.62s/it, est. speed input: 105.66 toks/s, output: 32.34 toks/s]
[2025-03-21 22:25:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 90.88 toks/s, output: 32.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 90.88 toks/s, output: 32.42 toks/s]
[2025-03-21 22:25:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 94.88 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 94.88 toks/s, output: 32.33 toks/s]
[2025-03-21 22:26:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.43s/it, est. speed input: 131.01 toks/s, output: 32.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.43s/it, est. speed input: 131.01 toks/s, output: 32.15 toks/s]
[2025-03-21 22:26:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.17s/it, est. speed input: 147.81 toks/s, output: 32.03 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.17s/it, est. speed input: 147.81 toks/s, output: 32.03 toks/s]
[2025-03-21 22:26:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 92.72 toks/s, output: 32.32 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 92.72 toks/s, output: 32.32 toks/s]
[2025-03-21 22:27:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 86.43 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 86.43 toks/s, output: 32.41 toks/s]
[2025-03-21 22:27:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 94.35 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 94.35 toks/s, output: 32.33 toks/s]
[2025-03-21 22:28:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.44s/it, est. speed input: 82.51 toks/s, output: 32.57 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.44s/it, est. speed input: 82.51 toks/s, output: 32.57 toks/s]
[2025-03-21 22:28:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.50s/it, est. speed input: 117.43 toks/s, output: 32.36 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.50s/it, est. speed input: 117.43 toks/s, output: 32.36 toks/s]
[2025-03-21 22:29:21] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.80s/it, est. speed input: 201.20 toks/s, output: 31.75 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.80s/it, est. speed input: 201.20 toks/s, output: 31.75 toks/s]
[2025-03-21 22:29:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.23s/it, est. speed input: 107.10 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.23s/it, est. speed input: 107.10 toks/s, output: 32.29 toks/s]
[2025-03-21 22:30:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 21.00s/it, est. speed input: 135.62 toks/s, output: 32.05 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 21.00s/it, est. speed input: 135.62 toks/s, output: 32.05 toks/s]
[2025-03-21 22:30:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.16s/it, est. speed input: 124.20 toks/s, output: 32.03 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.16s/it, est. speed input: 124.20 toks/s, output: 32.03 toks/s]
[2025-03-21 22:30:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.19s/it, est. speed input: 112.68 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.19s/it, est. speed input: 112.68 toks/s, output: 32.30 toks/s]
[2025-03-21 22:31:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 94.86 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 94.86 toks/s, output: 32.28 toks/s]
[2025-03-21 22:31:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.12s/it, est. speed input: 136.80 toks/s, output: 32.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.12s/it, est. speed input: 136.80 toks/s, output: 32.16 toks/s]
[2025-03-21 22:32:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.47s/it, est. speed input: 95.70 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.48s/it, est. speed input: 95.70 toks/s, output: 32.38 toks/s]
[2025-03-21 22:32:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.65s/it, est. speed input: 106.23 toks/s, output: 32.43 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.65s/it, est. speed input: 106.23 toks/s, output: 32.43 toks/s]
[2025-03-21 22:32:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.79s/it, est. speed input: 98.64 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.79s/it, est. speed input: 98.64 toks/s, output: 32.21 toks/s]
[2025-03-21 22:33:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.67s/it, est. speed input: 115.91 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.67s/it, est. speed input: 115.91 toks/s, output: 32.19 toks/s]
[2025-03-21 22:33:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.63s/it, est. speed input: 91.29 toks/s, output: 32.37 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.64s/it, est. speed input: 91.29 toks/s, output: 32.37 toks/s]
[2025-03-21 22:34:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 96.81 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 96.81 toks/s, output: 32.26 toks/s]
[2025-03-21 22:34:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 86.65 toks/s, output: 32.35 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 86.65 toks/s, output: 32.35 toks/s]
[2025-03-21 22:35:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 88.18 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 88.18 toks/s, output: 32.40 toks/s]
[2025-03-21 22:36:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 88.38 toks/s, output: 32.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 88.38 toks/s, output: 32.42 toks/s]
[2025-03-21 22:36:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it, est. speed input: 1879.82 toks/s, output: 18.49 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it, est. speed input: 1879.82 toks/s, output: 18.49 toks/s]
[2025-03-21 22:36:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.81s/it, est. speed input: 99.79 toks/s, output: 32.19 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.81s/it, est. speed input: 99.79 toks/s, output: 32.19 toks/s]
[2025-03-21 22:37:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.02s/it, est. speed input: 132.54 toks/s, output: 32.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.02s/it, est. speed input: 132.54 toks/s, output: 32.16 toks/s]
[2025-03-21 22:37:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 80.23 toks/s, output: 32.62 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.40s/it, est. speed input: 80.23 toks/s, output: 32.62 toks/s]
[2025-03-21 22:38:01] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 95.54 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 95.54 toks/s, output: 32.29 toks/s]
[2025-03-21 22:38:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 96.27 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 96.27 toks/s, output: 32.28 toks/s]
[2025-03-21 22:39:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.36s/it, est. speed input: 87.19 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.36s/it, est. speed input: 87.19 toks/s, output: 32.45 toks/s]
[2025-03-21 22:39:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 82.77 toks/s, output: 32.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.52s/it, est. speed input: 82.77 toks/s, output: 32.48 toks/s]
[2025-03-21 22:40:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.58s/it, est. speed input: 300.02 toks/s, output: 31.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.58s/it, est. speed input: 300.02 toks/s, output: 31.00 toks/s]
[2025-03-21 22:40:17] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it, est. speed input: 1753.98 toks/s, output: 19.83 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it, est. speed input: 1753.98 toks/s, output: 19.83 toks/s]
[2025-03-21 22:40:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.47s/it, est. speed input: 153.20 toks/s, output: 31.94 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.47s/it, est. speed input: 153.20 toks/s, output: 31.94 toks/s]
[2025-03-21 22:40:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.40s/it, est. speed input: 145.42 toks/s, output: 31.96 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.40s/it, est. speed input: 145.42 toks/s, output: 31.96 toks/s]
[2025-03-21 22:40:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.55s/it, est. speed input: 115.32 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.55s/it, est. speed input: 115.32 toks/s, output: 32.18 toks/s]
[2025-03-21 22:41:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 85.78 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 85.78 toks/s, output: 32.40 toks/s]
[2025-03-21 22:41:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.75s/it, est. speed input: 170.71 toks/s, output: 32.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.75s/it, est. speed input: 170.71 toks/s, output: 32.00 toks/s]
[2025-03-21 22:42:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.05s/it, est. speed input: 183.05 toks/s, output: 31.81 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.05s/it, est. speed input: 183.05 toks/s, output: 31.81 toks/s]
[2025-03-21 22:42:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it, est. speed input: 2010.78 toks/s, output: 16.99 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it, est. speed input: 2010.78 toks/s, output: 16.99 toks/s]
[2025-03-21 22:42:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.93s/it, est. speed input: 92.34 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.93s/it, est. speed input: 92.34 toks/s, output: 32.39 toks/s]
[2025-03-21 22:42:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 82.64 toks/s, output: 32.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 82.64 toks/s, output: 32.51 toks/s]
[2025-03-21 22:43:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 85.08 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 85.08 toks/s, output: 32.40 toks/s]
[2025-03-21 22:43:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 82.73 toks/s, output: 32.52 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.49s/it, est. speed input: 82.73 toks/s, output: 32.52 toks/s]
[2025-03-21 22:44:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it, est. speed input: 2017.34 toks/s, output: 17.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it, est. speed input: 2017.34 toks/s, output: 17.16 toks/s]
[2025-03-21 22:44:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.45s/it, est. speed input: 99.44 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.45s/it, est. speed input: 99.44 toks/s, output: 32.31 toks/s]
[2025-03-21 22:45:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 86.11 toks/s, output: 32.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.59s/it, est. speed input: 86.11 toks/s, output: 32.42 toks/s]
[2025-03-21 22:45:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 97.81 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.77s/it, est. speed input: 97.81 toks/s, output: 32.24 toks/s]
[2025-03-21 22:46:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.11s/it, est. speed input: 113.89 toks/s, output: 32.12 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.11s/it, est. speed input: 113.89 toks/s, output: 32.12 toks/s]
[2025-03-21 22:46:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 94.14 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 94.14 toks/s, output: 32.30 toks/s]
[2025-03-21 22:47:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.85s/it, est. speed input: 114.12 toks/s, output: 32.07 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.85s/it, est. speed input: 114.12 toks/s, output: 32.07 toks/s]
[2025-03-21 22:47:32] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.77s/it, est. speed input: 172.86 toks/s, output: 31.68 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.77s/it, est. speed input: 172.86 toks/s, output: 31.68 toks/s]
[2025-03-21 22:47:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.73s/it, est. speed input: 136.37 toks/s, output: 32.03 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.73s/it, est. speed input: 136.37 toks/s, output: 32.03 toks/s]
[2025-03-21 22:48:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 82.37 toks/s, output: 32.50 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 82.37 toks/s, output: 32.50 toks/s]
[2025-03-21 22:48:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.15s/it, est. speed input: 128.61 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.15s/it, est. speed input: 128.61 toks/s, output: 32.22 toks/s]
[2025-03-21 22:49:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it, est. speed input: 1719.00 toks/s, output: 20.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it, est. speed input: 1719.00 toks/s, output: 20.26 toks/s]
[2025-03-21 22:49:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.99s/it, est. speed input: 171.52 toks/s, output: 31.78 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.99s/it, est. speed input: 171.52 toks/s, output: 31.78 toks/s]
[2025-03-21 22:49:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.05s/it, est. speed input: 115.58 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.05s/it, est. speed input: 115.58 toks/s, output: 32.22 toks/s]
[2025-03-21 22:49:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it, est. speed input: 1794.71 toks/s, output: 19.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it, est. speed input: 1794.71 toks/s, output: 19.42 toks/s]
[2025-03-21 22:49:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 79.57 toks/s, output: 32.60 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 79.57 toks/s, output: 32.60 toks/s]
[2025-03-21 22:50:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.17s/it, est. speed input: 170.29 toks/s, output: 31.92 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.17s/it, est. speed input: 170.29 toks/s, output: 31.92 toks/s]
[2025-03-21 22:50:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.61s/it, est. speed input: 104.58 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.61s/it, est. speed input: 104.58 toks/s, output: 32.30 toks/s]
[2025-03-21 22:51:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.33s/it, est. speed input: 237.80 toks/s, output: 31.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.33s/it, est. speed input: 237.80 toks/s, output: 31.21 toks/s]
[2025-03-21 22:51:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 85.50 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 85.50 toks/s, output: 32.45 toks/s]
[2025-03-21 22:51:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s, est. speed input: 4010.58 toks/s, output: 1.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s, est. speed input: 4010.58 toks/s, output: 1.28 toks/s]
[2025-03-21 22:51:51] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.92s/it, est. speed input: 144.24 toks/s, output: 32.03 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.92s/it, est. speed input: 144.24 toks/s, output: 32.03 toks/s]
[2025-03-21 22:52:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.83s/it, est. speed input: 111.37 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.83s/it, est. speed input: 111.37 toks/s, output: 32.20 toks/s]
[2025-03-21 22:52:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.15s/it, est. speed input: 166.70 toks/s, output: 32.09 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.15s/it, est. speed input: 166.70 toks/s, output: 32.09 toks/s]
[2025-03-21 22:52:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.32s/it, est. speed input: 215.42 toks/s, output: 31.53 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.32s/it, est. speed input: 215.42 toks/s, output: 31.53 toks/s]
[2025-03-21 22:53:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.48s/it, est. speed input: 83.12 toks/s, output: 32.53 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.48s/it, est. speed input: 83.12 toks/s, output: 32.53 toks/s]
[2025-03-21 22:53:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it, est. speed input: 1954.29 toks/s, output: 17.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it, est. speed input: 1954.29 toks/s, output: 17.41 toks/s]
[2025-03-21 22:53:42] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.61s/it, est. speed input: 172.23 toks/s, output: 31.74 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.61s/it, est. speed input: 172.23 toks/s, output: 31.74 toks/s]
[2025-03-21 22:54:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.25s/it, est. speed input: 160.49 toks/s, output: 32.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.25s/it, est. speed input: 160.49 toks/s, output: 32.00 toks/s]
[2025-03-21 22:54:16] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.37s/it, est. speed input: 155.31 toks/s, output: 31.86 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.37s/it, est. speed input: 155.31 toks/s, output: 31.86 toks/s]
[2025-03-21 22:54:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.02s/it, est. speed input: 185.98 toks/s, output: 31.76 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.02s/it, est. speed input: 185.98 toks/s, output: 31.76 toks/s]
[2025-03-21 22:54:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 87.95 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 87.95 toks/s, output: 32.39 toks/s]
[2025-03-21 22:55:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.78s/it, est. speed input: 96.85 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.78s/it, est. speed input: 96.85 toks/s, output: 32.22 toks/s]
[2025-03-21 22:55:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.05s/it, est. speed input: 244.16 toks/s, output: 31.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.05s/it, est. speed input: 244.16 toks/s, output: 31.21 toks/s]
[2025-03-21 22:56:08] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 87.19 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 87.19 toks/s, output: 32.41 toks/s]
[2025-03-21 22:56:40] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.41s/it, est. speed input: 134.30 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.41s/it, est. speed input: 134.30 toks/s, output: 32.20 toks/s]
[2025-03-21 22:56:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 94.75 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.69s/it, est. speed input: 94.75 toks/s, output: 32.31 toks/s]
[2025-03-21 22:57:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 96.63 toks/s, output: 32.28 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.72s/it, est. speed input: 96.63 toks/s, output: 32.28 toks/s]
[2025-03-21 22:58:03] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.25s/it, est. speed input: 116.98 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.25s/it, est. speed input: 116.98 toks/s, output: 32.20 toks/s]
[2025-03-21 22:58:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.43s/it, est. speed input: 119.04 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.43s/it, est. speed input: 119.04 toks/s, output: 32.22 toks/s]
[2025-03-21 22:58:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 86.94 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 86.94 toks/s, output: 32.47 toks/s]
[2025-03-21 22:59:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
level2 Generation Success

--- Testing level3
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.54s/it, est. speed input: 114.75 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.54s/it, est. speed input: 114.75 toks/s, output: 32.23 toks/s]
[2025-03-21 22:59:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.22s/it, est. speed input: 103.80 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.22s/it, est. speed input: 103.80 toks/s, output: 32.24 toks/s]
[2025-03-21 23:00:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 94.38 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 94.38 toks/s, output: 32.30 toks/s]
[2025-03-21 23:00:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 95.46 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 95.46 toks/s, output: 32.27 toks/s]
[2025-03-21 23:01:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 97.56 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 97.56 toks/s, output: 32.24 toks/s]
[2025-03-21 23:01:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.88s/it, est. speed input: 116.35 toks/s, output: 32.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.88s/it, est. speed input: 116.35 toks/s, output: 32.15 toks/s]
[2025-03-21 23:02:21] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 93.50 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 93.50 toks/s, output: 32.33 toks/s]
[2025-03-21 23:02:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.94s/it, est. speed input: 117.08 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.94s/it, est. speed input: 117.08 toks/s, output: 32.20 toks/s]
[2025-03-21 23:03:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.34s/it, est. speed input: 125.41 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.34s/it, est. speed input: 125.41 toks/s, output: 32.08 toks/s]
[2025-03-21 23:03:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.15s/it, est. speed input: 204.20 toks/s, output: 31.59 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.15s/it, est. speed input: 204.20 toks/s, output: 31.59 toks/s]
[2025-03-21 23:03:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.71s/it, est. speed input: 104.21 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.71s/it, est. speed input: 104.21 toks/s, output: 32.25 toks/s]
[2025-03-21 23:04:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.24s/it, est. speed input: 115.00 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.24s/it, est. speed input: 115.00 toks/s, output: 32.21 toks/s]
[2025-03-21 23:04:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.80s/it, est. speed input: 99.61 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.80s/it, est. speed input: 99.61 toks/s, output: 32.20 toks/s]
[2025-03-21 23:05:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.82s/it, est. speed input: 99.58 toks/s, output: 32.18 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.82s/it, est. speed input: 99.58 toks/s, output: 32.18 toks/s]
[2025-03-21 23:05:57] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.31s/it, est. speed input: 106.84 toks/s, output: 32.14 toks/s]Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.31s/it, est. speed input: 106.84 toks/s, output: 32.14 toks/s]
[2025-03-21 23:06:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.84s/it, est. speed input: 99.69 toks/s, output: 32.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.84s/it, est. speed input: 99.69 toks/s, output: 32.16 toks/s]
[2025-03-21 23:06:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.21s/it, est. speed input: 114.86 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.21s/it, est. speed input: 114.86 toks/s, output: 32.27 toks/s]
[2025-03-21 23:07:23] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.13s/it, est. speed input: 121.30 toks/s, output: 32.13 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.13s/it, est. speed input: 121.30 toks/s, output: 32.13 toks/s]
[2025-03-21 23:07:45] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.51s/it, est. speed input: 93.25 toks/s, output: 32.40 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.51s/it, est. speed input: 93.25 toks/s, output: 32.40 toks/s]
[2025-03-21 23:08:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 84.33 toks/s, output: 32.46 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 84.33 toks/s, output: 32.46 toks/s]
[2025-03-21 23:08:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.40s/it, est. speed input: 116.34 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.40s/it, est. speed input: 116.34 toks/s, output: 32.23 toks/s]
[2025-03-21 23:09:10] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.62s/it, est. speed input: 108.14 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.62s/it, est. speed input: 108.14 toks/s, output: 32.33 toks/s]
[2025-03-21 23:09:35] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 84.56 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it, est. speed input: 84.56 toks/s, output: 32.39 toks/s]
[2025-03-21 23:10:07] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 84.43 toks/s, output: 32.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 84.43 toks/s, output: 32.51 toks/s]
[2025-03-21 23:10:39] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.03s/it, est. speed input: 98.85 toks/s, output: 32.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.03s/it, est. speed input: 98.85 toks/s, output: 32.56 toks/s]
[2025-03-21 23:11:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.33s/it, est. speed input: 137.81 toks/s, output: 32.30 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.33s/it, est. speed input: 137.81 toks/s, output: 32.30 toks/s]
[2025-03-21 23:11:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.93s/it, est. speed input: 132.05 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.93s/it, est. speed input: 132.05 toks/s, output: 32.22 toks/s]
[2025-03-21 23:11:43] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 79.46 toks/s, output: 32.60 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 79.46 toks/s, output: 32.60 toks/s]
[2025-03-21 23:12:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.51s/it, est. speed input: 171.93 toks/s, output: 32.06 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.51s/it, est. speed input: 171.93 toks/s, output: 32.06 toks/s]
[2025-03-21 23:12:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.94s/it, est. speed input: 131.93 toks/s, output: 32.08 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.94s/it, est. speed input: 131.93 toks/s, output: 32.08 toks/s]
[2025-03-21 23:12:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.31s/it, est. speed input: 105.67 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.31s/it, est. speed input: 105.67 toks/s, output: 32.25 toks/s]
[2025-03-21 23:13:22] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 94.79 toks/s, output: 32.29 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.71s/it, est. speed input: 94.79 toks/s, output: 32.29 toks/s]
[2025-03-21 23:13:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.21s/it, est. speed input: 294.01 toks/s, output: 30.85 toks/s]Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.21s/it, est. speed input: 294.01 toks/s, output: 30.85 toks/s]
[2025-03-21 23:14:04] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.72s/it, est. speed input: 131.07 toks/s, output: 32.09 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.72s/it, est. speed input: 131.07 toks/s, output: 32.09 toks/s]
[2025-03-21 23:14:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.74s/it, est. speed input: 120.93 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.74s/it, est. speed input: 120.93 toks/s, output: 32.17 toks/s]
[2025-03-21 23:14:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 95.40 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.74s/it, est. speed input: 95.40 toks/s, output: 32.26 toks/s]
[2025-03-21 23:15:25] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 84.11 toks/s, output: 32.50 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.51s/it, est. speed input: 84.11 toks/s, output: 32.50 toks/s]
[2025-03-21 23:15:56] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 85.81 toks/s, output: 32.39 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 85.81 toks/s, output: 32.39 toks/s]
[2025-03-21 23:16:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.72s/it, est. speed input: 160.65 toks/s, output: 31.84 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.72s/it, est. speed input: 160.65 toks/s, output: 31.84 toks/s]
[2025-03-21 23:16:47] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 85.49 toks/s, output: 32.47 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.54s/it, est. speed input: 85.49 toks/s, output: 32.47 toks/s]
[2025-03-21 23:17:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.60s/it, est. speed input: 98.16 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.60s/it, est. speed input: 98.16 toks/s, output: 32.31 toks/s]
[2025-03-21 23:17:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 87.76 toks/s, output: 32.43 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.58s/it, est. speed input: 87.76 toks/s, output: 32.43 toks/s]
[2025-03-21 23:18:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.34s/it, est. speed input: 104.51 toks/s, output: 32.25 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.34s/it, est. speed input: 104.51 toks/s, output: 32.25 toks/s]
[2025-03-21 23:18:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.32s/it, est. speed input: 175.99 toks/s, output: 31.75 toks/s]Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.33s/it, est. speed input: 175.99 toks/s, output: 31.75 toks/s]
[2025-03-21 23:19:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.06s/it, est. speed input: 210.35 toks/s, output: 31.42 toks/s]Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.06s/it, est. speed input: 210.35 toks/s, output: 31.42 toks/s]
[2025-03-21 23:19:21] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 84.68 toks/s, output: 32.51 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.50s/it, est. speed input: 84.68 toks/s, output: 32.51 toks/s]
[2025-03-21 23:19:53] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.78s/it, est. speed input: 157.90 toks/s, output: 31.89 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.78s/it, est. speed input: 157.90 toks/s, output: 31.89 toks/s]
[2025-03-21 23:20:12] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.47s/it, est. speed input: 115.67 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.47s/it, est. speed input: 115.67 toks/s, output: 32.21 toks/s]
[2025-03-21 23:20:36] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.97s/it, est. speed input: 142.41 toks/s, output: 32.04 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.97s/it, est. speed input: 142.41 toks/s, output: 32.04 toks/s]
[2025-03-21 23:20:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.35s/it, est. speed input: 149.00 toks/s, output: 31.99 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.35s/it, est. speed input: 149.00 toks/s, output: 31.99 toks/s]
[2025-03-21 23:21:14] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 90.85 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.62s/it, est. speed input: 90.85 toks/s, output: 32.38 toks/s]
[2025-03-21 23:21:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.69s/it, est. speed input: 126.71 toks/s, output: 32.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.69s/it, est. speed input: 126.71 toks/s, output: 32.17 toks/s]
[2025-03-21 23:22:09] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.78s/it, est. speed input: 116.07 toks/s, output: 32.21 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.78s/it, est. speed input: 116.07 toks/s, output: 32.21 toks/s]
[2025-03-21 23:22:34] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 96.34 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 96.34 toks/s, output: 32.27 toks/s]
[2025-03-21 23:23:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 86.09 toks/s, output: 32.45 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.56s/it, est. speed input: 86.09 toks/s, output: 32.45 toks/s]
[2025-03-21 23:23:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.45s/it, est. speed input: 110.26 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.45s/it, est. speed input: 110.26 toks/s, output: 32.20 toks/s]
[2025-03-21 23:24:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 95.44 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.70s/it, est. speed input: 95.44 toks/s, output: 32.31 toks/s]
[2025-03-21 23:24:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 97.53 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 97.53 toks/s, output: 32.24 toks/s]
[2025-03-21 23:25:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.79s/it, est. speed input: 164.86 toks/s, output: 33.05 toks/s]Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.79s/it, est. speed input: 164.86 toks/s, output: 33.05 toks/s]
[2025-03-21 23:25:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.23s/it, est. speed input: 429.56 toks/s, output: 29.75 toks/s]Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.23s/it, est. speed input: 429.56 toks/s, output: 29.75 toks/s]
[2025-03-21 23:25:37] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.85s/it, est. speed input: 187.48 toks/s, output: 31.57 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.85s/it, est. speed input: 187.48 toks/s, output: 31.57 toks/s]
[2025-03-21 23:25:55] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.66s/it, est. speed input: 103.29 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.66s/it, est. speed input: 103.29 toks/s, output: 32.24 toks/s]
[2025-03-21 23:26:24] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.12s/it, est. speed input: 113.30 toks/s, output: 32.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.12s/it, est. speed input: 113.30 toks/s, output: 32.16 toks/s]
[2025-03-21 23:26:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.07s/it, est. speed input: 120.11 toks/s, output: 32.11 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.07s/it, est. speed input: 120.11 toks/s, output: 32.11 toks/s]
[2025-03-21 23:27:15] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 92.09 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.67s/it, est. speed input: 92.09 toks/s, output: 32.34 toks/s]
[2025-03-21 23:27:48] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 97.10 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.76s/it, est. speed input: 97.10 toks/s, output: 32.24 toks/s]
[2025-03-21 23:28:20] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.93s/it, est. speed input: 98.29 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.93s/it, est. speed input: 98.29 toks/s, output: 32.31 toks/s]
[2025-03-21 23:28:49] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.64s/it, est. speed input: 161.82 toks/s, output: 31.92 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.64s/it, est. speed input: 161.82 toks/s, output: 31.92 toks/s]
[2025-03-21 23:29:06] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 92.63 toks/s, output: 32.41 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.60s/it, est. speed input: 92.63 toks/s, output: 32.41 toks/s]
[2025-03-21 23:29:38] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.24s/it, est. speed input: 174.21 toks/s, output: 31.76 toks/s]Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.25s/it, est. speed input: 174.21 toks/s, output: 31.76 toks/s]
[2025-03-21 23:29:54] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 92.13 toks/s, output: 32.34 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.66s/it, est. speed input: 92.13 toks/s, output: 32.34 toks/s]
[2025-03-21 23:30:27] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.63s/it, est. speed input: 90.88 toks/s, output: 32.38 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.63s/it, est. speed input: 90.88 toks/s, output: 32.38 toks/s]
[2025-03-21 23:30:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 93.95 toks/s, output: 32.33 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.68s/it, est. speed input: 93.95 toks/s, output: 32.33 toks/s]
[2025-03-21 23:31:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.28s/it, est. speed input: 107.27 toks/s, output: 32.26 toks/s]Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.28s/it, est. speed input: 107.27 toks/s, output: 32.26 toks/s]
[2025-03-21 23:31:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.81s/it, est. speed input: 146.95 toks/s, output: 32.01 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.81s/it, est. speed input: 146.95 toks/s, output: 32.01 toks/s]
[2025-03-21 23:32:19] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.29s/it, est. speed input: 111.75 toks/s, output: 32.23 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.29s/it, est. speed input: 111.75 toks/s, output: 32.23 toks/s]
[2025-03-21 23:32:45] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.74s/it, est. speed input: 128.95 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.74s/it, est. speed input: 128.95 toks/s, output: 32.22 toks/s]
[2025-03-21 23:33:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 25.00s/it, est. speed input: 114.32 toks/s, output: 32.20 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.00s/it, est. speed input: 114.32 toks/s, output: 32.20 toks/s]
[2025-03-21 23:33:30] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.94s/it, est. speed input: 1587.86 toks/s, output: 20.63 toks/s]Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.94s/it, est. speed input: 1587.86 toks/s, output: 20.63 toks/s]
[2025-03-21 23:33:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 79.72 toks/s, output: 32.60 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 79.72 toks/s, output: 32.60 toks/s]
[2025-03-21 23:34:05] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.34s/it, est. speed input: 188.82 toks/s, output: 31.87 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.34s/it, est. speed input: 188.82 toks/s, output: 31.87 toks/s]
[2025-03-21 23:34:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.69s/it, est. speed input: 98.02 toks/s, output: 33.17 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.69s/it, est. speed input: 98.02 toks/s, output: 33.17 toks/s]
[2025-03-21 23:34:44] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.66s/it, est. speed input: 188.83 toks/s, output: 31.78 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.66s/it, est. speed input: 188.83 toks/s, output: 31.78 toks/s]
[2025-03-21 23:34:58] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 94.72 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 94.72 toks/s, output: 32.27 toks/s]
[2025-03-21 23:35:31] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.95s/it, est. speed input: 200.96 toks/s, output: 31.56 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.95s/it, est. speed input: 200.96 toks/s, output: 31.56 toks/s]
[2025-03-21 23:35:46] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 79.07 toks/s, output: 32.60 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.41s/it, est. speed input: 79.07 toks/s, output: 32.60 toks/s]
[2025-03-21 23:36:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 96.62 toks/s, output: 32.27 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.73s/it, est. speed input: 96.62 toks/s, output: 32.27 toks/s]
[2025-03-21 23:36:50] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.32s/it, est. speed input: 144.16 toks/s, output: 31.95 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.32s/it, est. speed input: 144.16 toks/s, output: 31.95 toks/s]
[2025-03-21 23:37:11] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.92s/it, est. speed input: 122.08 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.92s/it, est. speed input: 122.08 toks/s, output: 32.31 toks/s]
[2025-03-21 23:37:33] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.41s/it, est. speed input: 96.88 toks/s, output: 32.48 toks/s]Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.41s/it, est. speed input: 96.88 toks/s, output: 32.48 toks/s]
[2025-03-21 23:37:59] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.21s/it, est. speed input: 210.55 toks/s, output: 31.65 toks/s]Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.21s/it, est. speed input: 210.55 toks/s, output: 31.65 toks/s]
[2025-03-21 23:38:13] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.63s/it, est. speed input: 186.68 toks/s, output: 31.72 toks/s]Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.63s/it, est. speed input: 186.68 toks/s, output: 31.72 toks/s]
[2025-03-21 23:38:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.52s/it, est. speed input: 222.21 toks/s, output: 33.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.52s/it, est. speed input: 222.21 toks/s, output: 33.16 toks/s]
[2025-03-21 23:38:41] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.29s/it, est. speed input: 139.53 toks/s, output: 31.99 toks/s]Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.29s/it, est. speed input: 139.53 toks/s, output: 31.99 toks/s]
[2025-03-21 23:39:02] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.62s/it, est. speed input: 112.27 toks/s, output: 32.24 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.62s/it, est. speed input: 112.27 toks/s, output: 32.24 toks/s]
[2025-03-21 23:39:28] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.85s/it, est. speed input: 98.52 toks/s, output: 32.15 toks/s]Processed prompts: 100%|██████████| 1/1 [00:31<00:00, 31.85s/it, est. speed input: 98.52 toks/s, output: 32.15 toks/s]
[2025-03-21 23:40:00] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.27s/it, est. speed input: 106.36 toks/s, output: 32.22 toks/s]Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.27s/it, est. speed input: 106.36 toks/s, output: 32.22 toks/s]
[2025-03-21 23:40:29] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.70s/it, est. speed input: 137.08 toks/s, output: 31.98 toks/s]Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.70s/it, est. speed input: 137.08 toks/s, output: 31.98 toks/s]
[2025-03-21 23:40:52] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.69s/it, est. speed input: 105.48 toks/s, output: 32.31 toks/s]Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.69s/it, est. speed input: 105.48 toks/s, output: 32.31 toks/s]
[2025-03-21 23:41:18] INFO _client.py:1038: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Using Local Model
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.40s/it, est. speed input: 134.78 toks/s, output: 32.16 toks/s]Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.40s/it, est. speed input: 134.78 toks/s, output: 32.16 toks/s]
level3 Generation Success

Total testing execution time: 7231.83 seconds
finished
