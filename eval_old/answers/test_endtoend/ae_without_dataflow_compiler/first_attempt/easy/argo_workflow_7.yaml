apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: http-wf-
spec:
  arguments:
    parameters:
    - name: width
    - name: height
  entrypoint: main
  templates:
  - name: main
    inputs:
      parameters:
      - name: width
      - name: height
    dag:
      tasks:
      - name: t1
        template: tti-graffiti-art
        arguments:
          parameters:
          - name: prompt
            value: Urban jungle
        dependencies: []
      - name: t2
        template: image-resizing
        arguments:
          parameters:
          - name: width
            value: '{{inputs.parameters.width}}'
          - name: height
            value: '{{inputs.parameters.height}}'
          - name: file
            value: '{{tasks.t1.outputs.result}}'
        dependencies: [t1]
  - name: tti-graffiti-art
    inputs:
      parameters:
      - name: prompt
    outputs:
      parameters:
      - name: result
        valueFrom:
          path: /tmp/generated_img.png
    script:
      image: python:3.8
      command: [python]
      source: |
        from fastapi import FastAPI, HTTPException
        from fastapi.responses import FileResponse

        from PIL import Image
        from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
        import torch
        from pydantic import BaseModel
        from pathlib import Path

        app = FastAPI()

        def load_model():
            model_id = 'bakebrain/bergraffi-berlin-graffiti'
            pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
            pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
            pipe = pipe.to('cuda')
            return pipe

        def process_data(prompt, pipe):
            response = pipe(prompt).images[0]
            return response

        @app.post("/generate_grafiti_image/")
        async def generate_image(prompt:str):
            try:
                # Load the model (replace load_model() with your actual model loading logic)
                pipe = load_model()

                # Prompt Creation
                prompt = "Grafiti-style picture: " + prompt

                # Process the data (replace process_data() with your actual data processing logic)
                response = process_data(prompt, pipe)

                ## Save the image
                filepath = '/tmp/generated_img.png'
                response.save(filepath)
                return FileResponse(filepath)

            except Exception as e:
                # Handle exceptions or errors here
                raise HTTPException(status_code=500, detail=str(e))
  - name: image-resizing
    inputs:
      parameters:
      - name: width
      - name: height
      - name: file
    outputs:
      parameters:
      - name: result
        valueFrom:
          path: /tmp/resized_image.png
    script:
      image: python:3.8
      command: [python]
      source: |-
        from fastapi import FastAPI, HTTPException, File, UploadFile
        from fastapi.responses import FileResponse
        from PIL import Image
        import io
        import os

        app = FastAPI()

        @app.post('/resize_image/')
        async def resize_image(width: int, height: int, file: UploadFile):
            try:
                # Read the uploaded file contents
                contents = await file.read()

                image = Image.open(io.BytesIO(contents))
                
                # Resize the image
                resized = image.resize((width, height))
                
                # Saving the resized image to a temporary file
                filename = "/tmp/resized_image.png"
                resized.save(filename)

                return FileResponse(filename, media_type="image/png", filename="output.png")
            
            except Exception as e:
                # Handle exceptions or errors here
                raise HTTPException(status_code=500, detail=str(e))
