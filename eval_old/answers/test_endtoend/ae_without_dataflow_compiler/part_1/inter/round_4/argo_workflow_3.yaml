"```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName:
http-wf-\nspec:\n  arguments:\n    parameters:\n    - name: width\n  entrypoint: main\n\
\  templates:\n  - name: main\n    inputs:\n    parameters:\n    - name: width\n \
\   dag:\n      tasks:\n      - name: t1\n        template: tti-Pastel-Art\n     \
\   arguments:\n          parameters:\n          - name: prompt\n            value:
\"Create a pastel art image of a sunset over the ocean.\"\n        dependencies: []\n\
\      - name: t2\n        template: image-enhancement\n        arguments:\n     \
\     parameters:\n          - name: file\n            value: '{{{{ tasks.t1.outputs.artifact
}}}}'\n        dependencies:\n        - t1\n      - name: t3\n        template: email-sender\n\
\        arguments:\n          parameters:\n          - name: file\n            value:
'{{{{ tasks.t2.outputs.artifact }}}}'\n        dependencies:\n        - t2\n\n  -
name: tti-Pastel-Art\n    inputs:\n    parameters:\n    - name: prompt\n    container:\n\
\      image: python:3.8\n      command: [\"python\", \"-c\"]\n      args: \n    \
\  - |\n        from fastapi import FastAPI, HTTPException\n        from fastapi.responses
import FileResponse\n        from PIL import Image\n        from diffusers import
StableDiffusionPipeline, DPMSolverMultistepScheduler\n        import torch\n     \
\   \n        def load_model():\n            model_id = 'JamesFlare/pastel-mix'\n\
\            pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n\
\            pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n\
\            pipe = pipe.to('cuda')\n            return pipe\n\n        def process_data(prompt,
pipe):\n            response = pipe(prompt).images[0]\n            return response\n\
\n        app = FastAPI()\n\n        @app.post(\"/generate_pastel_image/\")\n    \
\    async def generate_image(prompt: str):\n            try:\n                pipe
= load_model()\n                prompt = \"Pastel-style picture: \" + prompt\n   \
\             response = process_data(prompt, pipe)\n                response.save('generated_img.png')\n\
\                image_path = Path('generated_img.png')\n                if not image_path.is_file():\n\
\                    return {\"error\": \"Image not found on the server\"}\n     \
\           return FileResponse(image_path)\n            except Exception as e:\n\
\                raise HTTPException(status_code=500, detail=str(e))\n\n  - name:
image-enhancement\n    inputs:\n    parameters:\n    - name: file\n    container:\n\
\      image: python:3.8\n      command: [\"python\", \"-c\"]\n      args: \n    \
\  - |\n        from fastapi import FastAPI, HTTPException, File, UploadFile\n   \
\     from fastapi.responses import FileResponse\n        import cv2\n        import
numpy as np\n        from PIL import Image\n        from pathlib import Path\n\n \
\       SUPPORTED_FORMATS = [\n            \".bmp\", \".dib\",\n            \".jpeg\"\
, \".jpg\", \".jpe\",\n            \".jp2\",\n            \".png\",\n            \"\
.webp\",\n            \".avif\",\n            \".pbm\", \".pgm\", \".ppm\", \".pxm\"\
, \".pnm\",\n            \".pfm\",\n            \".sr\", \".ras\",\n            \"\
.tiff\", \".tif\",\n            \".exr\",\n            \".hdr\", \".pic\"\n      \
\  ]\n\n        app = FastAPI()\n\n        @app.post('/image_enhance/')\n        async
def enhance_image(file: UploadFile):\n            try:\n                image_name
= file.filename\n                image = Image.open(file.file)\n                image.save(image_name)\n\
\                img = cv2.imread(image_name)\n                denoised_image = cv2.fastNlMeansDenoisingColored(img,
None, 10, 10, 7, 21)\n                contrast_stretched_image = cv2.normalize(denoised_image,
None, 255, 0, cv2.NORM_MINMAX, cv2.CV_8UC1)\n                kernel = np.array([[0,
-1, 0], [-1, 5, -1], [0, -1, 0]], np.float32)\n                sharpened_image = cv2.filter2D(contrast_stretched_image,
-1, kernel=kernel)\n                brightness_image = cv2.convertScaleAbs(sharpened_image,
alpha=1, beta=5)\n                gamma = 1.5\n                lookup_table = np.array([((i
/ 255.0) ** gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n        \
\        gamma_corrected_image = cv2.LUT(brightness_image, lookup_table"
