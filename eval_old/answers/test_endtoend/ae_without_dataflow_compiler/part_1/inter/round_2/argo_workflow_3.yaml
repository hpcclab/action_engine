apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: http-wf-
spec:
  entrypoint: main
  templates:
  - name: main
    dag:
      tasks:
      - name: t1
        template: tti-Pastel-Art
        arguments:
          parameters:
          - name: prompt
            value: sunset over the ocean
      - name: t2
        template: Image-Enhancement
        arguments:
          artifacts:
          - name: file
            from: '{{tasks.t1.outputs.artifacts.generated_image}}'
        dependencies: [t1]

  - name: tti-Pastel-Art
    inputs:
      parameters:
      - name: prompt
    outputs:
      artifacts:
      - name: generated_image
        path: /tmp/generated_img.png
    script:
      image: python:3.8
      command: [sh, -c]
      source: |
        cd /tmp
        cat << 'EOF' > script.py
        from fastapi import FastAPI, HTTPException
        from fastapi.responses import FileResponse
        from PIL import Image
        from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
        import torch
        from pydantic import BaseModel
        from pathlib import Path

        app = FastAPI()

        def load_model():
            model_id = 'JamesFlare/pastel-mix'
            pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
            pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
            pipe = pipe.to('cuda')
            return pipe

        def process_data(prompt, pipe):
            response = pipe(prompt).images[0]
            return response

        prompt = "Pastel-style picture: " + prompt
        try:
            pipe = load_model()
            response = process_data(prompt, pipe)
            response.save('generated_img.png')
            print("generated_img.png")
        except Exception as e:
            raise Exception(str(e))
        EOF
        python script.py

  - name: Image-Enhancement
    inputs:
      artifacts:
      - name: file
        path: /tmp/input_image.png
    outputs:
      artifacts:
      - name: enhanced_image
        path: /tmp/final_enhanced_image.jpg
    script:
      image: python:3.8
      command: [sh, -c]
      source: |-
        cd /tmp
        cat << 'EOF' > script.py
        from fastapi import FastAPI, HTTPException, File, UploadFile
        from fastapi.responses import FileResponse
        from pathlib import Path
        import cv2
        import numpy as np
        from PIL import Image

        file_path = "input_image.png"
        SUPPORTED_FORMATS = [".bmp", ".dib", ".jpeg", ".jpg", ".jpe", ".jp2", ".png", ".webp", ".avif", ".pbm", ".pgm", ".ppm", ".pxm", ".pnm", ".pfm", ".sr", ".ras", ".tiff", ".tif", ".exr", ".hdr", ".pic"]

        try:
            image_name = file_path
            image = Image.open(file_path)
            image.save(image_name)

            img = cv2.imread(image_name)

            denoised_image = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)
            contrast_stretched_image = cv2.normalize(denoised_image, None, 255, 0, cv2.NORM_MINMAX, cv2.CV_8UC1)
            kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32)
            sharpened_image = cv2.filter2D(contrast_stretched_image, -1, kernel=kernel)
            brightness_image = cv2.convertScaleAbs(sharpened_image, alpha=1, beta=5)
            gamma = 1.5
            lookup_table = np.array([((i / 255.0) ** gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
            gamma_corrected_image = cv2.LUT(brightness_image, lookup_table)

            final_name = 'final_enhanced_image.jpg'
            cv2.imwrite(final_name, gamma_corrected_image)
            print(final_name)
        except Exception as e:
            raise Exception(str(e))
        EOF
        python script.py
