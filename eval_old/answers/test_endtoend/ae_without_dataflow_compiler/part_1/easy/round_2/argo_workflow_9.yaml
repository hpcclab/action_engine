"```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName:
http-wf-\nspec:\n  arguments:\n    parameters:\n    - name: width\n  entrypoint: main\n\
\  templates:\n    - name: main\n      inputs:\n        parameters:\n        - name:
width\n      dag:\n        tasks:\n        - name: t1\n          template: tti_Sketching_Art\n\
\          arguments:\n            parameters:\n            - name: prompt\n     \
\         value: 'A bustling marketplace'\n          \n        - name: t2\n      \
\    template: image_to_pdf_conversion\n          arguments:\n            parameters:\n\
\            - name: file\n              value: '{{tasks.t1.outputs.art_image}}'\n\
\          dependencies:\n          - t1\n\n    - name: tti_Sketching_Art\n      inputs:\n\
\        parameters:\n        - name: prompt\n      outputs:\n        parameters:\n\
\        - name: art_image\n          valueFrom:\n            path: /outputs/generated_img.png\n\
\      script:\n        image: python:3.8\n        command: [python]\n        source:
|\n          from fastapi import FastAPI, HTTPException\n          from fastapi.responses
import FileResponse\n          from pydantic import BaseModel\n          from pathlib
import Path\n          from PIL import Image\n          import torch\n          from
diffusers import (\n              StableDiffusionXLPipeline, \n              EulerAncestralDiscreteScheduler,\n\
\              AutoencoderKL\n          )\n          app = FastAPI()\n\n         \
\ @app.post(\"/generate_sketching_image/\")\n          async def generate_image(prompt:str):\n\
\              try:\n                  # Initialize LoRA model and weights\n     \
\             lora_model_id = \"Linaqruf/sketch-style-xl-lora\"\n                \
\  lora_filename = \"sketch-style-xl.safetensors\"\n\n                  # Load VAE
component\n                  vae = AutoencoderKL.from_pretrained(\n              \
\        \"madebyollin/sdxl-vae-fp16-fix\", \n                      torch_dtype=torch.float16\n\
\                  )\n\n                  # Configure the pipeline\n             \
\     pipe = StableDiffusionXLPipeline.from_pretrained(\n                      \"\
Linaqruf/animagine-xl-2.0\", \n                      vae=vae,\n                  \
\    torch_dtype=torch.float16, \n                      use_safetensors=True, \n \
\                     variant=\"fp16\"\n                  )\n                  pipe.scheduler
= EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n           \
\       pipe.to('cuda')\n\n                  # Load and fuse LoRA weights\n      \
\            pipe.load_lora_weights(lora_model_id, weight_name=lora_filename)\n  \
\                pipe.fuse_lora(lora_scale=0.6)\n\n                  # Define prompts
and generate image\n                  prompt = \"Monochrome, Greyscale Sketch-style
picture: \" + prompt\n\n                  negative_prompt = \"lowres, bad anatomy,
bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst
quality, low quality, normal quality, jpeg artifacts, signature, watermark, username,
blurry\"\n\n                  image = pipe(\n                      prompt, \n    \
\                  negative_prompt=negative_prompt, \n                      width=1024,\n\
\                      height=1024,\n                      guidance_scale=12,\n  \
\                    num_inference_steps=50\n                  ).images[0]\n\n   \
\               # Unfuse LoRA before saving the image\n                  pipe.unfuse_lora()\n\
\                  image.save(\"/outputs/generated_img.png\")\n\n                \
\  image_path = Path('/outputs/generated_img.png')\n                  if not image_path.is_file():\n\
\                      raise HTTPException(status_code=404, detail=\"Image not found
on the server\")\n                  return FileResponse(image_path)\n            \
\  except Exception as e:\n                  # Handle exceptions or errors here\n\
\                  raise HTTPException(status_code=500, detail=str(e))\n\n    - name:
image_to_pdf_conversion\n      inputs:\n        parameters:\n        - name: file\n\
\      script:\n        image: python:3.8\n        command: [python]\n        source:
|\n          from fastapi import FastAPI, File, UploadFile, HTTPException\n      \
\    from fastapi.responses import FileResponse\n          from pathlib import Path\n\
\          from PIL import Image\n          import img2pdf\n\n          app = FastAPI()\n\
\n          # Define the supported image extensions\n          supported_extensions
= [\".JPEG\", \".PNG\", \".GIF\", \".BMP\", \".TIFF\", \".PBM\", \".PGM\", \".PPM\"\
]\n\n          def check_file_extension(file_path):\n              file_extension
= file_path.suffix.upper()\n              if file_extension not in supported_extensions:\n\
\                  return False\n              return True\n\n          @app.post(\"\
/convert_to_pdf/\")\n          async def image_to_pdf(file: UploadFile):\n       \
\       try:\n                  file_path = Path(file.filename)\n                \
\  file_name = file_path.stem\n\n                  # File format support check\n \
\                 if not check_file_extension(file_path"
