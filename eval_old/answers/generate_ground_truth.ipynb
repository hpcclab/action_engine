{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    # If running as a script, use __file__ to find the directory\n",
    "    __file__\n",
    "    base_path = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))\n",
    "    sys.path.append(base_path)\n",
    "    \n",
    "except NameError:\n",
    "    # If running in an interactive environment (e.g., Jupyter Notebook)\n",
    "    base_path = Path().resolve().parent.parent\n",
    "    sys.path.append(str(base_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "  temperature=0,\n",
    "  api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "from utils.llm import call_llm\n",
    "# Local\n",
    "# filepath_apiinfo = \"/home/UNT/ae0589/Desktop/HPCC/AutomaticWorkflowGeneration/ActionEngine/db/api_info/api_information.json\"\n",
    "#filepath = \"/home/UNT/ae0589/Desktop/HPCC/AutomaticWorkflowGeneration/ActionEngine/eval/answers/\"\n",
    "\n",
    "#Cloud\n",
    "filepath_apiinfo = filepath_apiinfo = \"/home/cc/AutomaticWorkflowGeneration/ActionEngine/db/api_info/api_information.json\"\n",
    "filepath = \"/home/cc/AutomaticWorkflowGeneration/ActionEngine/eval/answers/\"\n",
    "\n",
    "filename_query_1to2 = filepath + 'test_queries/query_answer_1-2_nodes.json'\n",
    "filename_query_3to5 = filepath + 'test_queries/query_answer_3-5_nodes.json'\n",
    "filename_query_6to10 = filepath + 'test_queries/query_answer_6-10_nodes.json'\n",
    "\n",
    "def read_json_to_dict(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def escape_json(text: str) -> str:\n",
    "    return text.replace('{', '{{').replace('}', '}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate GT for Easy Dataset (1-2 Nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate TaskList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/UNT/ae0589/anaconda3/envs/ae/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SubTask Division\n",
    "\"\"\"\n",
    "from utils.schemas.workflow import Tasks\n",
    "from utils.subtask_div import subtask_diviser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-2 nodes\n",
    "q_1to2 = read_json_to_dict(filename_query_1to2)\n",
    "# Extract specific fields\n",
    "extracted_data = [\n",
    "    {\n",
    "        'id': item['id'],\n",
    "        'user_request': item['user_request'],\n",
    "        'selected_apis': item['selected_apis']\n",
    "    }\n",
    "    for item in q_1to2[\"test_data\"]\n",
    "]\n",
    "\n",
    "tasklists = []\n",
    "for i in range(len(extracted_data)):\n",
    "    tasklist = subtask_diviser(extracted_data[i][\"user_request\"])\n",
    "    t = {\"id\":extracted_data[i][\"id\"], \"node_number\": len(tasklist), \"user_query\": extracted_data[i][\"user_request\"] ,\"task_list\":tasklist, \"selected_apis\":extracted_data[i][\"selected_apis\"]}\n",
    "    tasklists.append(t)\n",
    "with open('./test_tasklist/tasklist_GTlabel_1-2_nodes.json', 'w') as json_file:\n",
    "    json.dump(tasklists, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ->Check the generated tasklist and selected functions manually before proceed further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate topological order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Workflow Optimizer\n",
    "\"\"\"\n",
    "from utils.schemas.workflow import Workflow\n",
    "from utils.wf_optimizer import wf_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2 Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate Topological Order\n",
    "1. Confirm the correctness of topological order manually\n",
    "\"\"\"\n",
    "filename_tasklist_1to2 = filepath + 'test_tasklist/tasklist_GTlabel_1-2_nodes.json'\n",
    "\n",
    "top_orders = read_json_to_dict(filename_tasklist_1to2)\n",
    "for i in range(len(extracted_data)):\n",
    "    topological_order = wf_optimizer(extracted_data[i][\"user_request\"], top_orders[i][\"task_list\"])\n",
    "    top_orders[i][\"topological_order\"] = topological_order\n",
    "\n",
    "with open('./test_topologicalorder/topologicalorder_GTlabel_1-2_nodes.json', 'w') as json_file:\n",
    "    json.dump(top_orders, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manually confirm the correctness of topological order manually before proceed nexr step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate Ground Truth for Topological Order\n",
    "\"\"\"\n",
    "# Read\n",
    "filename_topologiacal_1to2 = filepath + 'test_topologicalorder/topologicalorder_GTlabel_1-2_nodes.json'\n",
    "top_orders = read_json_to_dict(filename_topologiacal_1to2)\n",
    "\n",
    "# Generate order list \n",
    "for i in range(len(top_orders)):\n",
    "    # print(top_order[i][\"id\"])\n",
    "    node = top_orders[i][\"topological_order\"]  \n",
    "    order_list = [d[\"task_nums\"] for d in node]\n",
    "    top_orders[i][\"list_of_orders\"] = order_list\n",
    "    # print(order_list)\n",
    "\n",
    "for i in range(len(top_orders)):\n",
    "    # Flatten the list_of_orders into a single list of numbers\n",
    "    flattened_orders = [num for sublist in top_orders[i]['list_of_orders'] for num in sublist]\n",
    "\n",
    "    # Initialize the result list\n",
    "    result = []\n",
    "\n",
    "    # Generate the pairs for each number\n",
    "    for j, current_num in enumerate(flattened_orders):\n",
    "        pairs = []\n",
    "        for k in range(j + 1, len(flattened_orders)):\n",
    "            next_num = flattened_orders[k]\n",
    "            pairs.append(f\"{current_num} < {next_num}\")\n",
    "        \n",
    "        # Add the result for the current number\n",
    "        result.append({\"num\": current_num, \"pairs\": pairs})\n",
    "    top_orders[i][\"pairs\"] = result\n",
    "    print(top_orders[i][\"pairs\"])\n",
    "\n",
    "    topological_order_gt_1to2_nodes = [\n",
    "    {\n",
    "        'id': item[\"id\"],\n",
    "        'topological_order': item[\"topological_order\"],\n",
    "        'list_of_orders': item[\"list_of_orders\"],\n",
    "        'label': item[\"pairs\"],\n",
    "    } for item in top_orders]\n",
    "\n",
    "    with open('./test_topologicalorder/topologicalorder_GTlabel_1-2_nodes.json', 'w') as json_file:\n",
    "        json.dump(topological_order_gt_1to2_nodes, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ->Check the generated topological orders manually before proceed further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data Dependency Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare selected function list to feed into function of data dependency management\n",
    "\"\"\"\n",
    "filename_tasklist = filepath + 'test_tasklist/tasklist_GTlabel_1-2_nodes.json'\n",
    "filename_topologicalorder = filepath + 'test_topologicalorder/topologicalorder_GTlabel_1-2_nodes.json'\n",
    "\n",
    "def read_apiinfo(filename):\n",
    "    api_info = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            api_info.append(json.loads(line))\n",
    "\n",
    "    return api_info\n",
    "\n",
    "api_info = read_apiinfo(filepath_apiinfo)\n",
    "top_orders = read_json_to_dict(filename_topologicalorder)\n",
    "data = read_json_to_dict(filename_tasklist)\n",
    "\n",
    "# Loop over both lists and add 'topological_order' to the corresponding item in data\n",
    "for i in range(len(top_orders)):\n",
    "    # Assuming the length of top_orders and data is the same\n",
    "    data[i]['topological_order'] = top_orders[i]['topological_order']\n",
    "\n",
    "extracted_api_names = [\n",
    "    {\n",
    "        'id': item['id'],\n",
    "        'task_list': item[\"task_list\"],\n",
    "        'selected_apis': item['selected_apis']\n",
    "    }\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "all_task_info = []\n",
    "# Concatenate by same index\n",
    "for i in range(len(extracted_api_names)):\n",
    "    concatenated_list = [[task, api] for task, api in zip(extracted_api_names[i][\"task_list\"], extracted_api_names[i][\"selected_apis\"])]\n",
    "    combined_dicts = [{**dict1, **dict2} for dict1, dict2 in concatenated_list]\n",
    "    all_task_info.append(combined_dicts)\n",
    "\n",
    "# Extract all api names from api repositories\n",
    "all_api_names = [item[\"name\"] for item in api_info]\n",
    "\n",
    "# Retrieve apis' infomation\n",
    "for i in range(len(all_task_info)):\n",
    "    selected_functions = []\n",
    "    for task in all_task_info[i]:\n",
    "        if task[\"name\"] in all_api_names:\n",
    "            for func in api_info: \n",
    "                if task[\"name\"] == func[\"name\"]:\n",
    "                    selected_func = func.copy()  # Make a copy to avoid mutating the original\n",
    "                    selected_func[\"task_num\"] = int(task[\"task_number\"])\n",
    "                    selected_func[\"task_description\"] = task[\"task_description\"]\n",
    "                    selected_functions.append(selected_func)\n",
    "        data[i][\"selected_functions\"] = selected_functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dependency Management\n",
    "\"\"\"\n",
    "from utils.data_dependency import confirm_dependency\n",
    "from utils.schemas.workflow import TaskOutputDescription, DependentParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/miniconda3/envs/ml/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The function `convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.3.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For classification of data dependency \n",
    "\"\"\"\n",
    "for i in range(len(data)):\n",
    "    selected_functions, user_inputs, depended_params = confirm_dependency(data[i][\"topological_order\"], data[i][\"selected_functions\"])\n",
    "    func_list = []\n",
    "    for api in selected_functions:\n",
    "        all_params = [component['name'] for component in api[\"input_parameters_with_datatype\"]]\n",
    "        depended_params = [list(item.keys())[0] for item in api[\"depended_params\"]]\n",
    "        user_inputs = [param for param in all_params if param not in depended_params]\n",
    "        func_list.append({\"name\": api[\"name\"], \"all_params\": all_params, \"user_input\": user_inputs, \"dependent_params\": depended_params})\n",
    "    data[i][\"param_dependency_management\"] = func_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save Data Dependency Management test data\n",
    "- classification of user_input and dependent_param\n",
    "- correctness of dependednt_param \n",
    "\"\"\"\n",
    "dd_data = [\n",
    "    {\n",
    "        'id': item['id'],\n",
    "        \"number_of_node\": len(item[\"task_list\"]),\n",
    "        'task_list': item[\"task_list\"],\n",
    "        \"topological_order\": item[\"topological_order\"],\n",
    "        'selected_apis': [{\n",
    "            \"name\": api[\"name\"], \n",
    "            \"input_params\": api[\"input_parameters_with_datatype\"],\n",
    "            \"dependencies\": api[\"dependencies\"],\n",
    "            \"depended_params\": api[\"depended_params\"],\n",
    "            } for api in item['selected_functions']],\n",
    "        'param_dependency_management': item[\"param_dependency_management\"]\n",
    "    }\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "with open('./test_datadependency/datadep_GTlabel_1-2_nodes.json', 'w') as json_file:\n",
    "    json.dump(dd_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Intermidiate 3-5 Nodes Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate TaskList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/UNT/ae0589/anaconda3/envs/ae/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SubTask Division\n",
    "\"\"\"\n",
    "from utils.schemas.workflow import Tasks\n",
    "from utils.subtask_div import subtask_diviser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-2 nodes\n",
    "q_3to5 = read_json_to_dict(filename_query_3to5)\n",
    "extracted_data = [\n",
    "    {\n",
    "        'id': item['id'],\n",
    "        'user_request': item['user_request'],\n",
    "        'selected_apis': item['selected_apis']\n",
    "    }\n",
    "    for item in q_3to5[\"test_data\"]\n",
    "]\n",
    "\n",
    "\n",
    "tasklists = []\n",
    "for i in range(len(extracted_data)):\n",
    "    tasklist = subtask_diviser(extracted_data[i][\"user_request\"])\n",
    "    t = {\"id\":extracted_data[i][\"id\"], \"node_number\": len(tasklist), \"user_query\": extracted_data[i][\"user_request\"] ,\"task_list\":tasklist, \"selected_apis\":extracted_data[i][\"selected_apis\"]}\n",
    "    tasklists.append(t)\n",
    "with open('./test_tasklist/tasklist_GTlabel_3-5_nodes.json', 'w') as json_file:\n",
    "    json.dump(tasklists, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ->Check the generated tasklist and selected functions manually before proceed further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate topological order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Workflow Optimizer\n",
    "\"\"\"\n",
    "from utils.schemas.workflow import Workflow\n",
    "from utils.wf_optimizer import wf_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate Topological Order\n",
    "\"\"\"\n",
    "filename_tasklist_3to5 = filepath + 'test_tasklist/tasklist_GTlabel_3-5_nodes.json'\n",
    "top_orders = read_json_to_dict(filename_tasklist_3to5)\n",
    "for i in range(len(extracted_data)):\n",
    "    topological_order = wf_optimizer(extracted_data[i][\"user_request\"], top_orders[i][\"task_list\"])\n",
    "    top_orders[i][\"topological_order\"] = topological_order\n",
    "\n",
    "with open('./test_topologicalorder/topologicalorder_GTlabel_3-5_nodes.json', 'w') as json_file:\n",
    "    json.dump(top_orders, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manually confirm the correctness of topological order manually before proceed nexr step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename_topologiacal_3to5 = filepath + 'test_topologicalorder/topologicalorder_GTlabel_3-5_nodes.json'\n",
    "top_orders = read_json_to_dict(filename_topologiacal_3to5)\n",
    "\n",
    "# Generate order list \n",
    "for i in range(len(top_orders)):\n",
    "    # print(top_order[i][\"id\"])\n",
    "    node = top_orders[i][\"topological_order\"]  \n",
    "    order_list = [d[\"task_nums\"] for d in node]\n",
    "    top_orders[i][\"list_of_orders\"] = order_list\n",
    "    # print(order_list)\n",
    "\n",
    "for i in range(len(top_orders)):\n",
    "    # Flatten the list_of_orders into a single list of numbers\n",
    "    flattened_orders = [num for sublist in top_orders[i]['list_of_orders'] for num in sublist]\n",
    "\n",
    "    # Initialize the result list\n",
    "    result = []\n",
    "\n",
    "    # Generate the pairs for each number\n",
    "    for j, current_num in enumerate(flattened_orders):\n",
    "        pairs = []\n",
    "        for k in range(j + 1, len(flattened_orders)):\n",
    "            next_num = flattened_orders[k]\n",
    "            pairs.append(f\"{current_num} < {next_num}\")\n",
    "        \n",
    "        # Add the result for the current number\n",
    "        result.append({\"num\": current_num, \"pairs\": pairs})\n",
    "    top_orders[i][\"pairs\"] = result\n",
    "    print(top_orders[i][\"pairs\"])\n",
    "\n",
    "topological_order_gt_3to5_nodes = [\n",
    "{\n",
    "    'id': item[\"id\"],\n",
    "    'topological_order': item[\"topological_order\"],\n",
    "    'list_of_orders': item[\"list_of_orders\"],\n",
    "    'label': item[\"pairs\"],\n",
    "} for item in top_orders]\n",
    "\n",
    "with open('./test_topologicalorder/topologicalorder_GTlabel_3-5_nodes.json', 'w') as json_file:\n",
    "    json.dump(topological_order_gt_3to5_nodes, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ->Check the generated topological orders manually before proceed further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data Dependency Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare selected function list to feed into function of data dependency management\n",
    "\"\"\"\n",
    "def read_apiinfo(filename):\n",
    "    api_info = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            api_info.append(json.loads(line))\n",
    "\n",
    "    return api_info\n",
    "\n",
    "api_info = read_apiinfo(filepath_apiinfo)\n",
    "top_orders = read_json_to_dict(filename_topologiacal_3to5)\n",
    "data = read_json_to_dict(filename_tasklist_3to5)\n",
    "\n",
    "# Loop over both lists and add 'topological_order' to the corresponding item in data\n",
    "for i in range(len(top_orders)):\n",
    "    # Assuming the length of top_orders and data is the same\n",
    "    data[i]['topological_order'] = top_orders[i]['topological_order']\n",
    "\n",
    "extracted_api_names = [\n",
    "    {\n",
    "        'id': item['id'],\n",
    "        'task_list': item[\"task_list\"],\n",
    "        'selected_apis': item['selected_apis']\n",
    "    }\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "all_task_info = []\n",
    "# Concatenate by same index\n",
    "for i in range(len(extracted_api_names)):\n",
    "    concatenated_list = [[task, api] for task, api in zip(extracted_api_names[i][\"task_list\"], extracted_api_names[i][\"selected_apis\"])]\n",
    "    combined_dicts = [{**dict1, **dict2} for dict1, dict2 in concatenated_list]\n",
    "    all_task_info.append(combined_dicts)\n",
    "\n",
    "# Extract all api names from api repositories\n",
    "all_api_names = [item[\"name\"] for item in api_info]\n",
    "\n",
    "# Retrieve apis' infomation\n",
    "for i in range(len(all_task_info)):\n",
    "    selected_functions = []\n",
    "    for task in all_task_info[i]:\n",
    "        if task[\"name\"] in all_api_names:\n",
    "            for func in api_info: \n",
    "                if task[\"name\"] == func[\"name\"]:\n",
    "                    selected_func = func.copy()  # Make a copy to avoid mutating the original\n",
    "                    selected_func[\"task_num\"] = int(task[\"task_number\"])\n",
    "                    selected_func[\"task_description\"] = task[\"task_description\"]\n",
    "                    selected_functions.append(selected_func)\n",
    "        data[i][\"selected_functions\"] = selected_functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dependency Management\n",
    "\"\"\"\n",
    "from utils.data_dependency import confirm_dependency\n",
    "from utils.schemas.workflow import TaskOutputDescription, DependentParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++\n",
      "{2: [1], 3: [2], 1: []}\n",
      "++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/UNT/ae0589/anaconda3/envs/ae/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The function `convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++\n",
      "{2: [1], 3: [2], 1: []}\n",
      "++++++++++++++++++++++++++\n",
      "++++++++++++++++++++++++++\n",
      "{2: [1], 3: [2], 1: []}\n",
      "++++++++++++++++++++++++++\n",
      "++++++++++++++++++++++++++\n",
      "{2: [1], 3: [2], 1: []}\n",
      "++++++++++++++++++++++++++\n",
      "++++++++++++++++++++++++++\n",
      "{2: [1], 3: [2], 4: [3], 5: [4], 1: []}\n",
      "++++++++++++++++++++++++++\n",
      "++++++++++++++++++++++++++\n",
      "{2: [1], 3: [2], 4: [3], 5: [4], 1: []}\n",
      "++++++++++++++++++++++++++\n",
      "++++++++++++++++++++++++++\n",
      "{2: [1], 3: [2], 4: [3], 5: [4], 1: []}\n",
      "++++++++++++++++++++++++++\n",
      "++++++++++++++++++++++++++\n",
      "{2: [1], 3: [2], 4: [3], 5: [4], 1: []}\n",
      "++++++++++++++++++++++++++\n",
      "++++++++++++++++++++++++++\n",
      "{2: [1], 3: [2], 4: [3], 5: [4], 1: []}\n",
      "++++++++++++++++++++++++++\n",
      "++++++++++++++++++++++++++\n",
      "{2: [1], 3: [2], 4: [3], 5: [4], 1: []}\n",
      "++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For classification of data dependency \n",
    "\"\"\"\n",
    "for i in range(len(data)):\n",
    "    selected_functions, user_inputs, depended_params = confirm_dependency(data[i][\"topological_order\"], data[i][\"selected_functions\"])\n",
    "    func_list = []\n",
    "    for api in selected_functions:\n",
    "        all_params = [component['name'] for component in api[\"input_parameters_with_datatype\"]]\n",
    "        depended_params = [list(item.keys())[0] for item in api[\"depended_params\"]]\n",
    "        user_inputs = [param for param in all_params if param not in depended_params]\n",
    "        func_list.append({\"name\": api[\"name\"], \"all_params\": all_params, \"user_input\": user_inputs, \"dependent_params\": depended_params})\n",
    "    data[i][\"param_dependency_management\"] = func_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save Data Dependency Management test data\n",
    "- classification of user_input and dependent_param\n",
    "- correctness of dependednt_param \n",
    "\"\"\"\n",
    "dd_data = [\n",
    "    {\n",
    "        'id': item['id'],\n",
    "        \"number_of_node\": len(item[\"task_list\"]),\n",
    "        'task_list': item[\"task_list\"],\n",
    "        \"topological_order\": item[\"topological_order\"],\n",
    "        'selected_apis': [{\n",
    "            \"name\": api[\"name\"], \n",
    "            \"input_params\": api[\"input_parameters_with_datatype\"],\n",
    "            \"dependencies\": api[\"dependencies\"],\n",
    "            \"depended_params\": api[\"depended_params\"],\n",
    "            } for api in item['selected_functions']],\n",
    "        'param_dependency_management': item[\"param_dependency_management\"]\n",
    "    }\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "with open('./test_datadependency/datadep_GTlabel_3-5_nodes.json', 'w') as json_file:\n",
    "    json.dump(dd_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate GT for Hard Dataset (6-10 Nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate TaskList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SubTask Division\n",
    "\"\"\"\n",
    "from utils.schemas.workflow import Tasks\n",
    "from utils.subtask_div import subtask_diviser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/miniconda3/envs/ml/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The function `convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "#1-2 nodes\n",
    "q_6to10 = read_json_to_dict(filename_query_6to10)\n",
    "extracted_data = [\n",
    "    {\n",
    "        'id': item['id'],\n",
    "        'user_request': item['user_request'],\n",
    "        'selected_apis': item['selected_apis']\n",
    "    }\n",
    "    for item in q_6to10[\"test_data\"]\n",
    "]\n",
    "\n",
    "\n",
    "tasklists = []\n",
    "for i in range(len(extracted_data)):\n",
    "    tasklist = subtask_diviser(extracted_data[i][\"user_request\"])\n",
    "    t = {\"id\":extracted_data[i][\"id\"], \"node_number\": len(tasklist), \"user_query\": extracted_data[i][\"user_request\"] ,\"task_list\":tasklist, \"selected_apis\":extracted_data[i][\"selected_apis\"]}\n",
    "    tasklists.append(t)\n",
    "with open('./test_tasklist/tasklist_GTlabel_6-10_nodes.json', 'w') as json_file:\n",
    "    json.dump(tasklists, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ->Check the generated tasklist and selected functions manually before proceed further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate topological order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Workflow Optimizer\n",
    "\"\"\"\n",
    "from utils.schemas.workflow import Workflow\n",
    "from utils.wf_optimizer import wf_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate Topological Order\n",
    "\"\"\"\n",
    "filename_tasklist_6to10 = filepath + 'test_tasklist/tasklist_GTlabel_6-10_nodes.json'\n",
    "top_orders = read_json_to_dict(filename_tasklist_3to5)\n",
    "for i in range(len(extracted_data)):\n",
    "    topological_order = wf_optimizer(extracted_data[i][\"user_request\"], top_orders[i][\"task_list\"])\n",
    "    top_orders[i][\"topological_order\"] = topological_order\n",
    "\n",
    "with open('./test_topologicalorder/topologicalorder_GTlabel_6-10_nodes.json', 'w') as json_file:\n",
    "    json.dump(top_orders, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manually confirm the correctness of topological order manually before proceed nexr step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'num': 1, 'pairs': ['1 < 4', '1 < 5', '1 < 6']}, {'num': 2, 'pairs': ['2 < 4', '2 < 5', '2 < 6']}, {'num': 3, 'pairs': ['3 < 4', '3 < 5', '3 < 6']}, {'num': 4, 'pairs': ['4 < 5', '4 < 6']}, {'num': 5, 'pairs': ['5 < 6']}, {'num': 6, 'pairs': []}]\n",
      "[{'num': 1, 'pairs': ['1 < 4', '1 < 5', '1 < 6']}, {'num': 2, 'pairs': ['2 < 4', '2 < 5', '2 < 6']}, {'num': 3, 'pairs': ['3 < 4', '3 < 5', '3 < 6']}, {'num': 4, 'pairs': []}, {'num': 5, 'pairs': []}, {'num': 6, 'pairs': []}]\n",
      "[{'num': 1, 'pairs': ['1 < 4', '1 < 5', '1 < 6', '1 < 7']}, {'num': 2, 'pairs': ['2 < 4', '2 < 5', '2 < 6', '2 < 7']}, {'num': 3, 'pairs': ['3 < 4', '3 < 5', '3 < 6', '3 < 7']}, {'num': 4, 'pairs': ['4 < 5', '4 < 6', '4 < 7']}, {'num': 5, 'pairs': ['5 < 6', '5 < 7']}, {'num': 6, 'pairs': ['6 < 7']}, {'num': 7, 'pairs': []}]\n",
      "[{'num': 1, 'pairs': ['1 < 4', '1 < 5', '1 < 6', '1 < 7']}, {'num': 2, 'pairs': ['2 < 4', '2 < 5', '2 < 6', '2 < 7']}, {'num': 3, 'pairs': ['3 < 4', '3 < 5', '3 < 6', '3 < 7']}, {'num': 4, 'pairs': ['4 < 7']}, {'num': 5, 'pairs': ['5 < 7']}, {'num': 6, 'pairs': ['6 < 7']}, {'num': 7, 'pairs': []}]\n",
      "[{'num': 1, 'pairs': ['1 < 2', '1 < 3', '1 < 4', '1 < 5', '1 < 6', '1 < 7', '1 < 8']}, {'num': 2, 'pairs': ['2 < 3', '2 < 4', '2 < 5', '2 < 6', '2 < 7', '2 < 8']}, {'num': 3, 'pairs': ['3 < 4', '3 < 5', '3 < 6', '3 < 7', '3 < 8']}, {'num': 4, 'pairs': ['4 < 5', '4 < 6', '4 < 7', '4 < 8']}, {'num': 5, 'pairs': ['5 < 6', '5 < 7', '5 < 8']}, {'num': 6, 'pairs': []}, {'num': 7, 'pairs': []}, {'num': 8, 'pairs': []}]\n",
      "[{'num': 1, 'pairs': ['1 < 5', '1 < 6', '1 < 7', '1 < 8']}, {'num': 2, 'pairs': ['2 < 5', '2 < 6', '2 < 7', '2 < 8']}, {'num': 3, 'pairs': ['3 < 5', '3 < 6', '3 < 7', '3 < 8']}, {'num': 4, 'pairs': ['4 < 5', '4 < 6', '4 < 7', '4 < 8']}, {'num': 5, 'pairs': []}, {'num': 6, 'pairs': []}, {'num': 7, 'pairs': []}, {'num': 8, 'pairs': []}]\n",
      "[{'num': 1, 'pairs': ['1 < 3', '1 < 4', '1 < 5', '1 < 6', '1 < 7', '1 < 8']}, {'num': 2, 'pairs': ['2 < 3', '2 < 4', '2 < 5', '2 < 6', '2 < 7', '2 < 8']}, {'num': 3, 'pairs': ['3 < 5', '3 < 6', '3 < 7', '3 < 8']}, {'num': 4, 'pairs': ['4 < 5', '4 < 6', '4 < 7', '4 < 8']}, {'num': 5, 'pairs': ['5 < 7', '5 < 8']}, {'num': 6, 'pairs': ['6 < 7', '6 < 8']}, {'num': 7, 'pairs': []}, {'num': 8, 'pairs': []}]\n",
      "[{'num': 1, 'pairs': []}, {'num': 2, 'pairs': []}, {'num': 3, 'pairs': []}, {'num': 4, 'pairs': []}, {'num': 5, 'pairs': []}, {'num': 6, 'pairs': []}, {'num': 7, 'pairs': []}, {'num': 8, 'pairs': []}, {'num': 9, 'pairs': []}]\n",
      "[{'num': 1, 'pairs': ['1 < 6', '1 < 7', '1 < 8', '1 < 9', '1 < 10']}, {'num': 2, 'pairs': ['2 < 6', '2 < 7', '2 < 8', '2 < 9', '2 < 10']}, {'num': 3, 'pairs': ['3 < 6', '3 < 7', '3 < 8', '3 < 9', '3 < 10']}, {'num': 4, 'pairs': ['4 < 6', '4 < 7', '4 < 8', '4 < 9', '4 < 10']}, {'num': 5, 'pairs': ['5 < 6', '5 < 7', '5 < 8', '5 < 9', '5 < 10']}, {'num': 6, 'pairs': ['6 < 7', '6 < 8', '6 < 9', '6 < 10']}, {'num': 7, 'pairs': ['7 < 8', '7 < 9', '7 < 10']}, {'num': 8, 'pairs': ['8 < 10']}, {'num': 9, 'pairs': ['9 < 10']}, {'num': 10, 'pairs': []}]\n",
      "[{'num': 1, 'pairs': []}, {'num': 2, 'pairs': []}, {'num': 3, 'pairs': []}, {'num': 4, 'pairs': []}, {'num': 5, 'pairs': []}, {'num': 6, 'pairs': []}, {'num': 7, 'pairs': []}, {'num': 8, 'pairs': []}, {'num': 9, 'pairs': []}, {'num': 10, 'pairs': []}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename_topologiacal_6to10 = filepath + 'test_topologicalorder/topologicalorder_GTlabel_6-10_nodes.json'\n",
    "top_orders = read_json_to_dict(filename_topologiacal_3to5)\n",
    "\n",
    "# Generate order list \n",
    "for i in range(len(top_orders)):\n",
    "    node = top_orders[i][\"topological_order\"]  \n",
    "    order_list = [d[\"task_nums\"] for d in node]\n",
    "    top_orders[i][\"list_of_orders\"] = order_list\n",
    "\n",
    "for i in range(len(top_orders)):\n",
    "    # Flatten the list_of_orders into a single list of numbers\n",
    "    flattened_orders = [num for sublist in top_orders[i]['list_of_orders'] for num in sublist]\n",
    "    result = []\n",
    "\n",
    "    # Generate the pairs for each number, but only with elements from subsequent sublists\n",
    "    for j, current_num in enumerate(flattened_orders):\n",
    "        pairs = []\n",
    "        current_index = None\n",
    "        for idx, sublist in enumerate(top_orders[i]['list_of_orders']):\n",
    "            if current_num in sublist:\n",
    "                current_index = idx\n",
    "                break\n",
    "        \n",
    "        # Start pairing with elements in sublists after the current one\n",
    "        if current_index is not None:\n",
    "            for subsequent_sublist in top_orders[i]['list_of_orders'][current_index + 1:]:\n",
    "                for next_num in subsequent_sublist:\n",
    "                    pairs.append(f\"{current_num} < {next_num}\")\n",
    "        \n",
    "        # Add the result for the current number\n",
    "        result.append({\"num\": current_num, \"pairs\": pairs})\n",
    "    top_orders[i][\"pairs\"] = result\n",
    "    print(top_orders[i][\"pairs\"])\n",
    "\n",
    "\n",
    "\n",
    "topological_order_gt_3to5_nodes = [\n",
    "{\n",
    "    'id': item[\"id\"],\n",
    "    'topological_order': item[\"topological_order\"],\n",
    "    'list_of_orders': item[\"list_of_orders\"],\n",
    "    'label': item[\"pairs\"],\n",
    "} for item in top_orders]\n",
    "\n",
    "with open('./test_topologicalorder/topologicalorder_GTlabel_6-10_nodes.json', 'w') as json_file:\n",
    "    json.dump(topological_order_gt_3to5_nodes, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ->Check the generated topological orders manually before proceed further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data Dependency Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare selected function list to feed into function of data dependency management\n",
    "\"\"\"\n",
    "def read_apiinfo(filename):\n",
    "    api_info = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            api_info.append(json.loads(line))\n",
    "\n",
    "    return api_info\n",
    "\n",
    "api_info = read_apiinfo(filepath_apiinfo)\n",
    "top_orders = read_json_to_dict(filename_topologiacal_6to10)\n",
    "data = read_json_to_dict(filename_tasklist_6to10)\n",
    "\n",
    "# Loop over both lists and add 'topological_order' to the corresponding item in data\n",
    "for i in range(len(top_orders)):\n",
    "    # Assuming the length of top_orders and data is the same\n",
    "    data[i]['topological_order'] = top_orders[i]['topological_order']\n",
    "\n",
    "extracted_api_names = [\n",
    "    {\n",
    "        'id': item['id'],\n",
    "        'task_list': item[\"task_list\"],\n",
    "        'selected_apis': item['selected_apis']\n",
    "    }\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "all_task_info = []\n",
    "# Concatenate by same index\n",
    "for i in range(len(extracted_api_names)):\n",
    "    concatenated_list = [[task, api] for task, api in zip(extracted_api_names[i][\"task_list\"], extracted_api_names[i][\"selected_apis\"])]\n",
    "    combined_dicts = [{**dict1, **dict2} for dict1, dict2 in concatenated_list]\n",
    "    all_task_info.append(combined_dicts)\n",
    "\n",
    "# Extract all api names from api repositories\n",
    "all_api_names = [item[\"name\"] for item in api_info]\n",
    "\n",
    "# Retrieve apis' infomation\n",
    "for i in range(len(all_task_info)):\n",
    "    selected_functions = []\n",
    "    for task in all_task_info[i]:\n",
    "        if task[\"name\"] in all_api_names:\n",
    "            for func in api_info: \n",
    "                if task[\"name\"] == func[\"name\"]:\n",
    "                    selected_func = func.copy()  # Make a copy to avoid mutating the original\n",
    "                    selected_func[\"task_num\"] = int(task[\"task_number\"])\n",
    "                    selected_func[\"task_description\"] = task[\"task_description\"]\n",
    "                    selected_functions.append(selected_func)\n",
    "        data[i][\"selected_functions\"] = selected_functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dependency Management\n",
    "\"\"\"\n",
    "from utils.data_dependency import confirm_dependency\n",
    "from utils.schemas.workflow import TaskOutputDescription, DependentParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For classification of data dependency \n",
    "\"\"\"\n",
    "for i in range(len(data)):\n",
    "    selected_functions, user_inputs, depended_params = confirm_dependency(data[i][\"topological_order\"], data[i][\"selected_functions\"])\n",
    "    func_list = []\n",
    "    for api in selected_functions:\n",
    "        all_params = [component['name'] for component in api[\"input_parameters_with_datatype\"]]\n",
    "        depended_params = [list(item.keys())[0] for item in api[\"depended_params\"]]\n",
    "        user_inputs = [param for param in all_params if param not in depended_params]\n",
    "        func_list.append({\"name\": api[\"name\"], \"all_params\": all_params, \"user_input\": user_inputs, \"dependent_params\": depended_params})\n",
    "    data[i][\"param_dependency_management\"] = func_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save Data Dependency Management test data\n",
    "- classification of user_input and dependent_param\n",
    "- correctness of dependednt_param \n",
    "\"\"\"\n",
    "dd_data = [\n",
    "    {\n",
    "        'id': item['id'],\n",
    "        \"number_of_node\": len(item[\"task_list\"]),\n",
    "        'task_list': item[\"task_list\"],\n",
    "        \"topological_order\": item[\"topological_order\"],\n",
    "        'selected_apis': [{\n",
    "            \"name\": api[\"name\"], \n",
    "            \"input_params\": api[\"input_parameters_with_datatype\"],\n",
    "            \"dependencies\": api[\"dependencies\"],\n",
    "            \"depended_params\": api[\"depended_params\"],\n",
    "            } for api in item['selected_functions']],\n",
    "        'param_dependency_management': item[\"param_dependency_management\"]\n",
    "    }\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "with open('./test_datadependency/datadep_GTlabel_6-10_nodes.json', 'w') as json_file:\n",
    "    json.dump(dd_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
